[{"FileName": "FileName", "GUID": "GUID", "FileName Path": "FileName Path", "FileName Version": "FileName Version", "Created DateTime": "Created DateTime", "Updated DateTime": "Updated DateTime", "Created By": "Created By", "Updated By": "Updated By", "RawOCR": "RawOCR"}, {"FileName": "DocAve_Software_Brochure.pdf", "GUID": "3a1d05c5-2d6c-46d6-8981-d70d17ba4458              ", "FileName Path": "http://msfdemo.isearch.com:18605/Demo MSF/DocAve_Software_Brochure.pdf", "FileName Version": 1, "Created DateTime": "2023-01-25 06:40:52.000", "Updated DateTime": "2023-01-25 06:40:52.000", "Created By": "Guru                                                                                                ", "Updated By": "Guru                                                                                                ", "RawOCR": "UN A AvePoint* .\nAoW DocAve Brochure\n\nDocAve Software\n\nMigrate. Integrate. Manage. Optimize. Protect. Report.\n\nIntroducing Enterprise-Class Infrastructure Management Platform for\nMicrosoft\u201d SharePoint\u00ae\n\nAs a fully integrated platform, DocAve Software:\n\n= Simplifies the deployment, monitoring, and enforcement of Microsoft SharePoint Server and SharePoint Online infrastructure\nmanagement and governance policies\n\n= Enables centralized or delegated management of SharePoint farms hosted on-premises, or in private and public clouds such\nas Microsoft Office 365 and Microsoft Azure\n\n= Enhances business continuity with intelligent item-through platform-level data protection, simplified restoration of all SharePoint\nasset \u2014 including externalized content and customizations \u2014 and a one-switch highly available, failover orchestrator\n\n= Manages development, test, and production farms with ease\n\n= Governs solution and component deployment with application lifecycle management tools\n\nKey Benefits\n\nIncrease Business\nProductivity\n\nDeliver high-performance,\nglobal collaboration.\n\n= Enable seamless global\nSharePoint service\n\n= Empower business users while\nenforcing policies and standards\n\n= Optimize content availability\n= Improve quality of service\n\n= Consolidate document access\nto a single user experience\n\n= Automate the repetitive and\ntime-consuming processes\ninvolved in provisioning,\nconfiguring, managing, and\nenforcing SharePoint\ngovernance policies\n\nReduce Total Cost of\nOwnership\n\nIncrease operational\nefficiency.\n\n= Utilize cloud offerings and\neliminate infrastructure and\nstorage costs\n\n= Improve ongoing realignment\nof cost allocation by analyzing\nbusiness usage and rate of\nadoption\n\n= Provide insight into operations,\nperformance, and usage\n\n= Integrate and support leading\nSharePoint hardware and\nsoftware solutions\n\n= Consolidate and integrate\nlegacy content management\nsystems\n\nProvide IT Assurance\n\nImprove quality of service &\nminimize business\ndisruption.\n\n= Meet requirements for\nlong-term content and\ninformation management\n\nProtect business content \u2014\nregardless of on-premises,\nhybrid, or cloud hosted - with\nsupport for enterprise-caliber\nService Level Agreements\n\nArchitect a highly available\nservice resilient in the face of\ndisaster\n\nProtect the content and\nconfiguration of leading\nthird-party SharePoint\napplications and services\n\nEnable Security &\nCompliance for\nBusiness Content\n\nStandardize and enforce\ncorporate IT policies.\n\n= Provision user permissions\nto content\n\n= Comply with information\ngovernance and records\nmanagement policies by\napplying retention policies\nto content\n\n= Implement sophisticated\nauditing policies\n= Archive content to tiered\n\nstorage\n\n= Respond to Legal eDiscovery\nrequests for with speed and\nprecision\nDocAve Capabilities\n\nMigration\n\nSeamlessly migrate enterprise content from legacy systems or\nprevious SharePoint versions into SharePoint Server 2013,\n\nSharePoint Server 2010, or SharePoint Online with full fidelity\nfor swift reorganization and streamlined content propagation.\n\n\u00bb Migrators\n* Documentum eRoom Migrator * Oracle/Stellent Migrator\n* EMC Documentum Migrator \u00a9 Quickr Migrator\n\u00a9 Exchange Public Folder Migrator \u00bb SharePoint Migrator\n\u00b0 File System Migrator \u00a2 Vignette Migrator\n\u00a2 Livelink Migrator \u00a9 Website Migrator*\n\n\u00a2 Lotus Notes Migrator\n\nManagement\n\nStreamline the implementation and enforcement of access,\nprovisioning, and lifecycle management policies with\ncomplete, unified management and control over SharePoint\ncontent, customizations, users, security, and sites.\n\n= Administrator = Report Center\n\n= Content Manager = Governance Automation*\n= Deployment Manager = DocAve Online*\n\n= Replicator\n\nProtection\n\n@ y Protect all critical SharePoint assets from network failure,\nnon-compliant content, and accidental deletion to ensure\ncontinuous SharePoint platform availability.\n\n* Archiver * Vault\n* Backup and Restore = Governance Automation*\n\u00bb High Availability = DocAve Online*\n\n= SQL Server Data Manager\n\nHow to Buy DocAve\n\nCall: 201.793.1111\n3 Second Street\n\nJersey City, NJ 07311\n\nE-mail: Sales@AvePoint.com\n\nEvaluate DocAve for free at:\nwww.AvePoint.com/download\n\nAvePoint Global Headquarters.\n\nPhone: 201.793.1111 Fax: 201.217.8709\n\nIntegration\n\nIntegrate SharePoint environments with existing\nnetwork or cloud file-based content, or other\nSharePoint farms, to consolidate access to\nenterprise-wide digital assets without migration.\n\n\u00bb Connector\n\n* Replicator\n= File Share Navigator*\n\nOptimization\n\nDeliver high-performance global collaboration while\nlowering SharePoint total cost of ownership (TCO) with\nefficient Microsoft\u00ae SQL Server\u00ae storage and content\nlifecycle management.\n\n= Archiver = Storage Manager\n= Connector = File Share Navigator*\n\n= Report Center = Governance Automation*\n\nReporting\n\nSingle pane access to a wide variety of mission-critical\ncontent, data, and trending statistics to generate\ncustomizable reports and alerts based on growth,\nperformance, usage, or legal eDiscovery requests for\nproactive decision making.\n\n\" DocAve eDiscovery = Governance Automation*\n= Report Center\n\nFor US Government Organizations:\nDocAve can be purchased directly from\n\nG SA AvePoint or through the GSA website at\n\nwww.GSAadvantage.gov.\n\nFor more information on why you should choose AvePoint as your strategic SharePoint partner, visit www.avepoint.com.\nCan\u2019t get enough DocAve? Continue the conversation by joining our community site www.avepoint.com/community/.\n*Standalone products can be purchased independently of DocAve 6 Software Products.\n\nAccessible content available upon request.\n\n\u00a9 AvePoint, Inc. All rights reserved. DocAve, AvePoint, and the AvePoint logo are trademarks of AvePoint, Inc. All other marks are trademarks of their respective owners.\n"}, {"FileName": "Deployer User Guide.pdf", "GUID": "b90155f0-f06b-4a47-b811-536ca276fab9              ", "FileName Path": "http://msfdemo.isearch.com:18605/Demo MSF/Deployer User Guide.pdf", "FileName Version": 1, "Created DateTime": "2023-01-25 06:40:53.000", "Updated DateTime": "2023-01-25 06:40:53.000", "Created By": "Govind                                                                                              ", "Updated By": "Guru                                                                                                ", "RawOCR": "Tzunami\n\nMigration Masters\n\nTzunami Deployer\nUser Guide\n\nLearn how to successfully migrate ECM contents to\nMicrosoft SharePoint using Tzunami Deployer.\n\nVersion 2.8\nTable of Content\n\nCOMMENTS AND SUGGESTIONS\n\n1 TZUNAMI DEPLOYER FOR SHAREPOINT MIGRATION .........csccsssssssssssssssssssssssessessessessessessessessessessesseseeses 1-1\nTZUNAMI DEPLOYER OVERVIEW .....c.ccsesccssssescsecseeecsesesecsusensecsusesseseasensessasensessusessessasesseseaseaseseaseseeseasesseseaseneeseasese 1-2\nSupported Source SYStOMs......ceccecssceseeeeseeseeecseeecseeseeecsecaeeeeseeaeeaesecaeeaeeecaeeaseesaeeessesaeeesesaesaseesesaeeeeeeeate 1-2\n\nSupported Target Systems\nTZUNAMI DEPLOYER WORKFLOW...\nKey Features... eeeeceesseseessecseessecseeeeesaeeseesaecseseaeeaesaseaeeseseaeeseeeaecaeeaeeaeseseaeseseaeseeseaesaeseaseaeeeeseaeeenseaees\nLICENSING INFORMATION. .....cccccesssseseesssecseeecseceesesaececseseacecseseaseeseseasessessasesseseasesseseasesseseacesseseacesseseaseseesaaeeseesaases\n\nCREATING A NEW MIGRATION PROJECT.\n\nSAVE A PROJECT\n3 CONNECTING AND LOADING SERVERS. .........sssssssssssssssscssssssssseecsssecssscsessesessssccesscsesseseseseaceseccesecasaseesens 3-10\nCONNECTING AND LOADING SOURCE SERVER......:csccssssesessceeeecseceeeecsaceeecsasesseseasessessaceseessaseseessuseseseasesesaaseseeseases 3-11\n\nLoading from File System\nConnecting and Loading from Source SharePoint.\nLoading from TDX File\nCONNECTING AND LOADING TARGET SERVER...\nConnecting Microsoft Office 365 ...\nConnecting and Loading SharePoint WFE Server ..\n\nConnecting and Loading SharePoint Server (without using Remote Service) .........:esceceseeeeeeeeeeeeeees 3-30\n\nConnecting and Loading SharePoint 2003 ..\n\nReloading SharePoint Items\n\nRemoving SharePoint Project ........ceccecssceseeceseesceeeseeecseeseeeesesaeeecsesaeeeeseeaeeeesesaeeeesesaeeetsesaeeessesaeeeeeesaeees\nBEST PRACTICE ....ssescessssescsssseeecsessececsessnsecsasenecsaseasecsaseasessuseasessuseaseseaseaseseaseaseseasegeeseusesseseasesseseaseseeseuseaeeseasas\n\n4 MODELING, DEPLOYING AND COMMITTING DEPLOYER PROJECT ........s:cssssssssessessssssssesssssessessesesesseeee 4-34\n\nMODELING SHAREPOINT TARGETS\n\nModeling SharePoint Structure.. .\nModeling SharePoint Metadata Service ........eeccecssceeeeesseseeeeseeeeeeseeeesecaeeeesecaeeeeseeaeeessesaseesesateeteetaeeee 4-41\nViewing Security Information\n\nModeling SharePoint Security and Permissions\nFind and View It\u20acMS ......c cece eeneeseeeeseeseeeceeesesseneeesesessesseeeesesaeeceeesesseeeeeesesassaeeeesessseseeeesesaeeaeness\n\nDEPLOYING SOURCE DATA FOR MIGRATION\nDeploying Selected Source Items to a Target SharePoint Locations..\n\nDefining Deployment Options\nMapping Security Information ........ccecesceceecsseeseeeeseeeeeeeseeeeseeaeeecsesaeeeeseeaeeeesesaeeessesaeeetsesaseesesseeaeeesaeees\n\nwo\n\nMigration Masters\nBest Practice for deploying source.\nCOMMITTING THE MIGRATION\n\nCOMMIttINg NOW .0... eee eeeeseeeceeeeeeeeeeeaeeeeeseeseesaeeaeeseeeaeeseeeaecseseaesaeeeaeeaeseseaeeseseaesseseaesaeeeeseaeeeeseaeeeeeaees\n\nSchedule Commit ....\n\nBatch Mode Commit .. .\n\nBest Practice for Committing a Deployer Project .........cceccecsseeseeeeteeeeeeeseeeeseeseeeesecaeeeesesaeeeteeeseeeeeeeseeee 4-90\n\n5 CONFIGURING TZUNAMI DEPLOYER ADVANCE FEATURES..\n\nRULE ENGINE\n\nConfiguring Rule Engine\n\nOpening the Rule Sets... .\nSpecifying Rule Set LOCATION ........eseeeeecsseeceeeeseeeeeeseeeeseeseseeseeaesecsesaeecsesaeecsesaseeeseeateecsesateeseetaeeaseetaees 5-94\nRule Sets Editor\nCreating a New Rule Set\n\nCopying a Rule Seto... ee eeeceeceseecceeeseeecseeseeeeseeaeeecsesaeseesesaeseesesaeeeesesaeseesesateessesateeaesaseecsetateessetateeeaeeatee\nCreating a Rule in a Rule Set\nCopying and modifying a Rule in a Rule Set\nDefining Conditions ........cceeesseeeeceseeceeeeseeecseeseecsesacsecsecaesecsesaesecsesaesecsesassecsesassecaeeasesaeeaseesaeeeseeeaees\n\nDefining Actions\nTZUNAMI DEPLOYER OPTIONS ..\n\nSharePoint Connectivity ........sceccecescecessesceeeeeseeecseesceecseeacsecaeeeesecseeeesesaeeessesaeeassesaeeesesaseeseesaeeeseeeateee\nSharePoint Timeouts\nSharePoint Read Settings .\nSharePoint Commit Settings.........ccceccsssceccseseecceeeseeecseeeceecseeeeecseeeeseeaeeecsesaeeessesaseesetaeeeseesaeeaseesaeees\nDeployment\nMappings...\nSQCUIILY eee eeeeeeeseeeeeeseeeeeeeeeseeeaeeseesaeeaeeseeeaecseeeaesaessaeeaessaesaesseseaeeaeeeaeeaeseaeeaeeeeesaeseeeaeeeseaeseeeaeseeeeatees\nActive Directory\nMembership Provider\nRule Engine\nAuto Fixes\nOthers..\nLink Registration.. we\nLOGGING \u00aboe. ee eeeeeeeeceeseeseeeeeeseeeeeaeeseeeaecseeeaeeaeeseeeaeeseeeaecseeeaesaeeeaesaeeeesaeeseesaeeseseaesaeseaesaeseneeaeseaseeeeateaee\n\nFOLDER AND FILE NAMING CONSIDERATIONG............sssssssssssssssssessssssssssasssessssassassassassassasesesasesseassassassaseaseaeeas |\n\nFOLDER PATH AND FULLY QUALIFIED FILE NAME LENGTHS .\n\nRestrictions\n\nNAMING CONSIDERATIONS.\n\nEXECUTION REPORT .....sscscescsseseescssceeeecseceseecsacecsecsacessessasessessasesseseasesseseasessessasessessasesseseasesseseaseaeeseaseseeseasaaeeseaseaes Vi\n\ntuna\n\nMigration Masters\nUNEXPECTED ERRORS......cscescsseseescssesesessececsessacecsesaaecseseaseeseseasessesaasessesaaseeseseaseseeseaseseesaacessesaacessesaaeessesaaeeseeseases Vil\nFREQUENTLY ASKED QUESTIONS .......ccescsssseeeeseceeeecsaceesecsasessessusesseseaseaseseaseaseseasessessaseaseseaseaeeseeseaeeseeseaseseaseaeeseesagees xX\nInstallation\nPermissions\n\nMigration...\nSecurity\n\nBroken Links\nBatch and Command Line Operations.\n\nRemote Operation se\nLOGGING oo. eee eeeeceeseeeeeeseeeeeseeseeeeeeaeeseesaecseeeaecseeaesaeesaeeaeeseseaeeaeeeaseseseaeeaesseseaeeeseaesaeseaesaeeeaesaeeeaseaesenseaees\n\nCOPYRIGHT AND TRADEMARK..........scsscssessesessessessessessessessessessessessesseseeseeseeseeseeseeseeseeseeneeseeneeseeseeneeneeneeneenes XIV\n\ntuna\n\nMigration Masters\nPREFACE\n\nABOUT THIS GUIDE\n\nThis guide helps you to use the Tzunami Deployer and migrate contents from legacy ECM\n\nsystems to Microsoft SharePoint.\n\nThis preface contains the following topics.\n\nIntended Audience\nStructure\n\nRelated Documentation\nConventions\n\nTechnical Support\n\nComments and Suggestions\n\nINTENDED AUDIENCE\n\nTzunami Deployer Administrators\u2019 Guide is intended for:\n\nSystem Administrators who are responsible for setting migration environment using\nTzunami Deployer.\n\nProject Managers and IT Managers who create and regulate usage of Tzunami\nDeployer.\n\nSTRUCTURE\n\nThis Tzunami Deployer User Guide is organized as follows:\n\nTzunami\n\nMigration Masters\n\nPreface contains the overview of this manual.\n\nChapter 1 \u2018Tzunami Deployer for SharePoint Migration\u2019 provides the overview of\nTzunami Deployer.\n\nChapter 2 \u2018Getting Started with Tzunami Deployer\u2019 explicates how to create a\nDeployer project and save a project for future migration.\n\nChapter 3 \u2018Connecting and Loading servers\u2019 illustrates how you can load a Source\nECM contents and target SharePoint in the Deployer Project.\n\nChapter 4 \u2018Modeling, Deploying and Committing Deployer Project\u2019 explains how\nyou can model the target SharePoint and deploy Source content. It also explains\nways you can commit a Deployer project.\n\nChapter 5 \u2018Configuring Tzunami Deployer Advance Feature\u2019 describes you how to\nconfigure Tzunami Deployer settings.\n\nPage | |\nRELATED DOCUMENTATION\n\nFor more information, see these Tzunami Deployer resources.\n\nTable 1: Tzunami Products Documentation and Resources\n\nProducts\n\nTzunami Deployer\n\nTzunami Deployer\nLicensing Service\n\nExporters\n\nTzunami AquaLogic\nExporter\n\nTzunami Documentum\nExporter\n\nResource\n\nTzunami Deployer\nInstallation Guide\n\nTzunami Deployer User\u2019s\nGuide\n\nLicensing Service Guide\n\nAquaLogic Exporter Guide\n\nDocumentum Exporter\nGuide\n\nBrief Description\n\nDescribes how to run the setup program and\ncomplete the installation and configuration of\nTzunami Deployer and Tzunami Deployer\nService Components.\n\nElaborates the steps required to create, Load,\nmodel, deploy and commit a Deployer project.\n\nExplains step by step instruction for Tzunami\nDeployer licensing service.\n\nSupports migration of BEA AquaLogic User\n\nInteraction portal contents to Microsoft\nSharePoint.\nSupports migration of Documentum\n\nrepositories and content management services\nto Microsoft SharePoint.\n\nTzunami DocuShare\nExporter\n\nDocuShare Exporter\nGuide\n\nFacilitates migration of Xerox DocuShare web\ncontents to Microsoft SharePoint.\n\nTzunami eRoom\nExporter\n\nDocumentum eRoom\nExporter Guide\n\nSupports extraction of all rooms on the server\nand guides migration to Microsoft SharePoint.\n\nTzunami Exchange\nExporter\n\nTzunami Hummingbird\nDM5 Exporter\n\nExchange Exporter Guide\n\nHummingbird DM5\nExporter Guide\n\nGuides migrating Exchange contents to\nMicrosoft SharePoint.\n\nSupports migration of Hummingbird DM\nenterprise contents repositories to Microsoft\nSharePoint.\n\nTzunami Livelink\nExporter\n\nLivelink Exporter Guide\n\nSupports migration of LiveLink contents to\nMicrosoft SharePoint.\n\nTzunami Lotus Notes\nExporter\n\nTzunami Confluence\nExporter\n\nTzunami Oracle WCI\nExporter\n\nTzunami Google\nExporter\n\nTzunami SharePoint\n2001 Exporter\n\nTzunami\n\nMigration Masters\n\nLotus Note Exporter\nGuide\n\nConfluence Exporter\nGuide\n\nOracle WebCenter\nInteraction Exporter\nGuide\n\nGoogle Exporter Guide\n\nSharePoint 2001 Exporter\nGuide\n\nSupports migration of Notes contents to\nMicrosoft SharePoint.\n\nSupport migration of Confluence Enterprise\nwiki contents to Microsoft SharePoint.\n\nSupport migration of Oracle WebCenter\nInteraction components to Microsoft\nSharePoint.\n\nSupport migration of Google Drive contents to\nMicrosoft Sharepoint.\n\nProvides user interface and basic functionalities\nof Tzunami SharePoint 2001 Exporter.\n\nPage | Il\nCONVENTIONS\n\nThe following text conventions are used in this document:\n\n\u00a2 Commands and keywords are given in boldface\n\n\u00a2 Terminal sessions, console screens, or system file names are displayed in fixed\nwidth fonts\n\nA Caution indicates that the described action might result in program malfunction or data loss.\n\nSP Notes contain helpful suggestions about or references to materials not contained in this\nmanual.\n\n4 Tips provide information that might help you solve a problem.\n\nTECHNICAL SUPPORT\n\nBefore contacting Tzunami Deployer Support team, ensure that you are referencing the\nlatest copy of this user guide from:\n\nhttp://download.tzunami.com/go.aspx?UserGuide=Download\n\nIf you have searched our reference materials and the issue still persists, contact Tzunami\n\nDeployer Support Team at support@tzunami.com\n\nCOMMENTS AND SUGGESTIONS\n\nYour feedback is important to us and will help us to provide the most accurate and high\nquality information possible in our documentation. Send us comments or suggestions by\nemail to support@tzunami.com. Be sure to include as much of the following as possible:\n\ne\u00a2 The document title.\n\ne The location that the document was accessed from (either downloaded from\nTzunami web site or the Tzunami Deployer User Guide available in Tzunami\nDeployer).\n\ne The section or chapter number and the original text found in the document.\n\nWhen you send information to Tzunami Deployer, you grant Tzunami a non-exclusive right to\nuse or distribute the information in any way it believes appropriate without incurring any\nobligation to you.\n\ntuna\n\nMigration Masters\n1 TZUNAMI DEPLOYER FOR SHAREPOINT\nMIGRATION\n\nThis chapter describes the features of Tzunami Deployer for SharePoint that are\ndocumented in this guide and provides pointers to additional information. It contains the\nfollowing topics:\n\n\u00a2 Tzunami Deployer Overview\n\n\u00a2 Tzunami Deployer Workflow\n\ne Licensing Information\n\nwe ==\n\nMigration Masters\nTZUNAMI DEPLOYER OVERVIEW\n\nTzunami Deployer is the leading tool for rapid migration and consolidation of content from\nmultiple sources into Microsoft SharePoint Products and Technologies.\n\nTzunami Deployer enables organizations that wish to start using or upgrading their\nSharePoint to dramatically reduce migration costs. Using Tzunami Deployer, the time\nrequired for a SharePoint content migration project is significantly reduced compared to the\ntraditional labor-intensive processes.\n\nTzunami Deployer enables you to prepare modeling and migration plans offline and even\noff-site. Any changes performed in Tzunami Deployer do not actually affect the SharePoint\nserver until you choose to commit them. For more information about Microsoft SharePoint\nProducts and Technologies, refer to: http://www.microsoft.com/sharepoint/default.mspx.\n\nSupported Source Systems\n\ne SharePoint Portal Server 2001\n\u00a2 SharePoint Portal Server (SPS) 2003\ne\u00a2 Microsoft Office SharePoint Server (MOSS) 2007\n\ne SharePoint Server 2010(SPS2010) and SharePoint Foundation 2010\n(SPF2010)\n\n\u00a2 Microsoft Office 365\n\ne SharePoint Server 2013 (SPS2013) and SharePoint Foundation 2013\n(SPF2013)\n\n\u00a2 Local File System and Remote File Servers\ne Exchange Server\n\ne Lotus Notes and Domino Server Databases\ne BEA AquaLogic 5.x, 6.x and 6.5\n\ne EMC Documentum\n\n\u00a2 Xerox Docushare\n\n\u00a2 EMC Documentum eRoom\n\n\u00a2 = OpenText LiveLink\n\ne\u00a2 Hummingbird DM5\n\ne Atlassian Confluence\n\n\u00a2 Oracle WebCenter Interaction\n\ne HyperWave\n\n\u00a2 Google Drive\n\ne Custom Repositories\n\nua =\n\nMigration Masters\nTzunami\n\nSupported Target Systems\n\nWindows SharePoint Services (WSS) 3.0\nMicrosoft Office SharePoint Server (MOSS) 2007\n\nSharePoint Server 2010(SPS2010) and SharePoint Foundation 2010\n(SPF2010)\n\nMicrosoft Office 365\n\nSharePoint Server 2013 (SPS2013) and SharePoint Foundation 2013\n(SPF2013)\n\nTZUNAMI DEPLOYER WORKFLOW\n\nMigration Masters\n\ns ings\n== Service 5\ns Active\nB Directory\n< a\n\u201c pahigg ss PRESSES aS >\n\u2019 / \\\nso eo comme Commit 1\n~ i , og\nTDX _ I\n| Tzunami !\nee | Remote SharePoint 2013!\nsects | Service SharePoint 2010\ncacleoge sa Se a OR pan 2007,\n( Tzunami Deployer Using Remote service )\nFile System J\n\nLink\nResolver\nService\n\nRead Usersaa\n\n]\n;\nyp!\ni\n&\neer\nae\n\nTDX\n\u2018\nTzunami\nployer\nModel and Deploy,\n\n( Tzunami Deployer Without Using Remote service )\n\nFile System\n\nFigure 1: Tzunami Deployer Content Migration Workflow\nTzunami\n\nMigration Masters\n\nKey Features\n\nEasy to use\u2014 Similar to the windows file explorer, Tzunami Deployer has a\nfamiliar, tree-based, drag and drop user interface.\n\nMigrates all List Types\u2014 Custom Lists, Document Libraries, Folders, Issues,\nTask, Contacts, Announcements, Discussions, Web Part, Home Page, Quick\nLaunch, Wiki Site, Content Type etc. can all be migrated while preserving\nviews, metadata, and user-edit information.\n\nCopying contents within SharePoint servers\u2014 Tzunami Deployer supports\nthe copying of content between and within SPS2013/SPF2013, Office 365,\nSPS2010/SPF2010, MOSS/WSS3.0 and SPS2003/WSS2.0 servers, sites and\nlists.\n\nModeling and deploying tool\u2014 Leading tool for modeling, customizing, and\ndesigning SharePoint sites, lists, libraries, and folders etc. as well as\nmanaging security settings.\n\nMetadata editing and mapping\u2014 Tzunami Deployer\u2019s metadata editing and\nmapping features provides a central point for metadata administration for\nall SharePoint sites.\n\nRetain your valuable data\u2014 When deploying content to SharePoint, Tzunami\nDeployer maps metadata properties of source items to target columns in\nSharePoint libraries and lists. If no appropriate columns exist in the target to\nhost your source properties, you can create them on the spot.\n\nMigrate permission\u2014 When migrating content into SharePoint, Tzunami\nDeployer analyzes security permissions in the content sources and allows\nmapping of source users, roles and permissions to corresponding\nSharePoint users, groups, roles and permissions in order to best match the\nexisting settings.\n\nOffline simulation environment-\u2014 Tzunami Deployer loads all source and\ntarget information into a Tzunami Deployer project. This enables Tzunami\nDeployer to be used to make modifications and deployment plans even\nwhen it is not connected to either the source or the target machines.\n\nAll modification and deployment actions performed in Tzunami Deployer are\nnot executed immediately. Rather, these changes are recorded in a Tzunami\nDeployer project. You can duplicate a Tzunami Deployer project to create\nseveral modeling and deployment scenarios, and choose the one best suited\nfor your needs.\n\nTzunami Deployer only applies the changes to the target location and\nuploads the content from the source locations when you perform the\ncommitting stage.\n\nPage | 1-4\nAll changes performed by Tzunami Deployer are done through the\nsupported SharePoint API\u2019s. Tzunami Deployer does not perform any\nunsupported direct writes to the SharePoint databases.\n\nLICENSING INFORMATION\n\nThere are currently two types of licenses.\n\nEvaluation License: Each Tzunami Deployer and Exporters are installed with a\ndefault evaluation license which limits the number of items that can be migrated\nfrom each container. Refer to Tzunami Deployer Licensing Service Guide for more\nDetails.\n\nFull License: This type of license determines the amount of data that can be\nmigrated from the source system to the target SharePoint. When committing\ncontent to the target SharePoint, Tzunami Deployer Remote Service communicates\nwith Tzunami Licensing Service to check the availability of license.\n\nTzunami Deployer Licensing Service provides project managers with the centralized\npoint of management for the Tzunami Deployer licenses. For more information, see\nLicensing Service Guide.\n\nIf you do have a valid license installed, or the license that you have installed is expired, you\nwill be prompted to install a new license when you run Tzunami Deployer for SharePoint\nMigration. To purchase a new license, contact Tzunami Sales Team at sales@tzunami.com.\n\nIf an error message appears, contact the Tzunami Support Team at support@tzunami.com.\n\nTo evaluate Tzunami Deployer you do not need Tzunami Licensing Service. If you need\nTzunami Deployer evaluation license, please contact Tzunami Support.\n\nTzunami\n\nMigration Masters\n\nPage | 1-5\n2 GETTING STARTED WITH TZUNAMI\nDEPLOYER\n\nThis chapter describes how to create a project in Tzunami Deployer and save Deployer\nproject for future use. This chapter contains the following topics:\n\ne Creating a New Migration Project\n\ne Save a Project\n\nwe ==\n\nMigration Masters\nCREATING A NEW MIGRATION PROJECT\n\nTzunami Deployer stores all the information related to a particular project in a Tzunami\n\nDeployer project. The project consists of a file system folder, which contains the Tzunami\nDeployer project file (information describing the SharePoint structure and changes that will\n\nbe executed on the target).\n\nBegin using Tzunami Deployer by creating a new project.\n\nTo create a project:\n\n1.\n\n2.\n3.\n\nTzunami\n\nMigration Masters\n\nLaunch Tzunami Deployer and select File > New. The New Project window appears.\n\nx\nProject Name: [\nProject Folder: [D:\\Deployer2.8\\March 24 Browse...\n\nProject will be created at:\n\n0 Source SharePoint 2010\n\nSource SharePoint 2007 |\n1 Source SharePoint 2013 fe\n\nDeploy to: DD Taroet Office 365 ~\nCO Target SharePoint 2003\n1 Target SharePoint 2007 |\n\nre |\n\nFigure 2: New Project Window\n\nEnter a name for the project in the Project name field.\n\nIn the Project folder field, enter the location where you want Tzunami Deployer to\ncreate the new project folder.\n\nThe project folder contains all the definitions that you create in Tzunami Deployer, automatic\nbackups of the project, as well as logs and reports of the activities that are performed in and\nby Tzunami Deployer.\n\nTzunami Deployer (x64) does not support SharePoint 2001.\n\nSelect one or more types of source systems to be migrated in this project\n\nOne of Tzunami Deployer\u2019s advantages is its ability to consolidate several source\nsystems into a single target SharePoint server. The source options that are available\nfor selection are determined by the license that you installed, as described in the\nprevious section. Options that are not permitted by your license are not available for\nselection. For e.g. SharePoint 2003 is not available in the window above. For more\ninformation about the Tzunami Deployer license, and for support of systems that are\nnot listed, contact the Tzunami Support Team.\n\nSelect a target system for the migration in this project.\n\nPage | 2-7\n6. Click OK. Tzunami Deployer creates the new project folder and initializes the project\nfiles in it. The Project window appears. Initially, both parts of the Project window are\nempty.\n\n2/51 x!\n\nFile View Data Tools Help\n] \u00a9f | D YO GA ~ | Filesystem: 5, AddFileSystem 2, Add HyperWave gj | eRoom: \u00a7JExport (2-Load 2 2\n\nL-)\n\nName #Versions | Deployed To\n\nFigure 3: Project Window\n\nThe top half of the Project window uses a Windows Explorer style folder tree and details list\nto display the structure and content that has been loaded from the source systems. The\nbottom half of the Project window uses a similar approach to display the structure and\ncontent of the target SharePoint. The details list in the top and bottom parts of the Project\nwindow show columns of metadata properties and other information for the children items.\n\nThe status bar indicates various types of information, such as the currently listed and\nselected items and the status and progress of Tzunami Deployer processes. An indicator on\nthe left of the status bar displays red when Tzunami Deployer is busy or when a dialog is\nopen and Tzunami Deployer is waiting for user input. This indicator blinks yellow when\nTzunami Deployer is performing a background operation. During a background operation,\nthe current stage of the operation is also displayed, as well as a progress bar and the\nestimated time remaining for the operation to be completed. The indicator is green at all\nother times.\n\nua\n\nMigration Masters\nSAVE A PROJECT\n\nWhen you save a project, you can save it to a folder on your hard disk drive, a network\nlocation, disk, the desktop, or another storage location. To do this, select a desired\ndrive/folder from the Save As window. The Saving process is the same, regardless of what\nlocation you choose.\n\nYou should save the project frequently while you are working on it to avoid losing data\nbecause of an unexpected power failure or other problem.\n\nTo save a project:\n\n1. Click ad\n\nOr\n\nSelect File > Save\nOr\n\nPress Ctrl+$\n\nx\nProject name:\nProject folder: |D:\\Friend and Co Browse... |\n\nProject will be created at\n\n[0K] conca_|\n\nFigure 4: Save As window\n\n2. Enter Project name and Click Ok.\n\nua\n\nMigration Masters\n3 CONNECTING AND LOADING SERVERS\n\nThis chapter explains how to connect and load sources content and target SharePoint in\nDeployer project. This chapter contains the following topics:\n\n\u00a2 Connecting and Loading Source Server\n\ne Connecting and Loading Target Server\n\ne Best Practice\n\nTuna 8B\n\nMigration Masters\nCONNECTING AND LOADING SOURCE SERVER\n\nAfter creating a Tzunami Deployer project, you can load the information that describes the\nsource system\u2019s hierarchy structure and the metadata properties associated with each item.\nA tab appears in the Project window (Figure 3) for each source system type that you\nselected in the New Project window (Figure 2). For more information about creating a\nproject, see Creating a New Migration Project on page 2-7.\n\nThe loaded information is only read from the source system and no modifications are made to\nthe actual source at any time during the migration process.\n\nYou can load information into Tzunami Deployer from one or more of the following source\nstores:\n\ne File System \u2014 Tzunami Deployer can load information directly from your file system.\nFor more information, see Loading from File System on page 3-11.\n\ne\u00a2 SharePoint Web Front-End server\u2014 Tzunami Deployer can load directly from a\nsource SharePoint 2003/2007/2010/2013 store. For more information, see\nConnecting and Loading from Source SharePoint on page 3-14.\n\n\u00a2 Microsoft Office 365 \u2014 Tzunami Deployer can load directly from a source Microsoft\nOffice 365. For more information, see Connecting Microsoft Office 365 on page 3-\n16.\n\n\u00a2 Tzunami Deployer Export (TDX) File \u2014 For certain source (such as AquaLogic,\nDocumentum, DocuShare, Exchange, LiveLink, and so on), Tzunami Deployer first\nextracts structure and metadata information into a TDX file using Exporter modules,\nand then copies the files into a separate directory on your file system (depending on\nyour export mode). For more information about exporting source data, see Tzunami\nExporter Guide. You can then load this TDX file into your project. For more\ninformation, see Loading from TDX File on page 3-14.\n\nBS Information loaded from a source system captures the contents of that store at the time it is\nloaded (or exported, in the case of TDX files). If the source system is modified after being\nloaded, these modifications are not reflected in your Tzunami Deployer project. To access the\nup-to-date content of the source system, you must reload that system (or recreate the TDX\nfile, where necessary).\n\nAfter loading, two numbers appear to the right of each folder name in the source tree, for\n\nexample \u00a72 Log (0/22) The second number is the total number of items in that particular\nfolder and all its subfolders. The first number is the number of items that were deployed to\nthe target.\n\nAll source items are read-only and their icons are displayed with a blue lock (i) overlay.\n\nLoading from File System\n\nTzunami Deployer can load directly from a file system into one or more root folders\nthat you can define in the source tree.\n\nTana\n\nMigration Masters\nTzunam\n\nMigration Masters\n\no\u2014\n\nYou can load HyperWave directly from a File System by using HMI files generated by\n\nHyperWave. HMI files are text files. It contains properties, their values and security\n\npermission for a specific file folder.\n\n4 In order for a .HMI file to relate to a file/folder, the HMI file should:\n\nBe named after the related file/folder.\n\nFor Example \u2014 The HMI file sample1.doc.hmi relates to sample1.doc and contains its\n\nproperties and security permissions.\n\nHave the correct value for the property \u2018Type\u2019\n\nFor Example \u2014 If the property Type is populated with the value \u2018Link\u2019, the file has to\n\nbe html (or similar) file.\n\nHMI files must start with the following line:\n\u201cHyperWave Meta Information/1.1\u201d\nFollowed by an empty line\n\nTo load a source file system:\n\n1. Click us\nOr\n\nRight-click in the File System tab and select Add File System Root or Add\n\nHyperWave Root.\n\n& You can add as many roots as you want.\n\nThe Add File System Root window appears.\n\nadd File system Root xi)\nName: [Friends and Col\n\nLocation: [E\\FiendsandCos\u2014\u201c\u2018 S\u00e9SOSCSC;*;*;*;*;*;*;*;*;*;*;*;C#@BFOW SEL.\n\nM Analyze document content\nFilter\n\nT Created After Friday. February 03.2012 v\nI Modified After Fiday . February 03,2012 +,\nI Accessed After Friday. February 03.2012\u00bb\n\na\n\nFigure 5: Add File System Root window\n\nxi\nName: [Management\n\nLocation: [E\\FiendsandCos\u2014\u201c\u2018 S\u00e9SOSCSC;*;*;*;*;*;*;*;*;*;*;*;C#@BFOW SEL.\n\nF Hide internal properties [7 Overwrite file system properties [\u00a5 Analyze document content\nFilter\n\nT Created After Thursday . November 24,2011\nI Modified After Thursday . November 24.2011 >\nI Accessed After Thursday . November 24.2011\n\na\n\nFigure 6: Add HyperWave Root window\n\nPage | 3-12\n2. Enter a name for the file system root and specify the location of the source\nfile system folder to be loaded.\n\n3. Select Created After, Modified After, and Accessed After to filter out the\nfiles that will be loaded from the file system.\n\n\u2014\n\n(i The Analyze document content checkbox is selected by default and instructs\nTzunami Deployer to scan each file for embedded metadata properties, such as title,\nauthor, and so on. Metadata is retrieved based on IFilters installed on the computer\nrunning Tzunami Deployer.\n\nIf the number of source documents in your file system is very large or each file\u2019s\ninternal metadata does not need to be migrated, deselect this checkbox. When the\nAnalyze document content checkbox is deselected, the loading process is faster.\n\n4. Click OK. The source begins to load. When the process is complete, the\nfolder and files loaded by Tzunami Deployer appear at the top of the Project\nwindow and the status bar displays Ready.\n\nlolx)\n\nBile View Data Tools Help\n1 GF eh | P| 2 GB ~ | re system: i add Filesystem 3, Add HyperWave ij i eRoom: {{JExport (load 5}\n38 eRoom C2 File System | 324} Source SharePoint 2003 |\n\n1/4/2011 4:.... 1/4/2011 4:\n\n{52 Contractors & Consultants (0/18) 1/4/2011 4:.... 1/4/2011 4...\n2 Employee Records (0/7) 14/2011 4:.... 9/13/2011\n4 Employee Reference Letters (0/14) 14/2011 4:.... 2/7/2128...\n1/4/2011 4:.... 1/4/2011 4:.\nPre} Hing Emplo\n\nfg Insurance (0/7)\n[6 Managing & Motivating Employees (0/50)\n\nIEA Policies & Dacumentation (0/48)\n\nFigure 7: Tzunami Deployer Window - Loaded File System\n\n& If certain files fail to load, a warning window appears, listing those files. You can save\nthe information in this window in order to keep track of the migration. This may\noccur for a variety of reasons, such as failure to access a file because of a technical\nproblem. For more information, see Folder and File Naming Considerations on\n\npage I.\n\n=_\u2014m\n\nwe ==\n\nMigration Masters\nTzunami\n\nMigration Masters\n\nConnecting and Loading from Source SharePoint\n\nIf you are migrating contents between SharePoint servers, upgrading from\nSharePoint 2003 to SharePoint 2007/SharePoint 2010/SharePoint 2013/Office 365\nor simply copying your SharePoint content, Tzunami Deployer is an easy to use,\nleading tool to migrate your SharePoint data.\n\nTo do so, you must first connect and load the source SharePoint as a source in the\nTzunami Deployer project. This process is identical to the process of loading the\ntarget SharePoint information, except that you right-click in the source store area\nand then select the Connect to SharePoint option.\n\nTo connect and load source SharePoint:\nClick \u201c23Connect\nOr\n\nRight-click in the Source SharePoint (For example SharePoint 2013) tab and\nselect Connect to SharePoint.\n\nThe Connection Wizard window appears. For more information about\nconnecting to SharePoint, see Connecting and Loading Target Server on\npage 3-15.\n\nLoading from TDX File\n\nIf you have purchased a Tzunami Exporter, you can migrate content from additional\nsources, such as SharePoint 2001, LiveLink, and various other systems. This is done\nwith a Tzunami Deployer Export (TDX) file that can then be loaded as a source in\nTzunami Deployer. If you want to migrate from a content source that is not currently\nsupported, contact the Tzunami Support Team for more information, including the\nspecifications for the TDX file format, which can then be used in the same manner as\nthe sources listed in Connecting and Loading Source Server on page 3-11.\n\nji When running Tzunami Deployer on several machines, you can run an export on one\nmachine, and load the exported data on another machine. While copying exported\ndata to another machine, verify that you copy all the exported data, including both\nthe TDX file and the extracted files directory (typically named FileStore).\n\nWhen loading TDxX file, Exporters have two modes of operations: Full Export and Lite\nExport. When performing a Full Export, documents that are exported are saved to\nthe file system and uploaded from the file system during the commit stage. When\nperforming a Lite Export only the structure, metadata, and security information are\nexported, without the documents. During the commit stage, Tzunami Deployer\naccesses the source system and downloads the documents that are to be uploaded.\nFor Lite Export, the Tzunami Exporters must be installed on the Deployer machine.\n\nPage | 3-14\nTo load a TDx file:\n1. Right-click in the source area, and select Load <System Name> TDX. The\nLoad <System Name> exported information window appears.\n\n& If you have just completed an export, the Load <System Name> exported\ninformation window is already displayed and the Location field already contains the\nlocation of the exported data.\n\nLoad AquaLogic exported information xi\nName: [Friends and Co]\n\nLocation: le \u2018\\Friends and Co Itd\\Documentation \\Friends and Co\\exportData tdx Browse...\n\n[ox] core |\n\nFigure 8: Load <System Name> exported information window\n\n2. Enter a name for the content to be loaded and specify the location of the\nTDX file.\n\n3. Click OK. The source content begins to load. When the process is complete,\nthe folder and files loaded by Tzunami Deployer appear in the top window\nand the status bar displays Ready.\n\nCONNECTING AND LOADING TARGET SERVER\n\nIn this step, you load the structure information describing the content of the target\nSharePoint (2003, 2007, 2010, 2013 or Office 365). Tzunami Deployer loads the SharePoint\nstructure information, including portal areas, sites, lists, libraries, folders, documents, items,\nwiki page, etc. as well as security and metadata information. This information is displayed at\nthe bottom of the Project window in the Target SharePoint tab.\n\no\u2014\n\nThe target SharePoint is not modified until the committing step. For more information about\ncommitting, see Committing the Migration on page 4-84.\n\nYo"}, {"FileName": "Construction_2.pdf", "GUID": "566e050c-f49f-45c5-ba12-faaba4e3772d              ", "FileName Path": "http://msfdemo.isearch.com:18605/Demo MSF/Construction_2.pdf", "FileName Version": 1, "Created DateTime": "2023-01-25 06:40:53.000", "Updated DateTime": "2023-01-25 06:40:53.000", "Created By": "Arun                                                                                                ", "Updated By": "Govind                                                                                              ", "RawOCR": "Construction is the process of constructing a building or infrastructure. Construction differs from\nmanufacturing in that manufacturing typically involves mass production of similar items without a\ndesignated purchaser, while construction typically takes place on location for a known client.\nConstruction as an industry comprises six to nine percent of the gross domestic product of\n\ndeveloped countries. Construction starts with planning,|[citation needed] design, and financing and\n\ncontinues until the project is built and ready for use.\n\n"}, {"FileName": "computation_1.pdf", "GUID": "65e4f005-9746-47e9-a318-d6fc73a79415              ", "FileName Path": "http://msfdemo.isearch.com:18605/Demo MSF/computation_1.pdf", "FileName Version": 1, "Created DateTime": "2023-01-25 06:40:53.000", "Updated DateTime": "2023-01-25 06:40:53.000", "Created By": "Karan                                                                                               ", "Updated By": "Govind                                                                                              ", "RawOCR": "computational complexity theory is a branch of the theory of computation in theoretical computer\nscience that focuses on classifying computational problems according to their inherent difficulty,\nand relating those classes to each other. A computational problem is understood to be a task that is\nin principle amenable to being solved by a computer, which is equivalent to stating that the problem\nmay be solved by mechanical application of mathematical steps, such as an algorithm.\n\nUSER JOURNEY\n\n&O O89 &\noa\u201c \u00a9 ;\n\nMessaging Platform\n\nNatural Language Processing\n\n> SharePoint\n\n3 Party Applications\n\nSearch Document:\nFind in Corporate cam |p\n\nTraverse to a Project Folder\n\n"}, {"FileName": "community based child protection.pdf", "GUID": "f50ee95e-4377-465f-808d-d06d1fcdf7b8              ", "FileName Path": "http://msfdemo.isearch.com:18605/Demo MSF/community based child protection.pdf", "FileName Version": 1, "Created DateTime": "2023-01-25 06:40:53.000", "Updated DateTime": "2023-01-25 06:40:53.000", "Created By": "Pranav                                                                                              ", "Updated By": "Arun                                                                                                ", "RawOCR": "For situations that do not warrant immediate reporting to CPS, CPS may refer the\nfamilies to community\n\nbased Child Protection Specialist Centres (CPSCs), for ongoing support. Examples inclu\nde cases in which there was inappropriate or excessive discipline, but caregivers were\nwilling to receive help and improve on their parenting methods. More information on CP\nSCs is provided in Chapter Six. For families facing high levels of emotional and econo\nmic stress, which may adversely impact CYPs in the future, CPS may refer the familiest\no Family Service Centres (FSCs) and other social service agencies. Examples of such ca\nses will include families who need caregiving support, financial assistance or counsel\nling to better cope with stressors and provide adequate care for CYPs. When suspected\nchild abuse by a family member is reported to CPS and the case is taken up, a social i\nnvestigation is initiated. The police may concurrently undertake a criminal investigat\nion when a criminal offence is reported to have taken place or suspected to have taken\nplace. A Child Protection Officer (CPO) is assigned to the case.\n\nA: THE CHILD PROTECTION SYSTEM\n\nChild protection concerns operate on a continuum, with corresponding responses from either the\ncommunity, more specialised partners or the State. Generally, a more serious concern will necessitate\nhigher levels and more intrusive interventions, with the State stepping in when warranted.\n\nSTATUTORY + Serious injury, severe neglect, sexual abuse\n\nMILE\nPROTECTION + MSF Child Protective Service (CPS),\n\nNTERVENTION law enforcement agencies\n\n+ Neglect, excessive or inappropriate\ndiscipline, inadequate medical care\n\n+ Community Based Child Protection\nSpecialist Centres (CPSCs), Farnily\nViolence Speciatist Centres (FVSCa)\n\n+ High family stress,\nemotional and economic\n\nCOMMUNITY BASED SERVICES stress. pre incidence fam\n\n+ Community agencies\n\nDiagram | Continuum of Child Protection Intervention and Communty Baved Service\n"}, {"FileName": "Claims-Based Identity for Windows.pdf", "GUID": "8010c1f2-74d8-4a8c-8de2-c6bb5346809e              ", "FileName Path": "http://msfdemo.isearch.com:18605/Demo MSF/Claims-Based Identity for Windows.pdf", "FileName Version": 1, "Created DateTime": "2023-01-25 06:40:54.000", "Updated DateTime": "2023-01-25 06:40:54.000", "Created By": "Rajesh                                                                                              ", "Updated By": "Karan                                                                                               ", "RawOCR": "\u20183 DavidChappell\n\n& Associates\n\nCLAIMS-BASED IDENTITY FOR\nWINDOWS\n\nTECHNOLOGIES AND SCENARIOS\n\nDAVID CHAPPELL\n\nFEBRUARY 2011\n\nSPONSORED BY MICROSOFT CORPORATION\nCONTENTS\n\nUnderstanding Claims-Based Identity .............sssssssssesssssesseeessesssesseeesesssessneeseseasseeeseesssesseeeseeseeseneees 3\nThe Problem: Working with Identity in Applications..........ccccecesceceeeeseeseeeeseeeeeeeseeecseeaeeeeseeaeeeeesaeeeteetateee 3\nThe Solution: Claims-Based Identity .........cceceecsseeeeeeseeeeeecseeeeeeeseeeesesaeeeesesaeeeesesaeeeseesaseessesaseesesateeteesaeees 4\n\nClaims, TOKENS, AN STSS....ccccsccessesscessesscessessesscsssesscsssesecsesessceseascsssessesesesseseceessaecseseaseneseaseneseaseneseasens 4\nIdentity Providers and Identity LiDAries ........cccccssscesesssseesesseseeseneeeeeecseeseeecsecseecsesaseecseseseesesaseeeetaeee 5\nUsing Multiple Identity Providers ........:cscccsssceesseseecesesseeececsceecsesseeecsesaceecsesaeeecsesaseessesaseessesaseeseesaaees 7\nFederation Provider ......ccccccccsesssseseesessssesescsesssesescssssssescscssssesesessssasssescscssesesesesessesesesesessaseseseseesasesege 8\n\nImplementing Claims-Based Identity: Microsoft Technologies\n\nWINCOWS LiVe ID oo... ete cece eeeeeeeeeeeeeececeseesesececesessesecesesesseseeeeesesssseeeeesessesseesesesseeeeeesesseeeeeeenesagegs 11\nActive Directory Federation Services 2.0........ccssecesssceseeeeseeeeeeseeeeseeseecsesseeeesesaeeesesaeeesaesateessesateeseeeaeee 11\nWindows Azure AppFabric Access Control ........:cccecssceseeseseeeeeeeseeeeseeeeeecsesaeeesesaesecsesaeeessesateessesateeseeeaeee 12\nWindows Identity FOUNGatION .......eceeeeeesesceceeeeseeeeseeseeeeseeaeeeeseeacsecsecaesecsesaesecsesaeeesesateesaesaseetsesateesaeeatee 13\n\nUsing Claims-Based Identity: Scenarios ..\n\nOn-Premises SCOMariOS ........cccccccseccesssseseesssceecsesseeecsessececseseasecseseacesseseasecseseasesseseasesseseaeeseaseaeeseaseseeseasagee 14\nAccessing an Enterprise Application .......cccscsscsccssssescsssseescsssseeeceesceecseceeeecsesaseecseseeeecsesaseesaeeeseesaeeats 14\nAccessing an Enterprise Application via the INt@rnet ........:.ccsseccssseeceseeseeeeseeeeeeceeseeecseeeeeecaeeeeeeeneeaes 15\nProviding Single Sign-On to an Enterprise Application in Another Organization ........1scceceseeseeeeeeee 16\n\nClOUd SCENATIOS oo... eee eee ees ee cece esses eeeeeseececeseesesececesesseseeesesesasseceeesesssseeesesesseseeesesesseseeeeseseseeeeeesaeegegs 19\nProviding Single Sign-On to an Enterprise Application in the ClOUG........:cccssccseseeeeeeteeseteeeeeeteeaeeee 19\nProviding Single Sign-On to a SaaS Application ......ccccsseccecssseseeeeseeseeeeseeeceecseeeceecseeeceesaseeseesateesnesaeee 20\nAllowing Logins with Facebook, Google, and Other Cloud Identity Providers .......:ccssseeseeeeteeeee 22\n\nCONCIUSION........cscssscssssssssssssssssssssssssessessessessessessessessessussessessessessessessessessessessesseseesenseeseessesenseesensensensanses 24\nAbout the Author....\n\nUNDERSTANDING CLAIMS-BASED IDENTITY\n\nFor people who create applications, working with identity traditionally hasn\u2019t been much fun. First, a\ndeveloper needs to decide which identity technology is right for a particular application. If the application\nwill be accessed in different ways, such as within an organization, across different organizations, and via\nthe public Internet, one identity technology might not be enough\u2014the application might need to support\nmultiple options. The developer also needs to figure out how to find and keep track of identity\ninformation for each of the application\u2019s users. The application will get some of what it needs directly\nfrom those users, but it might also need to look up other information in a directory service or someplace\nelse. IT administrators must also be involved to configure this software correctly. Add the cloud to the\nmix, and things get even more complicated.\n\nThis is all more complex than it needs to be. Why not create a single interoperable approach to identity\nthat works in pretty much every situation, both on-premises and in the cloud? And rather than making\napplications hunt for identity information, why not make sure that this single approach lets users supply\neach application with the identity information it requires?\n\nClaims-based identity achieves these goals. It provides a common way for applications to acquire the\nidentity information they need about users inside their organization, in other organizations, and on the\nInternet. It also provides a consistent approach for applications running on-premises or in the cloud.\n\nTaking advantage of claims-based identity requires developers to understand how and why to create\nclaims-based applications. It also requires infrastructure software that applications can rely on. This\noverview describes the basics of claims-based identity, then looks at how a group of Microsoft\ntechnologies help make this world a reality. Those technologies are Active Directory Federation Services\n(AD FS) 2.0, the Windows Azure AppFabric Access Control service (ACS), and Windows Identity Foundation\n(WIF).\n\nTHE PROBLEM: WORKING WITH IDENTITY IN APPLICATIONS\n\nSometimes, working with identity is simple. Think of a Windows application that doesn\u2019t need to know\nmuch about its users, for example, and that will be accessed only by people within a single organization.\nThis application can just rely on Windows Integrated Authentication (WIA), which uses Kerberos under the\ncovers. Kerberos is implemented as part of Active Directory Domain Services (AD DS, originally known as\njust \u201cActive Directory\u201d), and it provides a way to authenticate users and convey basic information about\nthem. Or suppose you\u2019re creating an application that will be accessed solely by Internet users. Again, the\ncommon approach to handling identity is straightforward: just require each user to supply a username\nand password.\n\nYet the requirements for modern applications are rarely this simple. What if you need more information\nabout each user than is provided by either Kerberos or a simple username and password? Your\napplication will now need to acquire this information from some other source, such as AD DS, or keep\ntrack of the information itself. Or suppose the application must be accessed both by employees inside the\norganization and by customers via the Internet\u2014what now? Should the application support both Kerberos\nand username/password-based logins? And what about the case where you'd like to let users from a\nbusiness partner access this application without requiring a separate login? This kind of access can\u2019t be\naccomplished very well with either Kerberos or username/password logins\u2014more is required.\nThe right solution is to have one approach to identity that works in all of these scenarios. To be effective,\nthis single approach must be based on widely recognized industry standards that interoperate across both\nplatform and organizational boundaries. But standards alone aren\u2019t enough. The solution also needs to be\nwidely implemented in products from multiple vendors and be simple for developers to use. This unified,\nbroadly supported approach is exactly what claims-based identity is meant to provide.\n\nTHE SOLUTION: CLAIMS-BASED IDENTITY\n\nClaims-based identity is a straightforward idea, founded on a small number of concepts: claims, tokens,\nidentity providers, and a few more. This section describes the basics of this technology, starting with a\nlook at these fundamental notions.\n\nBefore launching into this description, however, there\u2019s an important point to make. While this paper\nfocuses on the mechanics, using the technology described here can require more, such as business\nagreements between different organizations. Addressing the technical challenges is essential, but they\u2019re\nnot always the whole story.\n\nClaims, Tokens, and STSs\n\nWhat is an identity? In the real world, the question is hard to answer\u2014the discussion quickly veers into\nthe metaphysical. In the digital world, however, the answer is simple: A digital identity is a set of\ninformation about somebody or something. While all kinds of entities can have digital identities, including\ncomputers and applications, we\u2019re most often concerned with identifying people. Accordingly, this\noverview will always refer to things with identities as \u201cusers\u201d.\n\nWhen a digital identity is transferred across a network, it\u2019s just a bunch of bytes. It\u2019s common to refer to a\nset of bytes containing identity information as a security token or just a token. In a claims-based world, a\ntoken contains one or more claims, each of which carries some piece of information about the user it\nidentifies. Figure 1 shows how this looks.\n\nToken\n\nExample Claims\n\n~ Name\n\u00bb Role\n\n~ Age\n\nFigure 1: A token contains claims about a user along with a digital signature that can be used to verify\nits issuer.\n\nClaims can represent pretty much anything about a user. In this example, for instance, the first three\nclaims in the token contain the user\u2019s name, an identifier for a role she belongs to, and her age. Other\ntokens can contain other claims, depending on what\u2019s required. A claim might also indicate the user\u2019s\nright to do something, such as access a file, or restrict some right, such as setting an employee\u2019s\npurchasing limit. And while it\u2019s common today to use tokens defined with the XML-based Security\nAssertion Markup Language (SAML), this isn\u2019t required. Web applications might use a simpler approach\ncalled Simple Web Token (SWT), for example.\n\nTo verify its source and to guard against unauthorized changes, a token\u2019s issuer digitally signs each token\nwhen it\u2019s created. As Figure 1 shows, the resulting digital signature is carried as part of the token.\n\nBut who issues tokens? In a claims-based world, tokens are created by software known as a security token\nservice (STS). Figure 2 illustrates the process.\n\n2) Authenticate 3) Get information\nuser about user\n\nN NX d\nAccount/\n\nAttribute Store\n\n4) Create and\nreturn token\n\n1) Request\ntoken\n\ni,\nUser\n\nFigure 2: A user acquires a token containing some set of claims from an STS.\n\nIn a typical scenario, an application working on behalf of a user, such as a Web browser or some other\nclient, asks an STS for a token containing claims for this user (step 1). Various protocols can be used to\nmake this request, but however it\u2019s done, the STS authenticates the user in some way, such as by\nvalidating her Kerberos ticket or checking her password (step 2). This lets the STS be certain that the user\nis who she claims to be.\n\nThe request sent to an STS typically contains a URI identifying the application this user wishes to access.\nThe STS then looks up information about both the user and the application in a database (step 3). As the\nfigure shows, this database maintains account information and other attributes about users and\napplications. Once the STS has found what it needs, it generates the token and returns it to the requester\n(step 4).\n\nIdentity Providers and Identity Libraries\n\nClaims, tokens, and STSs are the foundation of claims-based identity. They\u2019re all just means to an end,\nhowever. The real goal is to help a user present her digital identity to an application, then let the\napplication use this information to make decisions. Figure 3 shows a simple picture of how this happens.\n4) Use claims in token\n\nIdentity Provider (IdP)\n\n3) Verify token\u2019s\nsignature and\ncheck whether\n\nthis STS is trusted\n\n\\\n\nTrusted STSs\n\n2) Submit\ntoken\n\n1) Authenticate user,\nthen return token\n\ni\ni f\nUser\n\nFigure 3: A browser or other client can acquire a token from an STS, then present this token and the\nclaims it contains to an application.\n\nAs the figure shows, a Web browser or other client acting on behalf of a user gets a token for a particular\napplication from an STS (step 1). Once it has this token, the browser or client sends it to the application\n(step 2), which is configured with a list of one or more trusted STSs. To process the token, the application\ndepends on an identity library, a reusable set of code for working with tokens and the protocols that\nconvey them. This library verifies the token\u2019s signature, which lets the application know which STS issued\nthe token, then checks whether this STS is on the trusted list (step 3). If the application does trust the STS\nthat issued this token, it accepts the token\u2019s claims as correct and uses them to decide what the user is\nallowed to do or in other ways (step 4).\n\nIf the token contains the user\u2019s role, for example, the application can assume that the user really has the\nrights and permissions associated with that role. Since the user was required to authenticate herself to\nget this token, the application doesn\u2019t need to authenticate her again. (In fact, because it relies on the\nclaims in the token, an application is sometimes referred to as a relying party.)\n\nNotice an important difference between what\u2019s happening here and the way that applications frequently\nhandle identity: Rather than requiring the application itself to authenticate the user, claims-based identity\nrelies on the STS to do this. This gets developers out of the business of authenticating users, something\nthat definitely counts as progress. All an application needs to do is determine that the token a user\npresents was created by an STS this application trusts. How the user proved its identity to this STS\u2014with a\npassword, a digital signature, or something else\u2014isn\u2019t the application\u2019s problem. This lets the application\nbe deployed unchanged in different contexts, a significant improvement over the usual situation today.\n\nAlthough it\u2019s not shown in the figure, there\u2019s an essential first step before any of this can happen: An\nadministrator must configure the STS to issue the right claims for this user and this application. Without\nthis, the STS likely can\u2019t create a token containing the claims that the application needs. While doing this\nmight seem like a burden, the reality is that this information must also be configured in the non-claims-\nbased world. The big difference is that now the claims are all in one place, accessible through the STS,\nrather than spread across different systems.\n\nFigure 3 also illustrates another important concept, which is that an STS can be owned by some identity\nprovider (IdP). Sometimes called an issuer, the identity provider is what stands behind the truth of the\nclaims in the tokens this STS creates. In fact, this is why the contents of a token are called \u201cclaims\u201d:\nThey\u2019re statements that this identity provider claims are true. An application that receives this token can\ndecide whether it trusts this identity provider and the claims it makes about this user.\n\nIdentity providers come in many forms. If you use a token issued by an STS on your company\u2019s network,\nfor example, the identity provider is your company. If you use a token issued by the STS provided by a\nservice on the Internet, such as Windows Live ID, Facebook, or Google, this service is acting as the identity\nprovider. But whoever the identity provider is, being able to acquire and use a token containing claims is\nuseful.\n\nTo see why, think about the pre-claims world we (mostly) live in today. In this environment, an application\ntypically gets only simple identity information from a user, such as her login name. All of the other\ninformation it needs about that user must be acquired from somewhere else. The application might need\nto access a local directory service, for instance, or maintain its own application-specific database. With\nclaims-based identity, however, an application can specify exactly what claims it needs and which identity\nproviders it trusts, then expect each user to present those claims in a token issued by one of those\nproviders. A claims-aware application is still free to create its own user database, of course, but the need\nto do this shrinks. Instead, each request can potentially contain everything the application needs to know\nabout this user.\n\nUsing Multiple Identity Providers\n\nIn many cases, a user has only one identity provider\u2014and thus one STS\u2014to choose. When you access an\napplication inside your organization, for example, the application might only accept tokens issued by your\ncompany\u2019s STS. In some situations, though, an application might accept tokens issued by multiple identity\nproviders\u2014it might trust several different STSs.\n\nFor example, think about an application on the public Internet that wishes to let its users log in using a\nFacebook identity, a Google identity, or a Windows Live ID identity. Since hundreds of millions of people\nhave accounts with these services, why not accept them? Or suppose the application wishes to accept\nidentities directly from multiple instances of Active Directory\u2014what then? Both of these situations\nrequire the application to trust multiple STSs at multiple identity providers, then to let the user choose\nwhich one he wants to use. Figure 4 shows how this looks.\n5) Use claims in token\n\nIdentity Providers (IdPs)\n\n4) Submit\ntoken\n\n3) Authenticate user,\n2) Select\nan identity v\n\n1) Access application\nand learn which STSs\n\nthen return token for ;\nit trusts\nals\n\nselected identity\nUser\n\nFigure 4: If an application accepts identities from multiple identity providers, the user can select which\none to use.\n\nIn this situation, the user accesses the application and learns which STSs it trusts (step 1). For example,\nthe application might provide a login screen that lets the user choose to use his Facebook identity, his\nGoogle identity, or his Windows Live ID identity. The user then chooses one, and his browser or other\nclient software contacts that identity provider. This provider\u2019s STS authenticates the user, perhaps by\nrequiring him to enter a username and password, then returns a token for this identity (step 3). As before,\nthis token is then sent to the application (step 4), which validates it as usual and uses the claims it\ncontains (step 4).\n\nFor some applications, accepting tokens from multiple identity providers, especially public providers,\nmakes no sense. Letting employees use their Facebook identity to log into a critical business application\ninside your company probably isn\u2019t a good idea. But there are plenty of situations where this can be\nuseful. Think of an enterprise application that must be accessible to employees, partners, and customers,\nfor example, or a consumer application on the public Internet that wishes to make login as painless as\npossible. Addressing this requirement is an important part of modern identity technology.\n\nFederation Providers\n\nIn a claims-based world, a user always initially gets her identity from an STS owned by some identity\nprovider. But suppose the application she wants to access doesn\u2019t trust this STSs\u2014what then? One\npossibility is that there\u2019s just no way for her to access this application. There\u2019s also another option,\nhowever: even though the application she wants to access doesn\u2019t trust her STS, it might trust another\nSTS that in turn trusts her STS. This approach, called identity federation, is both common and useful. With\nfederation, an identity provider offers an STS as usual, but another STS is also offered by a federation\nprovider (FP). The federation provider STS is then configured by an administrator to trust the identity\nprovider STS. Figure 5 shows how a user can provide identity information to an application when\nfederation is used.\n\nIdentity 8) Use claims in token\nProvider (IdP) Federation Provider (FP) \u2014\u2014\n\n5) Validate IdP token,\nthen create FP token\n\n~----\u00bb Trusted STS: IdP\n\nIdentity Library\n\n2) Access FP\n\n\u201cee\n\nand learn -\nwhich STSs 6) Return FP Trusted STS: FP\nis token\nit trusts\n)) Sub 7) Submit\n4) Submit\n3) Authenticate user, IdP token FP token\n\n1) Access\napplication and\nlearn which STSs\nit trusts\n\nthen return token\n\nal h,\nUser\n\nFigure 5: An STS can act as a federation provider, accepting one token and producing another.\n\nAs always, the process begins when the user accesses an application from a browser or another client,\nlearning which STSs that application trusts (step 1). Here, the application trusts only the federation\nprovider STS. The user\u2019s browser or client software then contacts that federation provider, learning which\nSTSs it trusts (step 2). In this example, the federation provider STS is configured to trust the identity\nprovider\u2019s STS, and so the user\u2019s browser or client software contacts this STS. As usual, the user is\nauthenticated in some way, then gets back an IdP token created by this STS (step 3).\n\nThis token can\u2019t be used to access the application, however, since that application doesn\u2019t trust the STS\nthat issued it. Fortunately, this token can be used to acquire a token that the application will accept. To do\nthis, the browser or client software sends the IdP token to the federation provider (step 4). The federation\nprovider validates this token, ensuring that it came from an STS it trusts. Once it determines this, it\ncreates a new token for this user (step 5), then returns this FP token (step 6). The user\u2019s software submits\nthis token to the application (step 7), which verifies that the FP token was issued by an STS that it trusts.\nThe application then uses the claims in the token as usual (step 8).\n\nFrom the user\u2019s point of view, all of these exchanges are invisible. She accesses the application without\nexplicitly logging into it, that is, she gets what\u2019s known as single sign-on. The mechanics are a little more\ncomplex, but the core idea underlying identity federation is straightforward. It is that not only\napplications can trust STSs; one STS can trust another STS as well.\n\nStep 5 in the figure is worth examining in more detail. As just described, the federation provider receives a\ntoken issued by another STS, then generates a new token for the user. But exactly what claims does this\nnew token contain? The answer depends on what the federation provider\u2019s STS is configured to do. In the\nsimplest case, it might copy every claim from the IdP token directly into the FP token unchanged. Ina\nmore realistic scenario, the federation provider STS performs claims transformation, emitting a token that\ndoesn\u2019t contain the exact set of claims that it received from the identity provider.\n\nFor example, suppose the IdP token contains a claim indicating that this user is a member of the role\n\u201cAdministrator\u201d, expressing that claim as a character string containing this English word. It\u2019s possible that\nthe application understands the administrator role, but expects the claim to be expressed as a numeric\ncode or in Chinese or in some other way. The federation provider can perform this translation, inserting a\nclaim in the correct format in the FP token it generates.\n\nClaims transformation can do other things as well. When it creates the FP token, for example, the\nfederation provider might omit claims from the IdP token that aren\u2019t meaningful to this application. Or it\nmight add claims to the FP token that aren\u2019t present in the IdP token, such as an indication of the IdP that\nissued the original token. Claims transformation is a powerful idea, and it can be used in a variety of ways.\n\nIMPLEMENTING CLAIMS-BASED IDENTITY: MICROSOFT TECHNOLOGIES\n\nImplementing claims-based identity requires several things. Identity provider STSs must be available to\nissue tokens to users. Because identity federation is common, federation provider STSs are also essential.\nAnd finally, developers will need to build claims-aware applications that know how to receive tokens and\nuse the claims they contain. Rather than having every developer write this code from scratch, it makes\nsense to provide a standard identity library that any application can use.\n\nThe rise of cloud computing adds another requirement. All three of these things\u2014an identity provider\nSTS, a federation provider STS, and an identity library\u2014should be available both on premises (e.g.,\nrunning in an organization\u2019s data center) and in the cloud. Without this, some important scenarios are\nhard to address.\n\nThe Microsoft platform for claims-based identity targets all of these options. Figure 6 summarizes the\ntechnologies it includes today.\n\nIdentity Provider Federation Provider\nSTS STS Identity Library\n\nWindows Identity \u2014\n\nCloud indows Live ID Eatividation\n\nWindows Identity\nFoundation\n\nOn-premises\n\nFigure 6: Microsoft provides cloud and on-premises technologies for an identity provider STS, a\nfederation provider STS, and an identity library.\n\n10\nIn the cloud, Microsoft provides Windows Live ID as an identity provider STS, while Windows Azure\nAppFabric Access Control provides a federation provider STS. For an identity library, applications can use\nWindows Identity Foundation (WIF, commonly pronounced \u201cDub-I-F\u201d).\n\nFor on-premises use, Microsoft makes available Active Directory Federation Services (AD FS) 2.0. As Figure\n6 shows, this technology can be used as both an identity provider STS and a federation provider STS. And\nfor an identity library, applications once again can use Windows Identity Foundation.\n\nIt\u2019s important to note that while this overview focuses on Microsoft technologies, claims-based identity is\na multi-vendor effort. Given this, there are alternative technologies from other vendors for all of the\nboxes in this figure. And because interactions among the parties are based on industry standards, the\nofferings from Microsoft and other vendors can be combined in various ways. For example, using the\nMicrosoft identity platform doesn\u2019t require relying on Windows Live ID for a cloud identity provider STS\u2014\nother providers, such as those from Google and Facebook, can also be used. Similarly, AD FS 2.0 isn\u2019t the\nonly option for on-premises STSs; WIF can work with tokens created by products from IBM and other\nvendors.\n\nThe focus here is on the Microsoft technologies, however, and the best way to understand how they fit\ntogether is to walk through scenarios showing how they\u2019re used. Before doing this, we first need to look\nat the basics of each one.\n\nWINDOWS LIVE ID\n\nWindows Live ID implements an identity provider STS in the cloud. Today, the most popular applications\nthat accept tokens issued by this STS are Microsoft offerings such as Hotmail. Any application can choose\nto accept these tokens, however\u2014it\u2019s not usable only by Microsoft itself.\n\nThe token provided by Windows Live ID contains a very simple set of claims, primarily just a globally\nunique identifier. The structure of this identifier is opaque, which means that an application can\u2019t derive\nany meaning from the identifier\u2019s content or structure. An application can use this value to recognize\nindividual users, however. For example, a Web site that accepts Windows Live ID logins might ask each\nuser for information such as his name and shipping address, then store this data along with the user\u2019s\nWindows Live ID identifier. The next time the user logs in, the application can use this identifier to look up\nhis information.\n\nACTIVE DIRECTORY FEDERATION SERVICES 2.0\n\nHaving an identity provider STS in the cloud is useful. But for enterprises, having one on-premises is much\nmore important. Business applications inside your organization probably don\u2019t let employees log in with a\nWindows Live ID, a Facebook identity, or any other token issued by an identity provider STS in the cloud.\nInstead, they require a token issued by an STS that they control.\n\nActive Directory Federation Services 2.0 can fill this role. As its name suggests, AD FS 2.0 is the follow-on\nto the original Active Directory Federation Services technology. Don\u2019t be misled by the word \u201cfederation\u201d\nin the technology\u2019s name, however. In fact, AD FS 2.0 can act as either an identity provider STS ora\nfederation provider STS. The same AD FS 2.0 instance can even act in both roles simultaneously. And since\nit\u2019s part of Active Directory, AD FS 2.0 is available to current users at no extra cost. This makes claims-\n\n11\nbased identity immediately accessible to the large number of organizations that use Active Directory\ntoday.\n\nAD FS 2.0 contains several advances over its predecessor. It supports both browsers and other clients, for\nexample, such as those built using Windows Communication Foundation (wcF)*. Also unlike the first AD\nFS release, AD FS 2.0 supports the SAML 2.0 protocol as well as WS-Federation and WS-Trust, letting it\nwork in a broader range of environments.\n\nThe AD FS 2.0 STS can be used entirely inside an organization, exposed on the Internet, or both. The\nclaims it supplies can come from Active Directory Domain Services, of course, but this isn\u2019t the only\nchoice. AD FS 2.0 also supports using SQL Server as an attribute store, that is, a source for claims, and\ndevelopers are free to create custom attribute stores as well. To help manage an organization\u2019s attribute\nstores, including Active Directory and others, Microsoft provides Forefront Identity Manager (FIM). This\ntechnology offers a way to synchronize information across different attribute stores, along with an\nidentity management portal with pre-defined workflows for password resets, group management, and\n\nmore.\n\nYet it\u2019s worth reiterating that claims-based identity doesn\u2019t require using AD FS 2.0. Any STS from any\nvendor (or even a custom-built STS) that supports standard protocols and token formats can be used. Still,\none of Microsoft\u2019s primary goals in providing AD FS 2.0 is to make widely available a fully-featured STS\nbuilt on Active Directory. Ubiquitous STSs are fundamental to making the benefits of claims-based identity\nreal.\n\nWINDOWS AZURE APPFABRIC ACCESS CONTROL\n\nIdentity federation is useful in many situations. For applications running on premises, such as a business\napplication within an enterprise, using a federation provider STS that\u2019s also on premises is often the right\nchoice. But for an application running in the cloud, using a federation provider STS that runs in the cloud is\nlikely to be better. The Windows Azure AppFabric Access Control service fills that role.\n\nACS is most commonly applied today in two scenarios:\n\nLetting an application running in the cloud accept tokens issued by multiple on-premises identity\nprovider STSs, such as AD FS 2.0. This can give on-premises users in various organizations single sign-\non to the cloud application. This is especially useful for independent software vendors (ISVs) who\nwish to allow easy access to a Software as a Service (SaaS) application by customers in many different\nenterprises.\n\nOo Letting an application running in the cloud accept identities issued by multiple cloud identity provider\nSTSs. ACS has built-in support for handling the protocols and token formats used by Windows Live ID,\nGoogle, Facebook, Yahoo, and OpenID. An application that trusts the ACS federation provider STS can\nchoose to accept identities from any of these identity providers while still being shielded from the\nidiosyncratic details of each one.\n\n\u2018Inthe jargon of identity, AD FS 2.0 supports both active and passive clients, while the first release of AD FS supported only passive clients.\n\n12\nACS also provides another important function: built-in support for claims transformation. As described\nearlier, a federation provider STS commonly emits a token whose claims differ from the IdP token it\nreceived. To help do this more intelligently, ACS includes a rules engine for defining these\ntransformations.\n\nACS lets clients request tokens using various protocols, including WS-Federation, WS-Trust, OpenID 2.0,\nand OAuth 2.0. It can accept and issue tokens in various formats as well, including SAML 1.1, SAML 2.0,\nand Simple Web Token (SWT). The technology also allows delegated authorization using OAuth 2.0, which\nprovides a controlled way for an application to act on behalf of a user.\n\nWINDOWS IDENTITY FOUNDATION\n\nWhether it\u2019s offered by an identity provider or a federation provider, an STS creates tokens containing\nclaims. Yet those tokens are useless unless applications are able to accept and use them. The goal of WIF\nis to make this easier by helping developers create claims-aware Windows applications.\n\nWIF is a set of .NET Framework classes that implement essential identity functions, such as receiving a\ntoken, verifying its signature, and accessing the claims it contains. It supports tokens created using either\nthe SAML 1.1 or SAML 2.0 formats, so it can accept tokens issued by AD FS 2.0, ACS, or STSs from other\nvendors. WIF supports various standard protocols as well, including WS-Federation and WS-Trust, and it\u2019s\nextensible, allowing other technologies to be added. For example, Microsoft provides a sample WIF\nextension that implements the OAuth 2.0 protocol with SWT tokens.\n\nEach claim is extracted into an instance of a WIF-defined Claim class, providing a consistent way for\ndevelopers to"}, {"FileName": "Civildisobedience_4.pdf", "GUID": "73d401fd-1ea8-4c9a-8d29-2454734ce187              ", "FileName Path": "http://msfdemo.isearch.com:18605/Demo MSF/Civildisobedience_4.pdf", "FileName Version": 1, "Created DateTime": "2023-01-25 06:40:54.000", "Updated DateTime": "2023-01-25 06:40:54.000", "Created By": "Bijjala                                                                                             ", "Updated By": "Pranav                                                                                              ", "RawOCR": "One of its earliest massive implementations was brought about by Egyptians against the British\n\noccupation in the 1919 Revolution. Civil disobedience is one of the many ways people have\n\nrebelled against what they deem to be unfair laws. It has been used in many nonviolent resistance\nmovements in India (Gandhi's campaigns for independence from the British Empire), in\nCzechoslovakia's Velvet Revolution and in East Germany to oust their communist governments, In\nSouth Africa in the fight against apartheid, in the American Civil Rights Movement, in the Singing\nRevolution to bring independence to the Baltic countries from the Soviet Union, recently with the\n2003 Rose Revolution in Georgia and the 2004 Orange Revolution in Ukraine, among other various\n\nmovements worldwide.\n\n"}, {"FileName": "Child Protection CPS.pdf", "GUID": "4baeb893-4ccc-4acf-8c91-d2916117a114              ", "FileName Path": "http://msfdemo.isearch.com:18605/Demo MSF/Child Protection CPS.pdf", "FileName Version": 1, "Created DateTime": "2023-01-25 06:40:54.000", "Updated DateTime": "2023-01-25 06:40:54.000", "Created By": "Amit                                                                                                ", "Updated By": "Pranav                                                                                              ", "RawOCR": "Child protection concerns operate on a continuum, with corresponding responses from ei\nther the community, more specialised partners or the State. Generally, a more serious\n\nconcern will necessitate higher levels and more intrusive interventions, with the Stat\ne stepping in when warranted. Child protection is everyone\u2019s responsibility. The State\nshould not come in prematurely to intervene. Instead, community support and outreach s\nhould first be considered to help families early. CPS will however intervene in situat\nions where there are serious child protection concerns posed to the CYP e.g. sexual ab\nuse, severe neglect and cases with serious injuries inflicted by parent/caregiver. Suc\n\nh cases must be immediately reported to CPS\n\nTs\n\nSe &\n\nThe\n\nChild\nProtection\nSystem\n\nin Singapore\n"}, {"FileName": "Child Abuse.pdf", "GUID": "5b44669f-1318-43a6-b1b0-7c29e11c658d              ", "FileName Path": "http://msfdemo.isearch.com:18605/Demo MSF/Child Abuse.pdf", "FileName Version": 1, "Created DateTime": "2023-01-25 06:40:54.000", "Updated DateTime": "2023-01-25 06:40:54.000", "Created By": "Guru                                                                                                ", "Updated By": "Pranav                                                                                              ", "RawOCR": "The immediate objectives are to ascertain the safety of the CYP and work with the CYP\nand family to put in place a plan to address the safety concerns posed to the CYP. The\nCPO will also work with the CYP, family members, significant others and professionals\nin keeping the CYP safe. A care and protection plan is drawn up with the family. The\nCPO will also help the family members and significant others understand the profession\nal concerns over the current and future harm posed to the CYP, as well as identify ser\nvices, protective factors and strengths of the family that can be tapped upon. Subsequ\nently, CPS will present its investigation findings at the Child Abuse Protection Team\n(CAPT) meeting. CAPT comprises a multidisciplinary team of professionals that include\nconsultant paediatricians and psychologists. CAPT will review CPS\u2019s investigation find\n\nings, determine the risk of harm posed to the CYP, as well as endorse the goals and th\ne service plan for the CYP and family\n\n"}, {"FileName": "the-sharepoint-mvp-guide-to-optimizing-storage-and-performance.pdf", "GUID": "93af8d54-beed-438c-8566-bcc2ccc84f0c              ", "FileName Path": "http://msfdemo.isearch.com:18605/Demo MSF/the-sharepoint-mvp-guide-to-optimizing-storage-and-performance.pdf", "FileName Version": 1, "Created DateTime": "2023-01-25 06:40:54.000", "Updated DateTime": "2023-01-25 06:40:54.000", "Created By": "Govind                                                                                              ", "Updated By": "Amit                                                                                                ", "RawOCR": "SHAREPOINT 2013 EDITION\n\nTHE SHAREPOINT MVP GUIDE\nTO OPTIMIZING STORAGE AND\nPERFORMANCE\n\nWritten by Michael Noel, SharePoint MVP\n\nMetalogix\nTHE SHAREPOINT MVP GUIDE TO OPTIMIZING STORAGE AND PERFORMANCE\n\nCONTENTS\nUnderstanding the Current State of SharePoint and Out-of-Control Storage Growth ............ 3\nMicrosoft Guidance on Storage Sizes and Limitations........scsssssssssseessssssseeeeusssssesseesessssssed 6\n\nA More Efficient Route to Improving SharePoint Storage Performance.\n\nCOMCIUSION ..sssssssssssessssssssseesseesssssssssseeeseesseusssssssseeeeseesuussssssseeeeeessuusssssssseesesensussssseesaeeensusussssesseeeesetscunssssoseeee 12\n\nAbout Metalogix.\n\nCopyright \u00a9 2014 Metalogix International GmbH. All rights reserved. Metalogix is a trademark of Metalogix International GmbH. StoragePoint is a registered\n\ntrademark of BlueThread Technologies, Inc. Microsoft, Exchange Server, Microsoft Office, SharePoint, and SQL Server are registered trademarks of Microsoft\nCorporation.\n\nTHE SHAREPOINT MVP GUIDE TO OPTIMIZING STORAGE AND PERFORMANCE\n\nUNDERSTANDING THE CURRENT STATE OF SHAREPOINT AND OUT-OF-\nCONTROL STORAGE GROWTH\n\nSharePoint is an invaluable tool for document management and collaboration and the ideal platform for\nweb-based environments, including intranets and extranets. As such its popularity has grown exponentially,\n80 percent of Fortune 500 companies use SharePoint\u2019 and the latest data suggests that Microsoft adds more\nthan 20,000 users each day. SharePoint\u2019s document management capabilities are of particular interest, with\nenhanced document and information controls that allow for a better experience. In fact, according to a survey\nby Collaboris? , users cite document management as the major use of SharePoint within their organizations.\n\nWith this growth, however, comes storage challenges. Despite recent improvements in the way SharePoint\nstores documents, SharePoint remains a poor choice for storing the unstructured content like documents,\nimages and videos that dominates SharePoint. If not addressed, these storage limitations can lead to\nperformance issues\u2014making it even more important to implement controls on SharePoint content growth\nand devise a plan to manage it.\n\nThis whitepaper will explore SharePoint storage constraints and suggest steps that organizations can take to\nlimit the impact that content growth has on their mission-critical environments.\n\nHOW RAPID SHAREPOINT GROWTH INHIBITS PERFORMANCE\n\nSimply put, the larger the content - rich media, large repositories of content, etc. - the higher the performance\nrequirement. Subsequently, environments that grow too large have a negative impact on overall performance.\nPages can take longer to load and users quickly tire of waiting for content to refresh, which, in turn, has a\nnegative effect on platform adoption.\n\nThese storage concerns stem from the fact that SharePoint demands a high degree of performance from its\nstorage infrastructure. These performance metrics are directly related to the total amount of space that is\ntaken up by the databases. Specifically, Microsoft has determined that SharePoint content databases typically\nuse between 0.05 IOPS/GB and 0.2 IOPS/GB. For optimum performance, Microsoft recommends 0.5 IOPS/\nGB. This means that any disk infrastructure must be robust enough to support a fairly high IOPS total. The\nbigger the data store, the higher the requirements. Table 1 illustrates how many IOPS are required for various\ncontent database sizes.\n\n'MSDynamicsWorld.com, 2012\n\n? Great SharePoint Survey, Collaboris,\n\nTHE SHAREPOINT MVP GUIDE TO OPTIMIZING STORAGE AND PERFORMANCE\n\nTable 1: IOPS Required for Various Data Sizes\n\nTotal Content Database Size\n\nIOPS required for minimum per-\n\nIOPS required for optimal perfor-\n\nformance (0.2 IOPS/GB)\n\nmance (0.5 IOPS/GB)\n\n500GB 100 250\n1TB 200 500\n27TB 400 1000\n5TB 1,000 2,500\n\n20TB 4,000 10,000\n\nConsidering that many disk drives can provide 150-300 IOPS apiece, it is obvious that a large number of\ndisk spindles are required to support a growing environment. If the number of IOPS doesn\u2019t match the\ngrowth, there will be a gradual degradation in performance over time. In order to keep up with the growth,\nadministrators may need to over-provision disks to maintain the recommended number of IOPS, ending up\nwith a larger number of disks with unused capacity on each. This is especially true today as the average disk\nsize of a disk is increasing without an equivalent matching rise in the amount of IOPS capable per each disk.\n\nFor example, Table 2 shows sample disk architecture options that would provide approximately 1000 IOPS.\nConsidering that the maximum recommended IOPS required for 2TB of storage is 1000 IOPS, many of these\nconfigurations result in a large amount of wasted space: up to 7TB in total. So we can see that planning\nthe disk infrastructure is highly dependent on the total number of IOPS per-disk, the RAID chosen, and the\nnumber of disks in the drive set.\n\nTable 2: Example Disk Volumes to Achieve 1000 IOPS\n\nDrive Type | IOPS per Disk RAID Capacity (GB) # Disks Usable Max IOPS\nper Disk Capacity (GB)\n7.2k RPM SATA 90 RAID 0+1 1024 14 7168 1008\n10k RPM SATA 130 RAID 0+1 1024 10 5120 1040\n10k RPM SAS 140 RAID 0+1 1024 10 5120 1120\n15k RPM SAS 180 RAID 0+1 1024 8 4096 1152\n7.2k RPM SATA 90 RAID 5 512 20 9216 1026\n10k RPM SATA 130 RAID 5 512 14 6144 1037.4\n10k RPM SAS 140 RAID 5 512 14 6144 1117.2\n15k RPM SAS 180 RAID 5 512 10 4096 1026\n\nTHE SHAREPOINT MVP GUIDE TO OPTIMIZING STORAGE AND PERFORMANCE\n\nHOW RAPID SHAREPOINT GROWTH CHALLENGES IMPACT STORAGE\n\nWhile growing SharePoint environments can inhibit performance, rapid growth can also have an immediate\nimpact on storage. To understand why, let\u2019s look at how information is stored in SharePoint.\n\nSharePoint runs as a three-tiered application, as shown in Figure 1. The first tier, the web tier, is the tier that\nruns Internet Information Services (IIS) and serves up web content to clients directly. This is the tier that the\nclients connect directly to via HTTP or HTTPS and is often load-balanced for availability.\n\nFigure 1: Three Tiers of SharePoint Architecture\n\nThe second tier is a service application tier, which is used to run the multiple services that are consumed by\nnumerous systems within a SharePoint environment, both within the immediate farm and sometimes outside\nof the farm itself. These service applications include Search, Excel Services, PerformancePoint, the Managed\nMetadata Service, and the User Profile Synchronization Service.\n\nThe third SharePoint tier is the data tier, where all the information that is shared and managed within SharePoint\nis kept. With the exception of search indexes, this information is stored within Microsoft SQL Server databases.\nBy default, this includes all content within SharePoint, both structured, such as the metadata and contextual\ninformation, and unstructured, such as the actual documents themselves. These unstructured objects, known\nas Binary Large Objects (BLOBs), degrade performance and create SharePoint database sprawl, which is hard,\ntime consuming and expensive to manage.\n\nThese content databases are simply SQL databases used for storage of the content that is created and\nconsumed in the SharePoint environment.\n\nTHE SHAREPOINT MVP GUIDE TO OPTIMIZING STORAGE AND PERFORMANCE\n\nSHREDDED STORAGE IN SHAREPOINT 2013 ATTEMPTS TO PUT THINGS RIGHT\n\nPrior to the release of SharePoint 2013, SharePoint stored every version of every file as a full-sized BLOB, which\nled to significant database size growth. SharePoint 2013, on the other hand, introduced a concept known\nas \u201cShredded Storage\u2019, in which only the first version of a document is stored as a full-sized BLOB, and each\nsubsequent version stores only the changes made between versions. This reduces the steepness of the total\nstorage growth curve for SharePoint and also cuts down on data redundancy.\n\nOne disadvantage to shredded storage, however, is the fact that there is a performance cost associated with\nreassembling the BLOB versions. Natively, SharePoint will always serve up BLOBs directly from SQL Server, a\nprocess that can be up to two-times slower than accessing data from other storage mechanisms. In addition,\nshredded storage cannot be applied retroactively. In other words, documents that are migrated from\nSharePoint maintain their full BLOB sizes for older versions.\n\nDespite the introduction of shredded storage, environments that measure their SharePoint storage tier sizes\nin terabytes are still common. In fact, this has become the norm for even mid-sized or smaller organizations.\nBecause of the aforementioned performance issues, as well as the need to house the data, organizations must\npay close attention to how they architect the data tier and how they manage their data. It is important to\nunderstand Microsoft's official and updated guidance on this topic as well which we'll look at next.\n\nMICROSOFT GUIDANCE ON STORAGE SIZES AND LIMITATIONS\n\nThe guidance from Microsoft on SharePoint storage restrictions and size limitations can be confusing and\nis further complicated by the fact that the information was last updated in SharePoint 2010 Service Pack 1.\nBecause the design of a storage environment for SharePoint is tightly intertwined with this information, it is\ncritical to understand Microsoft's guidance.\n\nCURRENT LIMITATIONS AND RESTRICTIONS\n\nThere are a few key limitations and restrictions of SharePoint components that factor into storage design\nfor SharePoint 2013. Within a SharePoint farm content is housed within logical groupings known as web\napplications. Each SharePoint farm can house up to 500 content databases. While there is room for expansion\nat the content database tier, (each content database can house up to 2500 non-personal site collections) a\nsingle site collection can exist only in one content database - it cannot span multiple content databases.\n\nIn some cases, organizations may choose to keep all or the majority of their content within a single site\n\nTHE SHAREPOINT MVP GUIDE TO OPTIMIZING STORAGE AND PERFORMANCE\n\ncollection. This practice can lead to very large content database sizes, which complicates storage management\nplanning and can lead to the performance issues previously indicated. Indeed, best practices for SharePoint\nenvironments generally dictate that content should be distributed across a document management\nenvironment in multiple site collections that are stored in multiple content databases, as illustrated in Figure\n2. This can help improve performance by decreasing the density of the number of rows within the content\ndatabase, which can have a positive impact on performance.\n\nFigure 2 shows a sample organization that deployed multiple site collections for each business unit and\ndistributed their data across content databases in that manner, allowing for smaller overall databases and\navoiding situations where all content is stored in a single database.\n\nFigure 2: Distributing Content across Multiple Content Databases\n\nTHE SHAREPOINT MVP GUIDE TO OPTIMIZING STORAGE AND PERFORMANCE\n\nWhile this concept is ideal, it is not always followed and comes with some challenges. For example, Microsoft\nmakes the default navigation structure at the site collection level, so any type of menu-based navigation\nacross site collections must be created by the custom development of the master pages in SharePoint. For this\nand other reasons related to natural organic growth of the SharePoint environment, many organizations may\nend up with very large content database sizes. This becomes problematic given Microsoft's recently updated\nguidance on database sizes and the role this plays in the architecture of the data tier.\n\nMICROSOFT GUIDANCE ON CONTENT DATABASE SIZES\n\nWith the release of Service Pack 1 for SharePoint Server 2010 and SharePoint Foundation 2010, Microsoft\nupdated its recommendations for content database sizes. These recommendations also carry over to\nSharePoint 2013 environments. Previous recommendations capped database sizes at 200GB for each content\ndatabase for collaboration sites and 1TB for document archives. The maximum recommended size has been\nexpanded to a whopping 4TB for normal scenarios and unlimited database sizes for records management or\narchive scenarios. The only hard limitation then becomes the restriction to a maximum of 60 million objects\nin any single content database. This represents a large amount of items, but is not an unprecedented number\nin some larger SharePoint deployments.\n\nThe change in Microsoft's upper recommendation limits for content database sizes in Service Pack 1 was a\nresult of usage reassessment and the addition of the ability to recover sites that have been deleted from a\nnewly created \u201cSite Recycle Bin\u201d What Microsoft found is that one of the main reasons that administrators\nrestore databases is to recover deleted sites. Since that is no longer a major issue post-2010 SP1, Microsoft\nupdated their guidance and started to allow for massive database sizes. It's important to note that the\nprevious 200GB size \u201climitation\u201d was not an actual limitation at all, and SQL would allow databases that were\nmuch larger than that. Organizations with massive pre-2010 SP1 databases, however, found themselves in a\ntricky spot and were forced to recover an entire database simply to restore a single deleted site.\n\nThis doesn\u2019t mean that we advocate that organizations should immediately go out and create massive content\ndatabases. In fact, very large content databases can still have a negative impact on the overall functionality\nand the design possibilities available. For example, high availability and disaster recovery can be complicated\nby massive database sizes, since technologies such as SQL Mirroring and Log Shipping do not work well on\nlarger databases. Traditional restore techniques can also take too long in these scenarios. It can also be more\ndifficult to move data around to rebalance the load on SQL Servers when databases are extremely large.\n\nA MORE EFFICIENT ROUTE TO IMPROVING SHAREPOINT STORAGE\nPERFORMANCE\n\nThe architectural limitations of SharePoint\u2019s data tier coupled with its high disk IOPS requirements is driving\norganizations to seek new ways of improving SharePoint performance without investing significant funds in\ntheir storage infrastructure.\n\nSharePoint storage can be expensive business. Organizations must factor in the cost of high-performance SAN\nand NAS infrastructures combined with the lOPS requirements of dealing with a large document management\nrepository. These costs alone can dwarf the other budget items required to implement SharePoint. Clearly,\norganizations need a better way to manage SharePoint performance without the massive investment at the\nstorage tier.\n\nOne simple way to improve the performance of the data tier is to break a content database into multiple\npieces. This can be done by creating multiple distinct files for each content database within SQL Management\nStudio. These files can then be distributed across different storage volumes, as illustrated in Figure 3. If the\ndatabase files are distributed across separate disk aggregates, better performance is achieved at the data\ntier resulting in faster page loads. Administrators don\u2019t need to span multiple disk aggregates to get better\nperformance, since multiple files for each database can result in better parallelization of the database traffic.\n\nFigure 3: Distribution of Content Database Files across Volumes\n\n| i a cl\n\nTHE SHAREPOINT MVP GUIDE TO OPTIMIZING STORAGE AND PERFORMANCE\n\nIn Figure 3, a total of four files were created for each database. For example, DB-A is broken into four files\ndistributed across four volumes, as is DB-B. In addition, it is important to do the same for the SQL tempdb\nfile, which is a critical file for SharePoint performance. As illustrated in Figure 3, the rough calculation used to\ndetermine how many files to create is directly related to the number of physical processors in use on the SQL\nServer used by SharePoint. In this case, there are four physical processors, which is why the total number of\nfiles created is four. You may run into guidance that dictates that the number of files created should equal\nthe number of processor cores, but this guidance originated with SQL 2000 testing and is not as accurate for\ntoday\u2019s modern multi-core processors. There is no perfect equation for this process and, since creating too\nmany files does not necessarily lead to performance issues, the best practice in this case is to distribute by\nnumber of physical processors, not the number of cores.\n\nEach of the storage partitions that house SharePoint content should also be write-optimized, to allow them\nto handle the increased number of write operations that are performed. The ideal RAID level for SharePoint\ncontent is RAID 0+1, which ensures the highest performance and availability options. RAID 5 can be a cost-\neffective option that results in larger drive sizes, but administrators should be cautious about ensuring that\nthe number of IOPS required is maintained as RAID 5 does not provide the same level of performance as RAID\n0+1.\n\nIMPROVING STORAGE PERFORMANCE WITH REMOTE BLOB STORAGE (RBS)\n\nOne possible option for improving SharePoint storage is to take advantage of technologies that allow the\nactual documents and files to be stored outside of the content database, thereby keeping the overall size\nmuch lower. This is known as Remote BLOB Storage (RBS). As discussed earlier, a BLOB is the format in which\nall documents and files are stored within the content databases. This type of data is known as unstructured\ndata and SQL Server has not traditionally been the best place to store this type of content. SQL Server works\nbetter if it is given structured data to work with, such as metadata and the context of files. Using a process\nsuch as RBS, organizations can extract BLOBs from the SQL databases and store them on alternative storage, as\nshown in Figure 4. This approach provides the benefit of managing content from within SharePoint, without\nincurring the performance and storage hit associated with physically storing BLOBs in a SQL Server database.\n\nFigure 4: Understanding Remote BLOB Storage (RBS)\n\nRBS Content DB\n\n=> w/o BLOBs\n\nContent DB with BLOBs Alternative Storage\n\nTHE SHAREPOINT MVP GUIDE TO OPTIMIZING STORAGE AND PERFORMANCE\n\nSince the majority of content in the average SharePoint content database is typically composed of BLOB files,\nby storing content outside of the SQL content database, the size of the database itself can be reduced up to\n95 percent. This opens up a myriad of different architectural options for SharePoint, such as the ability to tier\nor segment the storage, or the ability to create complex archiving policies.\n\nOut-of-the-box, Microsoft provides a tool \u2014 \u201cFILESTREAM provider\u201d \u2014 that allows for RBS to be implemented\nwith SharePoint, but there are some significant limitations to FILESTREAM provider:\n\n+ It lacks basic features for enterprise deployments, including:\no No user interface\no Lack of support for remote storage\no No multi-threading for garbage collection\n\n+ RBS does not bypass SQL Server for BLOB processing; it pulls the BLOB out and redirects right back to SQL\nServer using FILESTREAM Column Type\n\n+ Backing out of FILESTREAM is difficult and time consuming\n\nFor this reason, it is recommended to use a third-party tool that can take advantage of the RBS features. These\ntools provide additional functionality well beyond that provided by the FILESTREAM provider, which was\nreleased by Microsoft as a sample provider, not as a fully baked solution. Additional functionality provided\nby third-party tools include using RBS to take advantage of storage tiers that may be remote, such as cloud\nstorage, slower and cheaper SATA disk volumes, and even keeping the data on file servers while accessing it\nin SharePoint via RBS, a concept known as a Shallow File Copy.\n\nAn additional advantage of using RBS to store the BLOBs on an alternate storage location is that it opens up\nthe environment for the use of data de-duplication options that were previously not accessible when the\nBLOBs were stored within the content databases. Many SAN vendors offer de-duplication at the block level\nfor content within their flat file volumes, so if data is repeated multiple times, the repetitive part of that data is\nonly stored once. Since one version of a document may be 90 percent similar to the last version in SharePoint,\nby storing the nearly identical BLOBs on the de-duplicated SAN volume, the overall space taken up by the files\nthemselves can be reduced. Check first with your SAN vendor to see if this is supported, but it is an option that\nprovides a way to deal with large document management environments.\n\nTHE SHAREPOINT MVP GUIDE TO OPTIMIZING STORAGE AND PERFORMANCE\n\nCONCLUSION\n\nBecause of SharePoint\u2019s robust disk requirements of up to 0.5 IOPS per GB, organizations with rapidly growing\nSharePoint environments are trapped between limiting SharePoint adoption and use or needing a significant\ninvestment in SharePoint specific storage. Fortunately for these organizations, there are methods that can\nrein-in storage growth while maintaining performance.\n\nThese methods include simple techniques such as creating multiple files for each SharePoint content\ndatabase, but they can also include advanced options such as RBS, which drastically reduces the size of\nSharePoint content databases, allowing them to maintain their speed requirements while storing the BLOBs\nin an alternative, cheaper location.\n\nOrganizations planning for growth within their SharePoint environment should also consider these options\u2014\nor run the risk of storage performance issues eventually sabotaging their plans for SharePoint.\n\nABOUT METALOGIX\n\nMetalogix provides industry-recognized management tools for mission-critical collaboration platforms.\nThese tools are engineered and supported by experts committed to the rapidly evolving deployment and\noperational success of our clients.\n\nMetalogix\u2019world-class tools and client service have proven to be the most effective way to manage increasingly\ncomplex, and exponentially growing metadata and content across collaboration platforms.\n\nFor over a decade, Metalogix has developed the industry's best and most trusted management tools for\nSharePoint, Exchange, and Office 365, backed by our globally acknowledged live 24x7 support. Over 14,000\nclients rely on Metalogix Tools every minute of every day to monitor, migrate, store, synchronize, archive,\nsecure, and backup their collaboration platforms.\n\nMetalogix is a Microsoft Gold Partner, an EMC Select Partner, and a GSA provider. Our Client Service division\nof certified specialists is the winner of the prestigious NorthFace ScoreBoard Award for World Class Excellence\nin Customer Service.\n\nMETALOGIX\n5335 Wisconsin Ave NW, Suite 510, Washington DC 20015\nsales@metalogix.com | www.metalogix.com | 1.202.609.9100\n\n"}, {"FileName": "TeBS_NTU_PaCE_CRM_Upgrade_ExtReq_WebRegistration_Final_SignOff.pdf", "GUID": "ad55a9db-dad6-4f7c-aafc-af4e09c4c5ab              ", "FileName Path": "http://msfdemo.isearch.com:18605/Demo MSF/TeBS_NTU_PaCE_CRM_Upgrade_ExtReq_WebRegistration_Final_SignOff.pdf", "FileName Version": 1, "Created DateTime": "2023-01-25 06:40:54.000", "Updated DateTime": "2023-01-25 06:40:54.000", "Created By": "Pranav                                                                                              ", "Updated By": "Amit                                                                                                ", "RawOCR": "Business Requirements Specification Document\n(Extended Requirements of\nShort Courses Course Registration)\n\nMicrosoft Dynamics CRM 2016 \u2014 On-Premises\nImplementation\n\nFOR\nNTU\n\nCollege of Professional and Continuing Education\n\nNANYANG |\neeyce,| TECHNOLOGICAL | College of Professional and\noF UNIVERSITY | Continuing Education\n\n_7 SINGAPORE i\n\nPrepared for | NTU \u2014 CoPACE\n\nProject | Microsoft CRM3.0 Upgrade to Dynamics CRM2016 |\n| Prepared by | Senthil\n| Business owner | CoPACE (Sales and Operation Team)\n\nNTU CoPACE \u2014 Extended Requirements (Short Courses Course Registration) v0.7 Page 1 of 13\nDocument Version\n\nVersion | Date Author Comment/ Changes from Prior Version\n\n0.1 17 Sep 2018 | Senthil Initial draft\n\n0.2 21 Sep 2018 | Senthil Revised workflow\nAmended SIP and eLearning scope after\n\n0.3 27 Sep 2018 | Senthil email correspondence with Lee Hoon on 224\n237 Sep\n\n. Amended after SIP field list and requirement\n\n0.4 29 Sep 2018 | Senthil email from Kat on 27\" Sep\n\n. After meeting with DL user on 1% Oct and\n\na cainamniies Senthil received revised field list matrix on 5\" Oct.\nAmended DL workflow based on Lily\u2019s 15\" Oct\nemail.\n\n0.6 16 Oct 2018 Senthil Amended SIP workflow after phone\nconversation (on 16\" Oct) by Chang Hsien\nand Patrick with Lee Hoon and Kathrine.\n\n. Amended workflow based on 18\" Oct\n\n0.7 18 Oct 2018 Senthil meeting.\n\nReview & Acceptance\n\nDate\n\nReviewed & Accepted by\n\nSignature \u2018\n4 Nanyang on University\n\nCollege of Professional and Co inuing Education\n\nTan Soon Meng 60 Nanyang Drive\nSBS -01s-50\n(aco (2 CoPACE Singapore 637551\nNTU NTU Reg. No: 200604393R\nTan Lee Hoon =\n\\o\n1S | (8 | copace ct Ll :\nNTU |\n\u2014\nNTU CoPACE \u2014 Extended Requirements (Short Courses Course Registration) v0.7 Page 2 of 13\nIndex\n\nTNE ODjECtIVE 2... eee eececeseeseeseeseeseeseeseesseeseeseessesaeeaecseesecseceaeeaecaeesecseeeteseeeeeseesenseeseeae 4\nREQUIFEMETIE OVEIVIOW a ccsvsccsscacreescesecceveseveucesseseesevereerecocescisneesseereen TSIEN 4\nWON MOW isszscevsccszcessussneracransntrersdninarenrnpeensoostsneepesentansrsoasentonesasenctancsnsenceassaspaneatanseaneaatant 5\nCourse Registration ............ccccceceecceseseseeesseesecessesecsecessecsscesseesseesseccseesseeseeeseesseesaseneees 8\nACCEPtance Page ou... eccceeccecesseseseeseseeseesesseseesesecsesaesesesaeseesesecsecaesecseeeeaeescaeeaeseeaeeesees 8\nExisting Registration: FOmMS ssscivcsscssessavecsrsseneniaracescanssemnanenmrnnaneereniere 9\nRegistration Page Sample Layout ............cccccccccececeseesceceseseeseecsecseecsececsesseseeseseeetsesaee 9\n\nNTU CoPACE \u2014 Extended Requirements (Short Courses Course Registration) v0.7 Page 3 of 13\nThe Objective\n\nThe objective is to create Course Registration and Course Acceptance page for short courses.\nThese pages will be developed to meet web responsive, so the users can access these pages\nfrom any devices and register easily. The user-friendly controls will be incorporated to make\nthe registration form filling easier for users.\n\nRequirement Overview\n\ne The following 3 different types of forms will be created.\no Short Courses (SC)\no Student Immersion Programme (SIP)\no Distance Learning (DL)\ne In order to capture the leads quickly, we propose to capture basic information of\nparticipant in first iteration of registration.\ne The overview of process flow shown below.\n\nRegister course by\nproviding\n\nParticipant selects\na preferred course\nin website and\nregister ONLINE\n\nBASIC\nINFORMATION\n\nCourse\ncommencement\nand closure\n\nconfirmed provide\nMORE\nINFORMATION\nand payment\n\ne Once the course has confirmed, the participant should provide more information and\nsubsequent action such payment. This approach is applicable for Short Courses only.\nThe Student Immersion Programme and Distance Learning registration doesn\u2019t need this\napproach due to there is no course confirmation process in it.\n\ne The following are the types of registration forms.\n\nSelf Sponsor Company Sponsor\n\nee\ngi See\n\nIndividual Group One or More\n\nNTU CoPACE \u2014 Extended Requirements (Short Courses Course Registration) v0.7 Page 4 of 13\ntat\nApplicant(s)\nthrough\nweb portal\n\nCo | 0 eee Oe Ge (Oe\ntriggers triggers crs cRM cRM pom\nRegistration successful Withdr || triggers triggers cRM triggers 4\n\u2018 # % i eo triggers\nsaved in CRM registration awal_ || Disqualifi course triggers nae = email with \u2018aceeseha\n2016 \u2018<a pena ed email cancellation || confirmat \u2018i payment payment\nemail ton email SPPIONE link CRM\nand class\nupdated A\nDenied with datails\nes cancelled J. information\nEvent & Sales Hee ne? Cacti A _priment\ncoe .\u2014} weoume ms | gianna, \u00ab| bares | | | ermecon\nCRM 2016 succe . confirm je? oo? oe | confirm the\nregistration e- i: Ost a Mom SS | course fee\nmail se? Info and yd\nDocume 4\u00b0\u201d ; \u2014\n- H\nH\n'\n'\n\nVerification e-\nmail sent to\nAAO and NTUC\nbased on\nAffiliation\n\nTeBS\n\ne The detailed registration processes explained in the following sections.\n\nWorkflow\n\nThe following workflow defines the processes of registering for a Short Course which has\nfunding and SkillsFuture Credit option.\n\nSC Registration workflow \u2014 Self Sponsor \u2014 Individual & Group \u2014 With Funding and SFC option\n\nApplicant claim SFC\n\ni A\ney Applicant | Applicant\nApplican Applicant idciew | submit\nregister for a i ' - PPR documents &\ngo weeesstul HI Applicant |) receives De ater 506 approwes Hv Applicant \u2014-\nthrough online coe. ones course te ae selects pplicant\nregistratio : \" ess receives\n{initial} zeae fecetves || cisauslife 1) cancetistion | Mime Romy payment jasiehie\n; de-mail enell onli (CoPACE-Role option\nal e-mail CePA\n\nEvent ICask |\nAlumni regarding |\nthe amount can 1:\n\\\n'\n'\n'\n\n1 Manage application\n\n'\nrecords/upload + CRM automation\n\nmissing documents\n\nbe utilized based\non balance\n\nNTU CoPACE \u2014 Extended Requirements (Short Courses Course Registration) v0.7 Page 5 of 13\nTeBS\n\nThe following workflow defines the processes of registering for a Short Course through\ncompany sponsor with funding options.\n\nSC Registration workflow \u2014 Company Sponsor \u2014 With Funding option\n\nApplicant\nApplicant Applicant \u2014 Applicant submit\nregister for a receives d Applicant\npee fol Applicant course adrpiaslagtt! qaceives\n2 success Neuere eunrgbanion provides ather\nthrough online JUREREacrcy * omer Z \u2018essential information class\n\n{Initial} ne-mail receives || disqualified email ee aataus\nwithdraw e-mail oo\nal e-mail *\n\n|\n\nea ee : +\ncRM ' Event || CRM of \u2018\nwiggers |} jc] triggers CRM cRM SS verified | CRM triggers\nRegistration | ph] successful |! update] Withdra || triggers triggers pats t Willies el setmseeae class details\nsaved in CRM registration |! the || wal Oisquelifi course triggers - pod sn information\n2016 email ' ' it ed email a confirmati | \u2018, | payable\nmii same jL ome || nema | \"sy satus \"| basedon\nFi wd %, 2 {funding\naa Denied yar {__options CRM provide |\nEvent & Sales Pons Missing supporting |\nIC receives ot . Documents document for |\nCRM 2016 successful 7\u201d Validates company invoice |\nregistration e- \u00ab registrati and participant |\nmail a, nai oe list and funding |\n. \u201c i it 1\n. , 4 | Manage application | Gesais H\nne, 5H . a Hl beeen een\nse SS. uel \u2018 records/ upload | 7\nVerification e- ae | missing documents } tegen\n! H\nLf '\n\nmail sent to in CRM2016 Web portal for pub\nAAO and NTUC Neeen- eee -----e\n\nCRM automation\n\nbased on\nAffiliation\n\n73\n\nThe following workflow defines the processes of registering for Student Immersion\nProgramme.\n\nStudent Immersion Programme \u2014 Registration Workflow\n\n; Pay through 8D Applicant\nApplicant Applicant Applicant receives\nregister fora receives Applicant accepts & Pay thequgh TT e-receipt\nPee course & successful | | receives selects elma\nApplicant(s) MEMS Cegmg | recistratio | | gicqualifie payment Pay through online schedule\nthrough through online de-mail option Applicant | [ Applicant receives\nwee per ; withdraw | | withdrawal e-mail\nCRM triggers CRM triggers + SEN ~t\na acknowledge ssa course offer Status we. cra | Updates the |\nheesauee ment of iiapers email with will be ana liodated {payment |\nseved in CRM application Disqualifi acceptances updated ba r with 1 information in |\n2036 email ed email ' wal H cRM !\npayment || incr a || payment | 9 L-----RM---- !\nmode p2ge information\n\nlink Event IC confirm class\nand triggers email\n\nworkflow to send out\n\nEvent & Sales\n\ntc ae 27 Event IC checks > e-receipt with class\nsucces: a? 5 \u201ci \u00a3\ncRM 2016 anton (2?) the early bird CRM Triggers schedule (4 weeks\n\n\u201c offer and other\n\n+ details and\nupdate the\n\n+ status in CRM -*\n\ne-mail mail to Finance before class start)\n\nrecords/ upload\nmissing documents [\"4yj\ninCRM2016 \u2014 | Documents\n\ni\n\nNTU CoPACE \u2014 Extended Requirements (Short Courses Course Registration) v0.7 Page 6 of 13\nTeBS\n\nProposed Detailed flow for online registration portion & payment portion (Took in reference of our other\nprogramme type who is using CRM2016 as well,is quite feasible to have them) :\n\nOnline registration input by course pax for SIP > Application route to event IC for processing & Application Acknowledgement Email auto sent\nto course pax > Event IC checked application in order and accept course pax\u2019s application > Change the application status of applicant in CRM\nto \u201cOffer\u201d > Autotrigger Application Acceptance email sent to course pax (Contents will mention the payment amount applicable for course\npax (should be auto detect from CRM), type of payment mode/deadline, information they need to have before they proceed to the url &\ncomes with an url to lead applicant to another webpage: Online Acceptance Page (Course pax can choose whether they accept or reject offer) .\nIf they accept, they can choose the payment mode (Online Credit Card / Telegraphic Transfer / Bank Draft).\n\na) if the person choose Online Credit Card payment, reflect the correct fee amount to be charged to applicant > prompt applicant to input\npayment details online > Transaction completed successfully > Payment Mode auto reflected in CRM as Credit Card. Payment Amount\nReceived: Auto indicated the received amount in crm.)\n\nb) If the person choose Telegraphic Transfer, prompt to upload attachment of their telegraphic transfer proof of advice from Bank > Auto\nRoute to our Finance for followup to track if the remittance was received and the amount received & Payment Mode should auto reflected in\nCRM as Telegraphic Transfer > Finance update the status in CRM > Payment Amount Received: Finance indicates the actual received payment\namount in crm.)\n\n\u00a2) If the person choose Bank Draft > Payment Mode should auto reflected in CRM as Bank Draft > Event IC follows up manually with course\npax > course pax submit bank draft to event IC > Event IC manually submit to Finance for followup to track if the Bankdraft amount was\nreceived and the amount received > Finance update the status in CRM > Payment Amount Received: Finance indicates the actual received\npayment amount in crm.)\n\nConcurrently, once the course pax choose to \u201cAccept the offer\u201d > to auto trigger email sent of selected required details of course pax (Self\nSponsored: Participant\u2019s Name & mailing address of course pax or University Sponsored: University Billing Contact Details) to Finance to\ncreate SAP record (this will be used by Finance to create Invoice and Receipt).\n\nThe following workflow defines the processes of registering for Distance Learning.\n\nDistance Learning \u2014 Registration Workflow\n\nApplicant\nApplicant withdraw\n\nreceives\n\nApplicant\n\nate\n\nny aguieado - successful Applicant Applicant selican\nApplicant(s) (aaa eg | recistratio receives selects aie\nthrough & ne-mail withdrew ef Meal i\nweb portal al e-mail tite \u2014\n\ncRM | Event\na triggers |} Ic cRM\nRegistration successful \u2018 update 0 CRM triggers\nsaved in CRM registration |! the onan successful\n2016 email ' status emaiiwi payment and\npayment\nPN: | link student\ncigataen network\nwith account\nEvent & Sales . [pani 7 payment information\nIC receives ur\u2019) Nalidates ~S. | confirm the information\nCRM 2016 successful i Applicant BY | course fee\n\u2014 e Sy info rs | | payable\n\nfunding\n\nEvent IC ask\nAlumni regarding\n\n\u2018\n\u2018\n\u2018\n1\n\\\n\n{basedon |\n'\n\noptions if |\n\n'\n\nVerification e-\n\ni\n'\n\u2018 1 \u2018\nmail sent to the amount can | Hl Manage iiaiaaial q\nhiner bavad on be utifized based | \u2018 records in !\nAffiliation (and on balance ' ! CRM2016 \\\nnTUci Lae | tana\n\napplicable)\n\nNTU CoPACE \u2014 Extended Requirements (Short Courses Course Registration) v0.7 Page 7 of 13\nCourse Registration\n\ne The course registration form will be loaded based on the course type. Ex. If the course\ntype is short courses, the form created for this type will be loaded.\n\u00a2 \u2014 The following list of fields will be incorporated in the registration form for different types.\n\nfields matrix_201810\n\n\u00a2 The company sponsor section will be enabled to fill only when the user selects company\nsponsor option.\n\ne The company sponsor and individual sponsor (group) can apply multiple applicants at\none-time registration, instead of submitting individually.\n\ne The user can add more than one participant in the registration form.\n\ne The course name and commencement date will be filled automatically by the system,\nbased on the intake chosen from Short Courses website.\n\ne The user can enter postal code to retrieve the block number and road name, for Singapore\naddress. Other such intuitive options will be provided in registration form.\n\ne The registration form will be responsive to access using mobile devices. The layout will\nbe adjusted automatically according to the device size.\n\n\u00a2 To verify whether the student is a current University student, they should submit University\nLetter at registration for SIP programme.\n\nAcceptance Page\n\ne The acceptance page will provide option for user to view the status of registration, any\ntime after successful registration.\n\ne When the course confirmed by Event ICs, the applicant will be informed to fill more\ninformation and select the preferred mode of payment from this acceptance page. Ex.\nOne-Stop (Student Services), Online Payment.\n\ne The online payment option will be provided if the applicant selected payment mode is\nOnline Payment.\n\ne The user will be verified at the time of accessing this acceptance page.\n\ne The student could withdraw offer from this page, before paying for SIP programme.\n\nNTU CoPACE \u2014 Extended Requirements (Short Courses Course Registration) v0.7 Page 8 of 13\nTeBS\n\nExisting Registration Forms\n\n{fF poo\n\nEe Ug iy\n\na Gases\nShort Course e-Learning\n\nNeed to add the attached \u201cFront Page\u201d for SIP before the actual registration input page to\ninform applicant get ready those details before they key their details.\n\nFront Page for SIP SIP Registration\nregistration page be Form\n\nRegistration Page Sample Layout\n\ne The following image shows registration page sample layout. The list of fields will be\nfollowed as per the fields list attached in this document.\n\ne The registration form will be split for basic information and more information for short\ncourses.\n\ne The HTML mock-up design will be provided for user acceptance as next milestone.\n\nNTU CoPACE \u2014 Extended Requirements (Short Courses Course Registration) v0.7 Page 9 of 13\nPARINERSPEERS LOGW\n\nIRE NaNvaNG\n\n\u00ab> TECHNOLOGICAL\n\nQS university\n24> Sincarene\n\nCollege of Professioual and Continuing Education\n\nArtificial Intelligence (01 Oct 2018 - 02 Oct 2018)\n\nto) g = &\n\nCompany Participant Pre-course Acknowledgement\nSurvey\nCompany Sponsored? @Yes ONo\nCOMPANY v\n\nCompany Name *\n\nCompany Billing Address\n\nAddress 1 *\n4\nCity * Country * Postal Code *\nCompany Mailing Address\nCompany Sponsored? @yes ONo\nAddress 1\u00b0\nCity * Country * Postal Code *\nCOMPANY DEPT v\nCompany/Organisation Representative Salutation & Name\nSalutation Family Name* Given Name *\nor\nContact Dept *\nContact Details\nTelephone * Fax* Email ~\nNext\n\nNTU CoPACE \u2014 Extended Requirements (Short Courses Course Registration) v0.7\n\nTeBS\n\nPage 10 of 13\nTeBS\n\nPROSPECTIVE STUDENTS | STUDENTS\n\nI. FACULTY/ STAFF MEDIA PARTNERS/PEERS LOGIN\u201d #\n\nim NANYANG\n\nTECHNOLOGICAL\n\nOs\n& UNIVERSITY\n\nSINGAPORE\n\nCollege of Professional and Continuing Education\n\nArtificial Intelligence (01 Oct 2018 - 02 Oct 2018)\n\ng 8\nCompany Participant Pre-course Acknowledgement\nSurvey\n+ Add Participant\nPARTICIPANT 1 foam\nParticipant Details \u201ca\nParticipant Name\nSalutation Family Name* Given Name *\nOr sg\nFull Name (as shown in NRIC/Passport) *\nContact Number(s)\nOffice Telephone Number * Mobile Number * Home Number *\nParticipant Department v\nParticipant Personal Details v\nParticipant Emergency Contact Details v\nMode of Payment v\n\nNTU CoPACE \u2014 Extended Requirements (Short Courses Course Registration) v0.7 Page 11 of 13\nTeBS\n\nPROSPECTIVE STUDENTS STUDENTS ALUMNI FACULTY/STAFR = MEDIA. PARTNERS/PEERS LOGIN. = -#X\n\nERG Nanyanc\n\nez, TECHNOLOGICAL\nSQ university\nSo? SINGAPORE\n\nCollege of Professional and Continuing Education\n\nArtificial Intelligence (01 Oct 2018 - 02 Oct 2018)\n\ng @\n\nCompany Participant Pre-course Acknowledgement\nSurvey\n\nPRE-COURSE SURVEY \u201cwn\n\nHave you attended our\n\ncourse previously? @ yes No\nHow did you hear about us?\n@ PACE College Website O PACE College Facebook O Emailer / Mailing List\nO Online Advertisement O Organisation HR/L&D O SkillsFuture Portal\nO Friend's Recommendation \u00a9 Search Engine O Other\n\nPlease upload your transcript (PG applicants only): What does this category refers to?\n\nUPLOAD\n\nPlease upload your photo (for Summer programme\u2019s applicants only)\n\nUPLOAD\n\nNTU CoPACE \u2014 Extended Requirements (Short Courses Course Registration) v0.7 Page 12 of 13\nSCTIVE STUDENTS\u2019 STUDENTS\u201d ALUMNI FAC\u2019 [AFF MEDIA: RSIPEERS LOGIN ~#X\n\nNANYANG\nTECHNOLOGICAL\n\nSINGAPORE\nCollege of Professional and Continuing Education\n\nArtificial Intelligence (01 Oct 2018 - 02 Oct 2018)\n\nCompany Participant Pre-course Acknowledgement\nSurvey\n\nMETHODS OF PAYMENT \u201c~\n\n1. Credit Card (Visa, American Express and Mastercard only)\n\n2. Cheque made payable to Nanyang Technological University\n3. Invoice to Company (for Company Sponsored Participants)\n4.E-invoice (for Government Organizations)\n\n5. Telegraphic Transfer or Bank Draft (Note: All related charges are to be borne by participant)\n\nCANCELLATION & REFUND POLICY Vv\nREPLACEMENT POLICY Mw\nTERMS AND CONDITIONS Vv\nPRIVACY CLAUSES pe\n\nYes, | acknowledge and agree to the above. (change to declaration? That the above is true\nand accurate. Etc)\n\n| declare that the information provided by me in this application is true and accurate to the\nbest of my knowledge and | have not willfully suppressed any material fact. | accept that if\nany information given by me in this application is in anyway false or incorrect at the point of\napplication, my application will be rejected and any offer of course placement and subsidy(if\n\napplicable) will be withdrawn.\n\n| have read and agreed to the Terms and Conditions attached herein.\n\nNTU CoPACE \u2014 Extended Requirements (Short Courses Course Registration) v0.7 Page 13 of 13\n"}, {"FileName": "TeBS_2018_NTU_CoPaCE_CR0243_20181005_v0.2.pdf", "GUID": "48b3d01a-465a-492d-8a2d-92b7eaa3c463              ", "FileName Path": "http://msfdemo.isearch.com:18605/Demo MSF/TeBS_2018_NTU_CoPaCE_CR0243_20181005_v0.2.pdf", "FileName Version": 1, "Created DateTime": "2023-01-25 06:40:55.000", "Updated DateTime": "2023-01-25 06:40:55.000", "Created By": "Karan                                                                                               ", "Updated By": "Guru                                                                                                ", "RawOCR": "EES] NANYANG\nTeBS TECHNOLOGICAL\n\u00abOS UNIVERSITY\n\nsolutions for utre needs <2\u201d SINGAPORE\n\nChange Requests Impact Analysis\n\nNTU\n\nCollege of Professional and Continuing Education\n\nTEBS-2018-NTU CoPACE CR\n\nTeBS-2018-NTU CoPaCE CR 26/09/2018 Page | of 5\n\n\u00a9 Copy right and all rights reserved. No part of this document may be reproduced, stored, or transmitted in any form or by any means,\nwithout the prior permission of the company.\nUNIVERSITY\n\nFEES] NANYANG\nTeBS OF TECHNOLOGICAL\n\nSolutions for future needs oa SINGAPORE\n\nChange Requests Impact Analysis\n\nCase ID TeBS-2018-CRO243/NTU CR Number TeBS-2018-CRO243/NTU\nInitiated By Senthil Initiated Date 26/09/2018\nPriority HighCMedium OL Application NTU CoPaCe \u2014 SC\nAssessment 8 edium ow PP\n\n. Target .\nBillable Yes LINo Completion Date Schedule provided\nRequirement | Short Course website enhancements and NTU business system integration\n\nChange Requests\n1. Short Courses website enhancement\nThe existing short courses list and detail pages are built in traditional ASP pages. The short\n\ncourses listing, and detailed content page will be enhanced with filtering features and layout.\nThe following 3 pages and 2 web parts will be enhanced as part of this website enhancement\n\nproject.\ne Short Courses Home Page\ne Short Courses Course List Page\ne Short Courses Course Detail Page\ne WSQ Precision Engineering & WSQ Lean Six Sigma web parts\n\nThis website will be integrated with Short Courses CRM2016. The website integration with\nCRM2016 will be delivered as part of this enhanced requirement.\n\n2. Integration with Student Billing System (SBS)\n\nWriting wrapper services (wrapper service involving delta change as well as initial load) in\nCRM to integrate with the PL/SQL to fetch and submit the financial data (CRM to billing and\nbilling to CRM). Student participant and transaction information (charges, payment and\nfunding) Updating CRM data accordingly.\n\n3. Integration with One-Stop\n\nCalling the Java based API for creating a payment case in One-Stop system.\n\nTeBS-2018-NTU CoPaCE CR 26/09/2018 Page 2 of 5\n\n\u00a9 Copy right and all rights reserved. No part of this document may be reproduced, stored, or transmitted in any form or by any means,\nwithout the prior permission of the company.\n= NANYANG\nTECHNOLOGICAL\n) UNIVERSITY\nSINGAPORE\n\nChange Requests Impact Analysis\n\n4. Integration with e-Cert\n\nDeveloping CRM 2016 API to submit the e-Cert PDF file from the PL/SQL database to be stored\nin the Notes' Attachment of the Participant record.\n\n5. Integration with e-Receipt\n\nDeveloping CRM 2016 API to submit the e-Receipt PDF file from the PL/SQL database to be\nstored in the Notes\u2019 Attachment of the Participant record.\n\n6. Integration with BBCRM and Alumni Portal\n\nDeveloping CRM 2016 API to validate a participant whether Alumni. The interface will update\nthe credit unit utilized for CoPACE course. All events completed in CoPACE, will be added to the\nBBCRM education.\n\n7. Course Registration and Acceptance web pages\n\nThe objective is to create Course Registration and Course Acceptance page for short courses.\nThese pages will be developed to meet web responsive, so the users can access these pages from\nany devices and register easily. The user-friendly controls will be incorporated to make the\nregistration form filling easier for users.\n\ne The following 4 different types of forms will be created.\no Short Courses (SC)\no Student Immersion Programme (SIP)\no Distance Learning (DL)\no NSA (National Silver Academy)\ne In order to capture the leads quickly, we propose to capture basic information of\nparticipant in first iteration of registration.\ne The overview of process flow shown below.\n\nRegister course by\nproviding\nParticipant selects\n\na preferred course Course\n\ncommencement\nand closure\n\nin website and\nregister\n\n2 Once the course is\nconfirmed provide\n\nand payment\n\nTeBS-2018-NTU CoPaCE CR 26/09/2018 Page 3 of 5\n\n\u00a9 Copy right and all rights reserved. No part of this document may be reproduced, stored, or transmitted in any form or by any means,\nwithout the prior permission of the company.\nEES] NANYANG\nTeBS TECHNOLOGICAL\nQF UNIVERSITY\n\nSolutions for future needs _ SINGAPORE\n\nChange Requests Impact Analysis\n\ne Once the course has confirmed, the participant should provide more information and\nsubsequent action such payment. This approach is applicable for Short Courses. The\nregistration will be one time (registering with all the necessary information) for Student\nImmersion Programme and Distance Learning programmes due to there is no course\nconfirmation process in it.\n\nAssumptions\n\nSC Website Enhancements\n\ne Roles and Security for internal users will be implemented using SharePoint 2010 Out-of-\nthe-box features.\n\ne The static content should be managed from SharePoint.\n\ne 5 different filtering options will be incorporated in course listing page. Since the data is in\nCRM, user may experience delay in page loading.\n\ne NTU should provide the master page with page navigation option. TeBS SharePoint team\nworks only for the body content.\n\nIntegration with NTU Business Systems\ne NTU will provide or create necessary services in business systems and expose for CRM\nintegration.\ne NTU will provide necessary interface documents consist of request and response\nparameters.\ne NTU will provide development, UAT environment to accomplish the integration tasks.\n\nImpact Assessment\n\nShort Courses (SC) website enhancement 39\n\nIntegration with Student Billing System (SBS)\n\nIntegration with One-Stop\n\n13\n18\n[neestonwinewe i\n\nIntegration with e-Receipt\n\nIntegration with BBCRM & Alumni Portal 26\n\nCourse Registration and Acceptance web pages 84\n\nTotal man days 198\n\nTotal Price ($600/Man day) $118,800\n\nTeBS-2018-NTU CoPaCE CR 26/09/2018 Page 4 of 5\n\n\u00a9 Copy right and all rights reserved. No part of this document may be reproduced, stored, or transmitted in any form or by any means,\nwithout the prior permission of the company.\nERE] NaNyaNs\nreas) | red TECHNOLOGICAL\n\n) UNIVERSITY\n\n\u2018Solutions for future nends ~_\u201d SINGAPORE\n\nChange Requests Impact Analysis\n\nImplementation Schedule\n\nAs per ITQ contract Change Requests\n\n* CRM2016 Upgrade * Enhancement of | * Web registration page for\nfrom CRM3.0 Programme file in COPACE individual and group (4\n* Data Migration from website different types of\nCRM3.0 to CRM2016 * Integration with e-cert templates)\n| \u00a9 Integration for e-receipt | * Bulk registration through\n| \u00ab Integration with Student | excel file in CRM2016\nBilling System | * Web page for providing\n| * Integration with One Stop more information and e-\n* Integration with BBCRM & Payment\n\nAlumni Portal\n\nGo live readiness\nby 29/10/2018\n\nGo live by 29/11/2018\n\n* Change Request sign-off\n(by 05/10/18)\n\nTimeline\n\nWe expect NTU confirm this Change Request and sign-off by 05/10/18, to deliver the full system\nby 26\" Nov 2018. The final go live date impact if any delay in this Change Request confirmation.\n\nApproval:\nName Designation Date Signature\nNanyang\nTechnological\nUniversity\nTeBS-2018-NTU CoPaCE CR 26/09/2018 Page 5 of 5\n\n\u00a9 Copy right and all rights reserved. No part of this document may be reproduced, stored, or transmitted in any form or by any means,\nwithout the prior permission of the company.\n"}, {"FileName": "TeBS_2018_NTU_CoPaCE_CR0243_20181003_v0.1.pdf", "GUID": "0646781d-fd83-43d7-bcd1-2bbd1b8b04cd              ", "FileName Path": "http://msfdemo.isearch.com:18605/Demo MSF/TeBS_2018_NTU_CoPaCE_CR0243_20181003_v0.1.pdf", "FileName Version": 1, "Created DateTime": "2023-01-25 06:40:55.000", "Updated DateTime": "2023-01-25 06:40:55.000", "Created By": "Arun                                                                                                ", "Updated By": "Bijjala                                                                                             ", "RawOCR": "EES] NANYANG\nTeBS TECHNOLOGICAL\n\u00abOS UNIVERSITY\n\nsolutions for utre needs <2\u201d SINGAPORE\n\nChange Requests Impact Analysis\n\nNTU\n\nCollege of Professional and Continuing Education\n\nTEBS-2018-NTU CoPACE CR\n\nTeBS-2018-NTU CoPaCE CR 26/09/2018 Page | of 6\n\n\u00a9 Copy right and all rights reserved. No part of this document may be reproduced, stored, or transmitted in any form or by any means,\nwithout the prior permission of the company.\nUNIVERSITY\n\nFEES] NANYANG\nTeBS OF TECHNOLOGICAL\n\nSolutions for future needs oa SINGAPORE\n\nChange Requests Impact Analysis\n\nCase ID TeBS-2018-CRO243/NTU CR Number TeBS-2018-CRO243/NTU\nInitiated By Senthil Initiated Date 26/09/2018\nPriority HighCMedium OL Application NTU CoPaCe \u2014 SC\nAssessment 8 edium ow PP\n\n. Target .\nBillable Yes LINo Completion Date Schedule provided\nRequirement | Short Course website enhancements and NTU business system integration\n\nChange Requests\n1. Short Courses website enhancement\nThe existing short courses list and detail pages are built in traditional ASP pages. The short\n\ncourses listing, and detailed content page will be enhanced with filtering features and layout.\nThe following 3 pages and 2 web parts will be enhanced as part of this website enhancement\n\nproject.\ne Short Courses Home Page\ne Short Courses Course List Page\ne Short Courses Course Detail Page\ne WSQ Precision Engineering & WSQ Lean Six Sigma web parts\n\nThis website will be integrated with Short Courses CRM2016. The website integration with\nCRM2016 will be delivered as part of this enhanced requirement.\n\n2. Integration with Student Billing System (SBS)\n\nWriting wrapper services (wrapper service involving delta change as well as initial load) in\nCRM to integrate with the PL/SQL to fetch and submit the financial data (CRM to billing and\nbilling to CRM). Student participant and transaction information (charges, payment and\nfunding) Updating CRM data accordingly.\n\n3. Integration with One-Stop\n\nCalling the Java based API for creating a payment case in One-Stop system.\n\nTeBS-2018-NTU CoPaCE CR 26/09/2018 Page 2 of 6\n\n\u00a9 Copy right and all rights reserved. No part of this document may be reproduced, stored, or transmitted in any form or by any means,\nwithout the prior permission of the company.\n= NANYANG\nTECHNOLOGICAL\n) UNIVERSITY\nSINGAPORE\n\nChange Requests Impact Analysis\n\n4. Integration with e-Cert\n\nDeveloping CRM 2016 API to submit the e-Cert PDF file from the PL/SQL database to be stored\nin the Notes' Attachment of the Participant record.\n\n5. Integration with e-Receipt\n\nDeveloping CRM 2016 API to submit the e-Receipt PDF file from the PL/SQL database to be\nstored in the Notes\u2019 Attachment of the Participant record.\n\n6. Integration with BBCRM and Alumni Portal\n\nDeveloping CRM 2016 API to validate a participant whether Alumni. The interface will update\nthe credit unit utilized for CoPACE course. All events completed in CoPACE, will be added to the\nBBCRM education.\n\n7. Course Registration and Acceptance web pages\n\nThe objective is to create Course Registration and Course Acceptance page for short courses.\nThese pages will be developed to meet web responsive, so the users can access these pages from\nany devices and register easily. The user-friendly controls will be incorporated to make the\nregistration form filling easier for users.\n\ne The following 4 different types of forms will be created.\no Short Courses (SC)\no Student Immersion Programme (SIP)\no Distance Learning (DL)\no NSA (National Silver Academy)\ne In order to capture the leads quickly, we propose to capture basic information of\nparticipant in first iteration of registration.\ne The overview of process flow shown below.\n\nRegister course by\nproviding\nParticipant selects\n\na preferred course Course\n\ncommencement\nand closure\n\nin website and\nregister\n\n2 Once the course is\nconfirmed provide\n\nand payment\n\nTeBS-2018-NTU CoPaCE CR 26/09/2018 Page 3 of 6\n\n\u00a9 Copy right and all rights reserved. No part of this document may be reproduced, stored, or transmitted in any form or by any means,\nwithout the prior permission of the company.\nSWE] NANYANG\nTeBS TECHNOLOGICAL\nQF UNIVERSITY\n\nsolutions for utre needs <2\u201d SINGAPORE\n\nChange Requests Impact Analysis\n\nOnce the course has confirmed, the participant should provide more information and\nsubsequent action such payment. This approach is applicable for Short Courses. The\nregistration will be one time (registering with all the necessary information) for Student\nImmersion Programme and Distance Learning programmes due to there is no course\nconfirmation process in it.\n\nAssumptions\n\nSC Website Enhancements\n\nSharePoint authentication mechanisms will be leveraged such as AD authentication\nRoles and Security for internal users will be implemented using SharePoint 2010 Out-of-\nthe-box features\n\nThe course category will be static content in SharePoint. New page need to be created\nand included in navigation for new category.\n\nThe static content should be managed from SharePoint.\n\n5 different filtering options will be incorporated in course listing page. Since the data is in\nCRM, user may experience delay in page loading. No search field will be included.\n\nNo additional design elements will be added.\n\nNTU should provide the master page with page navigation option. TeBS SharePoint team\nworks only for the body content.\n\nTeBS will use SLC content template for Short Courses. Thus, the screen responsive follows\nthe same. No enhancement in responsiveness can be done.\n\nThe applicant registration form will be developed by NTU. TeBS CRM team will share\nknowledge on which attribute and entity need to be accessed in CRM to store the\nregistration.\n\nIntegration with NTU Business Systems\n\nNTU will provide or create necessary services in business systems and expose for CRM\nintegration\n\nNTU will provide necessary interface documents consist of request and response\nparameters\n\nNTU will provide development, UAT and Production environment to accomplish the\nintegration tasks\n\nAlumni course credit system integration effort is not included\n\nTeBS-2018-NTU CoPaCE CR 26/09/2018 Page 4 of 6\n\n\u00a9 Copy right and all rights reserved. No part of this document may be reproduced, stored, or transmitted in any form or by any means,\nwithout the prior permission of the company.\nEES] NANYANG\n\nTeBS | TECHNOLOGICAL\nCa UNIVERSITY\n\u00a5.\n\nSINGAPORE\n\nChange Requests Impact Analysis\n\nImpact Assessment\n\nDescription (The effort needed for design, development, testing and\n\nsupporting deployment) AS IEL CEES)\n\nShort Courses (SC) website enhancement\n\n. Integration with Student Billing System (SBS)\n\n. Integration with One-Stop\n\n39\nIntegration with e-cert\nIntegration with e-Receipt \u2014\n198\n\nIntegration with BBCRM & Alumni Portal\n\n: Course Registration and Acceptance web pages\n\nNo.\n1.\n4.\n5.\n\nTotal man days\n\nImplementation Schedule\n\nAs per ITQ contract Change Requests\n\n* CRM2016 Upgrade | \u00a9 Enhancement of * Web registration page for\nfrom CRM3.0 Programme file in CoPACE individual and group (4\n* Data Migration from website different types of\nCRM3.0 to CRM2016 * Integration with e-cert templates)\n* Integration for e-receipt | * Bulk registration through\n| \u00a9 Integration with Student | excel file in CRM2016\n| Billing System | * Web page for providing\n| * Integration with One Stop more information and e-\nle Integration with BBCRM & Payment\n\nAlumni Portal\n\nGo live readiness\nby 29/10/2018\n\nGo live by 29/11/2018\n\n* Change Request sign-off\n(by 05/10/18)\n\nTimeline\n\nWe expect NTU confirm this Change Request and sign-off by 05/10/18, to deliver the full system\nby 26\" Nov 2018. The final go live date impact if any delay in this Change Request confirmation.\n\nTeBS-2018-NTU CoPaCE CR 26/09/2018 Page 5 of 6\n\n\u00a9 Copy right and all rights reserved. No part of this document may be reproduced, stored, or transmitted in any form or by any means,\nwithout the prior permission of the company.\nNANYANG\nTECHNOLOGICAL\nUNIVERSITY\n\nSINGAPORE\n\nChange Requests Impact Analysis\n\nApproval:\nName Designation Date Signature\nNanyang\nTechnological\nUniversity\nTeBS-2018-NTU CoPaCE CR 26/09/2018 Page 6 of 6\n\n\u00a9 Copy right and all rights reserved. No part of this document may be reproduced, stored, or transmitted in any form or by any means,\nwithout the prior permission of the company.\n"}, {"FileName": "SubsiteOrSiteCollection_SPTechCon_Oct2010.pdf", "GUID": "53c3ace0-0327-4814-96b7-535fb9dfe206              ", "FileName Path": "http://msfdemo.isearch.com:18605/Demo MSF/SubsiteOrSiteCollection_SPTechCon_Oct2010.pdf", "FileName Version": 1, "Created DateTime": "2023-01-25 06:40:55.000", "Updated DateTime": "2023-01-25 06:40:55.000", "Created By": "Rajesh                                                                                              ", "Updated By": "Rajesh                                                                                              ", "RawOCR": "| A a ee oe Le eS\nConsulting, LLC\n\nGary Lapointe, MVP\n\nSub-Site or Site\nCollection?\nia\n\n| CGAL TLCS LOT\n@) U eC } Consulting, LLC\n\n)\n\nS<APTILLON\n\u00ae SharePoint MVP\n\n\u00a9 Independent Consultant and Owner of\nFalchion Consulting, LLC\n\n\u00a9 Principal Consultant - Aptillon, Inc.\n\n\u00a9 Blog:\n\u00a9 Twitter: @glapointe\n\u00a9 Email: gary@falchionconsulting.com\n\n\\_APTILLON | GL AL TNC Jak Ik\nAgenda\n\n\u00ae Site Collections vs. Sub-Sites\ne What you need to consider\n\u00a9 There can be only one\n\ne Considerations for making multiple Site\nCollections \u201cappear\u201d homogenous\n\n\u00a9 Dealing with change\ne Converting to or from Site Collections\n\n\\_APTILLON a oe\nSite Collections vs. Sub-Sites\n\nSite Collections\n\n\\_APTILLON QUO MUO\nConsiderations\n\n\u00a9 Scalability \u00a9 Branding\n\n\u00a9 Backup/Restore \u00a9 Navigation\n\n\u00a9 Security \u00a9 Content Rollup and\n\u00a9 Search Settings Aggregation\n\n\u00a9 Audit/IRM Settings\n\u00a9 Feature Scope\n\u00a9 Recycle Bin\n\n\u00a9 Content Type / Site\nColumn Scope\n\n\\_APTILLON | NGL OIL\n\nACTA ETS\n) Consulting, LLC\nScalability\n\n\u00a9 The single most critical reason for using\nmultiple Site Collections is scalability\n\n\u00a9 Limit Content Databases to 200GB\n\n\u00ae Limit Site Collections to 100GB\n\ne If you must go over 100GB then use only 1 site\ncollection in the content database\n\ne You will encounter performance issues and\npossibly deadlock conditions\n\ne Split Site Collections approaching 100GB into a\nnew Site Collection in a separate content\ndatabase (PowerShell)\n\n\u00a9 Watch out for the second stage recycle bin!\n\n\\_APTILLON | Gull ILA\n\nACTA ETS\n) Consulting, LLC\nBackup/Restore\n\n\u00a9 Full fidelity backups are only possible at\nthe Site Collection level\n\u00a9 SharePoint 2010 Allows Sub-Site and\nList/Library Recovery\ne Not Full Fidelity\n\u00a9 Cannot restore recycle bin, workflows, alerts,\npersonalization settings, auditing data\n\u00ae 3 party solutions offer full fidelity\nrecovery at more granular levels\n\n\\_APTILLON A@UWOWLWONLL\nSecurity\n\n\u00a9 Site Collections allow security groups and\npermissions to be isolated from each other\n\n\u00a9 Management is more complex with Site Collections\n\ne Difficult to see what access a user has across Site\nCollections\n\ne No OOTB way to synchronize across Site Collections\n\u00a9 Avoid breaking inheritance where possible\ne May result in unforeseen/undesirable consequences\ne Site Collections can reduce the need to break inheritance\n\u00a9 For large deployments Site Collections can help\novercome SharePoint group limitations\ne Cannot go over 2000 users or AD groups in a single ACL\n\n\\_APTILLON COUN\n\n)\n\nNA Ak Ik\nConsulting, LLC\nsearch Settings\n\n\u00a9 Search Scopes are defined at the Site\nCollection level\n\ne You can create shared scopes via the SA but\nthey must be \u201cactivated\u201d at each Site Collection\n\n\u00a9 Best Bets and Keywords are Site\nCollection scoped\ne Use a single search center\n\n\u00a9 Settings must be manually (or\n\nprogrammatically) synchronized across site\ncollections\n\n\\_APTILLON | Gull ILA\n\nACTA ETS\n) Consulting, LLC\nAuditing/IRM\n\n\u00a9 Policies are created at the Site Collection\nscope\ne Compliance and regulatory requirements can be\nenforced in a consistent fashion\n\u00ae No built-in mechanism for synchronizing\npolicies across Site Collections\n\ne Will have to be done manually or\nprogrammatically\n\n7\n\n\\_APTILLON Green\n\nNA Ak Ik\n) Consulting, LLC\nFeature Scope\n\n\u00a9 Features can be scoped to a Site Collection\nor Web (or Farm or Web Application)\n\n\u00a9 You can prevent access to certain\nfunctionality by using Site Collections\ne Some Features must be scoped to a site\ncollection\ne You might have to activate a Feature thereby\n(potentially) making functionality available to all\nusers/contributors/designers of a site\n\nfA\n\n\\_APTILLON ee acetal\n\n)\nRecycle Bin\n\n\u00a9 Each Site Collection has a First and Second\nStage Recycle Bin\n\ne First Stage counts towards the Quota\n\ne Second Stage does not count towards the Quota\n\n\u00a9 Be aware of the defaults \u2014 30 days in the first stage\nand 50% of the Site Collection Quota for the second\nstage\n\n\u00a9 If there\u2019s no quota then the second stage will grow\ninfinitely\n\u00a9 For large Site Collections change the 2\" stage\nto ~20% and Quota to < ~80GB\n\ne This will reduce the amount of additional data over\nthe recommended 100GB allotment\n\n\\_APTILLON\n\n| CQL TAS Tk\n) Consulting, LLC\nContent Types / Site Columns\n\n\u00a9 Two Options:\ne Content Type Syndication\no Can \u201cPublish\u201d Content Types across Site Collections\n\no Requires Metadata Service Application (Enterprise\nLicense)\n\n\u00a9 Don\u2019t mix with Features\n\u00a9 Only Propagates Site Columns associated with\nContent Types\ne Use Features to deploy to multiple Site Collections\no Not recommended if Content Type Syndication is used\no Can be used to propagate Site Columns not\nassociated with Content Types\n\n\\_APTILLON | GWU ILN\n\nACTA ETS\n) Consulting, LLC\nt Type Syndication\nThere can be only one!\n\n\u00a9 You want people to\nthink that there\u2019s\nonly one [Site\nCollection]...\n\n..but in reality\nthere\u2019s a whole\nmess of them that\nwe just didn\u2019t want\nusers to know\nabout\n\na CHRISTOPHER LAMBERT MARIO VAN PEEBLES\n\n\u2018Ta Protect Ali That Is Seed.\n\nsta] \u2018 Ame\n<< APTIL LON * ALCL ILWWOUL AL\n\nsulting, LLC\nBranding\n\n\u00a9 Masterpages and CSS can be used to\nenforce a consistent branding\nexperience\n\n\u00a9 Use Features to deploy branding\n\ne Use Feature Stapling to automatically apply\nthe branding to new Site Collections / Sites\n\ne This provides a seamless experience for the\nend-user\n\nfA\n\n\\_APTILLON ee acetal\n\n)\nConsistent Navigation\n\nSPXmIContentMapProvider Custom SiteMapProvider\n\n\u00a9 Uses an XML file to store \u00a9 Can get the navigation\nthe navigation from a \u201csource\u201d site or\n\n\u00a9 Easy to implement list\n\n\u00a9 Navigationis hard coded \u00a9 Requires a lot of custom\n\n\u00a9 Changes should be code .\ndeployed via a Feature \u00a9 Could support security\n\u00a9 Does not support trimming or audience\nsecurity trimming or targeting\naudience targeting Manual\n\n\u00a9 Viable for small numbers\nof Site Collections\nContent Aggregation\n\n\u00a9 Out-of-box\n\ne Search Results Web Part for cross Site\nCollection\n\ne Content Query Web Part or Data Form Web\nPart for single Site Collection\n\n\u00a9 3 Party\n\ne Many different options\no Example:\n\n\u00a9 Custom\ne Make sure you load test (users and content)!\n\n\\_APTILLON COUN\n\nNA Ak Ik\n) Consulting, LLC\nWindows PowerShell\n\n\u00a9 Learn it!\ne You'll need to eventually\n\n\u00a9 Great for making sweeping changes and\ncross Site Collection reports\n\n\u00a9 Download My custom PowerShell\nCmdlets and Scripts\n\n\\_APTILLON\nting with PowerShell\nDealing with Change\n\nMAK!\nCHANGES I cove:\nASKED FOR? ii\n\nDO YOU REMEMBER\nWHAT YOU ASKED\nME TO CHANGE?\n\nYES. IT\u2019S A CONFUSED\nJUMBLE OF USELESS\nINFORMATION WITH A\nTURTLE HEAD OF\nUNSUPPORTED CONCLU\u2014\n\nacottedens #90! com\n\nz\n:\n5\nJ\n\u00a3\n3\n:\n2\n\u00a7\nx\nE\n\nwww.dilbert.com\n\nGOOD PLAN. I LOOK\nTwice AS Ue \u00a9} FORWARD TO SPONTAN\u2014\nTO SURVIVE IN EOUSLY DEVELOPING\n\nTHIS ECONOMY. AN LQ. OF 400.\n\ni}\n\nENOUGH TIME TO DO THAT I ;\nTHINGS RIGHT, DEADLINES, OR DO\nSHOULD I JUST DO SHODDY WORK, OR\n\njarma.@ sol. com\n\nO% \u00a9200\"Soott Adams, inc./Dist. by UPS, inc\n\n1 PRAY FOR DIVINE\n\nsail i INTERVENTION?\n8\ng\n:\n\nMARKETING. \\\nf \u201d) FUTURE? : tal\n\u201cwr\n\n} COLO TNC TT\n) Consulting, LLC\n\nManaging Content Databases\n\n\u00a9 Remember to set the Max # of Site\nCollections per DB \u2014 don't use the default\n\ne This will help to enforce the 200GB Content\nDatabase sizing guidelines\n\ne Use Quotas!\n\u00a9 Move-SPSite PowerShell Cmdlet\ne Move a Site Collection from one Content\nDatabase to another\n\u00a9 Use New-SPSite to create a Site Collection\nin a specific Content Database\n\n\\_APTILLON @UWCWL\nConverting to/from Site Collections\n\n\u00a9 Notaconversion but a migration\n\u00a9 Use Export-SPWeb & Import-SPWeb PowerShell Cmdlets\n\nExport/Import Sites and Lists/Libraries\nNo Workflow Tasks/State\n\nNo Personalization Settings\n\nNo Alerts\n\nNo Recycle Bin Items\n\nNo Audit Information\n\n\u00a9 Non-publishing sites are simple(r)\ne Watch out for Web Parts which reference Lists via a GUID\ne Watch out for Features scoped to the Site Collection that may need to\n\nbe activated\n\n\u00a9 Publishing Sites migrate with numerous errors...\ne If Lists/Libraries are all you need then you can avoid a lot of trouble by\n\n\\_APTILLON\n\nfocusing on them only\n\n\u00a9 Watch out for Lookup Columns!\n\nfA\n| CQL TAS Tk\n) Consulting, LLC\nPublishing Site Migration Errors\n\n\u00a9 File not found errors on pages that map to the wrong\nPage Layout path and/or missing Page Layouts\n\n\u00a9 Page Layouts and Settings page produces an XML\nparsing error\n\n\u00a9 Page Layouts do not have the correct Content Type\nassigned\n\n\u00a9 File not found errors for missing master page files\n\n\u00a9 ContentType field for the Master Page Gallery library is\ncorrupt and will need to be reset (wrong field type)\n\n\u00a9 Site Collection scoped Features may need to be activated\n\u00a9 Global Navigation will be corrupt or missing\n\n\u00a9 Web Parts that use a GUID to refer to the target item will\nbe broken\n\n\u00a9 Andmore....\n\nfA\n\n\\_APTILLON ee acetal\n\n)\nDemo\n\nConvertTo-SPSite / Repair-\nSPSite\nResources\n\n\u00a9 TechNet \u2014 Plan for Software Boundaries\n\ne http://technet.microsoft.com/en-\nus/library/cc262787.aspx\n\n\u00a9 My PowerShell Cmdlets & Scripts\n\n\\_APTILLON | (QL sae Ik 7\nThank You!!!\n\nQuestions?\n"}, {"FileName": "SP_RequirementSpecifications.pdf", "GUID": "5f09ebc8-b552-47f7-984b-21f83fbe404a              ", "FileName Path": "http://msfdemo.isearch.com:18605/Demo MSF/SP_RequirementSpecifications.pdf", "FileName Version": 1, "Created DateTime": "2023-01-25 06:40:55.000", "Updated DateTime": "2023-01-25 06:40:55.000", "Created By": "Amit                                                                                                ", "Updated By": "Karan                                                                                               ", "RawOCR": "SINGAPORE POLYTECHNIC\nDEPARTMENT OF INFORMATION AND DIGITAL TECHNOLOGY\nSERVICES\n\nImplementation of Enterprise Content Management\nSystem (ECM) Using SharePoint 2013\nand Migration of Existing Content\n\nPART 2\n\nREQUIREMENT SPECIFICATIONS\n\nAll rights reserved. This document may not be reproduced in any form or by any means without\nthe prior permission of Singapore Polytechnic.\n\nThe information given in this document is not to be communicated, either directly or indirectly, to\nthe press or to any person not authorised to receive it.\n\nYour attention is drawn to the official secrets act (chapter 213), which relates to the safeguarding of\nofficial information.\n\nImplementation of ECM Using SharePoint 2013 and Migration Page 1\n\nPart 2 Requirement Specifications\n\nCONTENTS\n1. BACKGROUND ...........csssessccessrceeessseeeeeessnseeeessneeeeessneeeesessteeeessenesenesseeeeecessteceeesseeeeeeesseeeeesennees 6\n2. OBJECTIVE .......ssssccsssreccesssreeeessseeeseesssteeesssseesesessseeseessstecesessneseseessnseeesssneeesesseeeeeessseeeeessreeeeesens 6\n3. EXISTING ENVIRONMENT...\n4. COMMENCEMENT AND DURATION OF CONTRACT...\n5. TERMINATION OF CONTRACT\n6. SERVICE CREDITS .........cssssscsecssseeeecssnreceessseeeesesseeesecsssneceessseesesenssnseecesnneceeesseeeesessseeeeeesseeeeeesses 7\n7. PAYMENT SCHEDULE AND INVOICEG...........cscccsssrssecsssrecesessreseresssneeecessreceeessneeeeessseeeeesseeeeeesees 7\n8. CLARIFICATIONS .........cccssssssessssrreseessnrecessssresesessseesecsssteeeessssesesessseeeeesssneeeeessneeeressseeeeessseeeeesees 7\n9. DESCRIPTION OF TENDER..........csccccssssccessseceesssseesecessnsecessseeeeeessseeeseesseeeeeesneeeeesesseeeeeesseeeeeesaes 10\n10. SCOPE OF TENDER ...........cccsssssscsssssesesssssrsceessseeseessseesesscsstscecsnseeeeesenseeeesessneeeesseeeeessneeeeesesnees 10\n11. SCOPE OF WORK...........ssscccsssrssessssssesssssreceessneseessseesssssseseeesseeesessnseesesssseeeeessseeeeessseeeeessenees 13\n12. PLANNED IMPLEMENTATION SCHEDULE...............ssscsscssssrsceessseceessseeeesesreeeessneeeeessneeeeeeerenees 14\n13. OTHERS ........sccccssssssesssssrscecssseeceessseeeescssstsceessneceessseeseesssseeceesnseeeeesseceeeesesseseceeseeeeessneeeesereees 15\n14. GENERAL REQUIREMENTA.........csssscsssssssrecesssseceessseeeessssstecessssseeeessneeeeesssseeeeessneeeeessnereeeeseseees 17\n15. FUNCTIONAL REQUIREMENTG..........:scssssscccsssseceessseeesessssnsceessseeceessneeeeesesseeeceesseeeeessneeeeeeerenees 19\n16. APPLICATION PLATFORM AND CODE STANDARDS REQUIREMENTS ..........sssccssssscsessssreeeeeeerees 25\n17. INTERFACE REQUIREMENTS. ...........scscccsssrsecssssecesssseeessssssneeeessseeeeessneeesessseeeeessseeeeessreeeeessserees 28\n18. WEBSPHERE PORTAL INTEGRATION .............cssssssesssssrseeesssescecsnnseceesenseeeecesseececeseeeeessneeeeeesrenees 28\n19. ACTIVE DIRECTORY FOREST..........::scssscsssrseecsssreceessseeseecsssneceesneeceessneeeeesessesecesseeeeessneeeeeesrenees 28\n20. OVERVIEW OF TECHNICAL REQUIREMENTA..........csssssscessssrecesssseseeesseeceessreeeesssseeseeesseeeeesnes 31\n21. SP TECHNICAL ARCHITECTURE\n22.\n23. SP INFRASTRUCTURE REQUIREMENTS ..........scssssssscesssecesssseeeesssnnsececeseeeceesneeeeeseseeeeeessreeeeesnes 32\n24. SYSTEM SECURITY AND CONTROL REQUIREMENTS. ..........sssssccssssssssssssrsecesssseeeesesseeseessseeeeesnes 36\n25. APPLICATION SYSTEM LOGG.............ssscccssssresesssseseecessneecessneeeeeessseseecesnneeceesseeeeessneeeeeesseeeeeesaes 36\n\nImplementation of ECM Using SharePoint 2013 and Migration Page 2\nPart 2 Requirement Specifications\n\n26. TECHNOLOGY PROTECTION ....\n\n27. IPV6 REQUIREMENT..\n\n28. CONTENT MIGRATION ..........csssescccessseceessseceesssseesecessntecessseeeeeesssneesecsseeeceesneeeeeseseeseeessneeeeesaes 40\n29. SYSTEM PERFORMANCE REQUIREMENTE...........::sccssssscessssreeeessseeseeceseeeceesneeeeeseseeeeeesseeeeeesnes 44\nBO. AVAILABILITY............sccccssssrsesesssreseeessstecessseeeeesssseeseeessnsecesssseeeesssseeseeessnseeeesseeeessssseeeeeesseeeeesses 45\nB31. RELIABILITY.............seccccssssrecesssessecesseeecesnseeeeecsessecessnseeeesseeeeeesnsneseecssnseeeesseeeeeseseeeeeesseeeeeesaes 45\n32. ICT SECURITY REQUIREMENTS ..........ssccccsssssssessssesecesseecessseeeeeesseeeecessneeceesseeeeseeseeeeessseeeeesnes 46\n33. APPLICATION SECURITY ...........ssssccssssreecssssecesessseesesesseeecessnseeeesssseeseesssseeeeesseeeeesssseeseesssseeeeesses 53\n34. SYSTEM SECURITY...........sscccccssssssecessseceesseeeesssseesecessnsecessseeeeeesseneeeecssnseceesseeeeeseseeeeeesseeeeesses 54\n35. TESTING AND ACCEPTANCE...........cssssscccessscceesssessecessntecessseeeeessssesesecsnneeceesneeeeesenseeseeesseeeeeesaes 66\nBG. TRAINING .........:ccccsssseccsssseceeessseseecessneeecesseeeeessssessecessnseeecsseeeeeesnsessecesneeeeesneeeeeseseeeeeesseeeeeesaes 69\n37. INTRODUCTION .........cccssssssssssseeseecssseecesssseessessseesssessnseceesnseeeesesseeseeessnseeeesseeeeesssseeseeesseeeeesaes 72\n38. CHANGE CONTROL MANAGEMENT REQUIREMENTS ..........scccccssssssscesssseceesseeeeesesseeseeesseeeeesses 72\n39. CLASSIFICATION AND SERVICE REQUEST SERVICE LEVELG...........ssssccssssssceessseeeressseeeeessreeeeesnes 72\n40. SERVICE REQUEST MANAGEMENT ...........sssccsessssssssssstscessseeeeesssseeeeesssneeeeesneeeeessseeseeesseeeeeesnes 73\n41. SERVICE REQUEST EVALUATION REPORT ...........sssccsssssscesssseceesssseeseecesnteceesseeeeesesseeeeeesseeeeeesaes 74\n42. PAYMENT SCHEDULE FOR SERVICE REQUESTS ...\n\n43. INSTALLATION AND IMPLEMENTATION\n\n44. DOCUMENTATION...\n\n45. QUALITY MANAGEMENT SYSTEM (QMS) ........sssssssssssssssesssssssesessssessssssesesessssssesesssessesseesseases 79\n46. MOBILISATION OF PERSONNEL REQUIREMENTS. .........csssssssssssssssseessrteceesseeeeesssseeseessseeeeeesnes 81\n47. PROJECT ORGANISATION..........:sccccsssseecessseceessssesecessnsecessseeeeeessesesecsnnteceesneeeeeesseeseeesseeeeesaes 81\n48. PROJECT MANAGEMENT PLAN ..........:ccccssssssesssrssecesstecessseeeecsseseecessneeceesneeeeeeesseeseeesseeeeeesses 82\n49. ROLE OF SP REPRESENTATIVE ..........ssscccsssssscsesssesssessstecessseeeeessseesseessnseceesseeeessssseeseeesseeeeeesnes 82\n50. PROJECT MANAGER (CONTRACTOR) .......ssssssssssssssscssssssesssscsssssesssesssessesesessesssesessssesseaseeseenees 83\n51. ROLE OF PROJECT MANAGER. ...........ssscccesssssceessseseecessseecessseeeeeesseesecessnseceesneeeeeseseeeeeesseeeeesaes 83\n52. PROGRESS REPORTING ..........ssscssccssssreecsssseeeesssseesesessnseeessnseeeesssseeeeesssseeeeesseeeessseteeessseeeeesnes 84\n\nImplementation of ECM Using SharePoint 2013 and Migration Page 3\nPart 2 Requirement Specifications\n\n53. REPLACEMENT OF PERSONNEL REQUIREMENT...\n\n54. DATA PROTECTION...\n\n55. PROJECT TECHNICAL REVIEWS ...........:ccccsssssscessseeeecesseccessseeeessneeseecesseeeeesneeeeeeeseeeeeesseeeceesaes 85\n56. RIGHTS TO THE SOFTWARE & DOCUMENTATION. .........s:sssscesssesssessseessseesseeseestseesesesseenseeessees 88\n57. PERFORMANCE GUARANTEE PERIOD/SYSTEM WARRANTY. .......ssssssssssssssssssssssssssssssssessessesseee 90\n58. INTRODUCTION ..........cccsssccccesssrsecessstecessseceesessessecessneecessseeeeeessseeseeeesnteeeesseeeeeeeseeeeeessneeeeesses 92\n59. INCIDENT MANAGEMENT REQUIREMENTS ..........csssssscesssereeeessseseeessneeceesseeeesesseeeeeesseeeeesnes 92\n60. SERVICE LEVEL FOR INCIDENT RESOLUTION TIME..........csssssssssssssscssstecesssseesesssseeseessseeeeesnee 92\nG1. SCOPE OF WORK. ..........csssessscesssrssecesseeecessseceesesseesecesseeeceesnseeseesssnseeeessnseceesneeeeeseneeseeesseeeeesaes 97\n62. SUPPORT HOURS (SYSTEM)......sssssssssssssssssssssssssssssssssssssesessesssesesessascsssesesesseeseasessssessesseeseeases 98\n63. MAINTENANCE .........cccccsssssecessseseecessnteceesseeeesssessesessneecessseeeeeesnsnseeeesnseceesseeeeeeesseeeeeessneeeeesaes 98\n64. APPLICATION & SYSTEM SOFTWARE MAINTENANCE SUPPORT........sssssssssssseestseesssesseenseeesees 98\n65. SOFTWARE SUPPORT.........ccccssssssccessrseeesssseceesssseesecesseteceesseeeeeessneeeeessneeceesneeeeseseeeeeessneeeeess 102\n66. TRANSITION AND EXIT MANAGEMENT ..........ccssessscesssrecesssseceessssneeeeessneceeesseeeeessneeeeesssneeeeess 104\n67. EXPIRATION OF CONTRACT.........scssssssccssssecesesssesecessnsecessseeesessseesssessneecessnseeeeessseeeeessseeeeess 105\n68. COMPLIANCE WITH REGULATORY REQUIREMENT. .........ssscccccssssssseessneeceesseeeersesseeeeeesseeeeeess 107\n69. INFRASTRUCTURE INFORMATION\n\nImplementation of ECM Using SharePoint 2013 and Migration Page 4\nPart 2 Requirement Specifications\nSection A - Introduction\n\nSECTION A\n\nINTRODUCTION\n\nImplementation of ECM Using SharePoint 2013 and Migration Page 5\nPart 2 Requirement Specifications\nSection A - Introduction\n\n1. BACKGROUND\n\nLL.\n\n1.2.\n\nSP invites vendors to submit proposals for Implementation of Enterprise Content\nManagement System (ECM) using Microsoft SharePoint 2013 and content\nmigration from existing Documentum repository (known as DARE).\n\nThere is approximately 1,700 staff using the existing system.\n\n2. OBJECTIVE\n\n2.1.\n\nThe implementation of the ECM System aims to achieve the following\nobjectives:\n\nDeploy a content and document management system that is easy to use,\naccessible anywhere and from all devices\n\nProvide a seamless integration with user\u2019s commonly used applications such as\nMS Office, Email client, Windows Explorer\n\nConfigure the Enterprise Search features to search content from common data\nsources\n\nMigrate the content from existing repository DARE to SharePoint\n\nImplement a user-friendly landing page that shall be a launch-pad to all existing\nand future SharePoint sites and applications\n\nProcure maintenance and support for the entire SharePoint farm including\nexisting servers\n\n3. EXISTING ENVIRONMENT\n\n3.1.\n\n3.2.\n\n3.3.\n\n3.4.\n\n3.5.\n\nSingapore Polytechnic (SP) is currently using EMC Documentum v6.5 SP2. The\nsystem runs on a combination of Solaris and Windows servers. For details, please\nrefer to section 69-1. Details of Existing Documentum System (DARE).\n\nStaff accesses DARE through a customized EMC Documentum DAM client. The\nsupported desktop environment in SP is Microsoft Windows 8.x, Windows 7,\nMac OS Mountain Lion and Maverick. Supported browsers are Internet Explorer\n7 or higher, and Firefox 3.X or higher. Standard software suite includes\nMicrosoft Office 2007, 2010 and 2013 with Outlook 2007, 2010 and 2013 for\nWindows OS, and Mac Office 2011 for Mac OS.\n\nSP enterprise backup is based on Symantec NetBackup.\n\nSP will provide Microsoft software licences through existing Microsoft Campus\nAgreement, Wintel server hardware (or Virtual Machines) and Symantec\nNetBackup licences through existing term contracts.\n\nSP has an existing SharePoint 2013 farm being used for other applications. This\nfarm shall be expanded with additional server resources to support the new ECM\nsystem as per contractor\u2019s recommendations.\n\n4. COMMENCEMENT AND DURATION OF CONTRACT\n\nImplementation of ECM Using SharePoint 2013 and Migration Page 6\nPart 2 Requirement Specifications\nSection A - Introduction\n\n4.1. This Contract shall commence on the date stated in the Letter of Acceptance and\nshall remain in force for a period of 4 years after the System Acceptance.\n\n4.2. The Contract shall be reviewed and renewed by SP on a yearly basis.\n\n5. TERMINATION OF CONTRACT\n\n5.1. | SP reserves the right to terminate the contract with 30-day written notice to the\nContractor in the event of SLA breach or any material breach as stated in the\nrequirement specification.\n\n5.2. In addition, SP reserves the right to terminate the contract during the yearly\nreview.\n\n6. SERVICE CREDITS\n\n6.1. In the event, if Contractor is unable to meet the Service Level Agreements\n(SLAs) specified in Section G \u2014 System Performance, Availability & Security.\nSP will be eligible to claim for Service Credits. The Tenderer shall detail the\ncomputation of service credits for breach in agreements (SLA) during the project,\nwarranty and maintenance periods. The service shall be benchmarked against the\nSLA stated in this tender specification document.\n\n7. PAYMENT SCHEDULE AND INVOICES\n\n7.1. The payment schedule will be based on the key milestones and completing the\nnecessary acceptance as shown below:\n\nSign off Requirements\nSpecification and Detailed\nDesign Specifications\n\nSign off on Successful User\nAcceptance Tests\n\nAcceptance of Requirements\nand Detailed Design\nSpecifications\nAcceptance of User\nAcceptance Tests\n\n3 Acceptance of Performance Sign off System Performance\nTest and on Commissioning Test and Commission Letter\n\n4 System Acceptance \u2014 Acceptance Letter\nCompletion of Performance\nGuarantee Period\n\n5 Payment for Annual Maintenance and Support will be released at the beginning of every six-\n\nmonth period.\n\n7.2. E-invoices should be submitted electronically via the Vendors@Gov portal\n(www.vendors.gov.sg). On enquires related to the invoice submission, contractor\nmay contact the AGD Helpdesk by calling 1800-VENDORS (1800-8363677) or\nsend enquiries by clicking on the \"Contact Us\" link at http://www.vendors.gov.sg.\n\n8. CLARIFICATIONS\n\nImplementation of ECM Using SharePoint 2013 and Migration Page 7\nPart 2 Requirement Specifications\nSection A - Introduction\n\n8.1. All enquiries regarding this tender should be made in writing and emailed to:\n\nK V Ramana Rao (Ram)\n\nManager\n\nDepartment of Information & Digital Technology Services\nSingapore Polytechnic\n\nTel: 68707852\n\nEmail: ramanarao@sp.edu.sg\n\n8.2. SP reserves the right to make clarifications submitted by Tenderer available to all\nother Tenderers. This clause is applicable where there is a site briefing conducted\nand attendees\u2019 details are obtained.\n\n8.3. All clarifications shall be deemed not to be confidential.\n\n8.4. All telephone and facsimile enquiries shall not be entertained.\n\nImplementation of ECM Using SharePoint 2013 and Migration Page 8\nPart 2 Requirement Specifications\nSection B \u2014 Scope of Tender & Work\n\nSECTION B\n\nSCOPE OF TENDER & WORK\n\nImplementation of ECM Using SharePoint 2013 and Migration Page 9\nPart 2 Requirement Specifications\nSection B \u2014 Scope of Tender & Work\n\n9.1.\n\nDESCRIPTION OF TENDER\n\nTenderers are invited to submit a complete proposal for the design, development,\nsupply, delivery, installation, testing, training, commissioning and maintenance of\nthe Enterprise Content Management (ECM) System using Microsoft SharePoint\n2013 including migration of content from existing DARE Documentum system,\nwith Option to procure additional 100 man-days for professional services as term\ncontract.\n\n10. SCOPE OF TENDER\n\n10.1.\n\n10.2.\n\n10.3.\n\n10.4.\n\nThe scope of the project is to implement the ECM System. The requirements\nspecified are mandatory, while the Options are for SP to exercise when awarding\nthe tender.\n\n\u201cOption\u201d, \u201cOptional\u201d are options to SP and NOT options for Tenderers.\nTenderers must quote for ALL components specified in this Requirement\nSpecification. Tenderers who do not quote for Options will be disqualified from\nthe evaluation.\n\nMANDATORY REQUIREMENTS:\n\nTo design the ECM system architecture, propose additional server resources\nrequired and provide professional services to setup and configure SharePoint\nsoftware, services and components (such as web-applications, sites, libraries,\ncontent types, meta-data, permissions and other necessary artefacts) for\nexpanding SP\u2019s existing SharePoint farm to support the functionalities specified\nin this tender specification. Setup development environment and staging\nenvironment (also referred to as Test environment meant to be used for\nintegration testing and UAT) for application development and testing purposes.\nTo provide all tools (e.g. tools for migration, system monitoring, etc.) and\nprofessional services needed to migrate all the content, meta-data, information\nand functionalities of existing DARE system to SharePoint platform.\n\nDesign and implement a user-customizable visually attractive landing page to\nfunction as a launch-pad to access sites within the ECM system and other existing\nand future SharePoint Applications.\n\nProvide ONE Year warranty period for the ECM system starting from the System\nAcceptance Date and sign-off for all deliverables.\n\nProvide 3 years of maintenance and support for the ECM System including all\nservers and system components.\n\nProvide maintenance and support for the entire SharePoint farm including\nexisting servers from the date of the project award and during system\nimplementation, warranty and maintenance periods.\n\nProvision of 100 (One Hundred) man-days as an OPTION (indicate a man-day\nrate charged) for professional services for application enhancements e.g. for new\nfeatures, enhancements, server setup, etc (These man-days are not to be\nconsumed for bug-fixes which shall be covered by warranty and system\nmaintenance). Separate purchase orders shall be raised by SP for consuming these\nman-days. The validity period will be from the date of award till the last day the\nsystem is under 1 Year warranty or 3 Years maintenance with the contractor.\n\nImplementation of ECM Using SharePoint 2013 and Migration Page 10\nPart 2 Requirement Specifications\nSection B \u2014 Scope of Tender & Work\n\n10.5.\n\n10.6.\n\n10.7.\n\n10.8.\n\n10.9.\n\n10.10.\n\n10.11.\n\n10.12.\n\n10.13.\n\n10.14.\n\nSP has the rights to award this tender in part.\n\nThe successful Tenderer, shall be required to conduct a detailed requirement\nstudy after the award of the Tender to study the existing systems, clarify the\ndetails and confirm the user requirements.\n\nThe Tenderer shall propose a solution that best meets SP functional requirements\nto a level of quality acceptable by SP with optimal customisation and\nincorporating best practices available in the product solutions. The proposed\nsolution shall utilize the latest features and API to maintain upward compatibility\nwith future product releases.\n\nThe Tenderer\u2019s submission shall include a detailed system architecture diagram\nwith the specifications of the servers (Number of servers, CPU, RAM, Storage,\netc) and software needed to enhance the existing SharePoint farm to meet all\nrequirements specified in this tender document. It shall be noted that virtualized\n(VMWare) servers shall be provided by SP according to the specifications\nprovided by the tenderer. The tenderer shall be responsible for complete system\ninstallation, software setup & configuration and for meeting the performance\nrequirements.\n\nProposals shall include professional services for installation and configuration of\nsystem software, database software, development tools, or any\nperipherals/systems/services deemed necessary for the implementation and\nmaintenance of the System for SP. Tenderers shall specify clearly the purpose for\neach peripheral, system software components, third-party software components\nand services proposed for SP.\n\nThe Tenderer shall provide interface components for the System to interface with\nSP\u2019s existing application systems as well as those Systems belonging to third\nparty vendors if applicable. Please refer to Section D- Interface Requirements\nfor more details on the interface requirements.\n\nThe Tenderer shall review the existing SP hardware and system software\nsolutions, and recommend architecture to meet the requirements. An architecture\ndiagram with description of proposed changes must be included in the tender\nsubmission. Please refer to Section E\u2014 Technical Requirements for details of\nthe technical requirements.\n\nThe Contractor shall provide for offsite development of the System (Office space\nprovided by the Contractor and Development Hardware/Software to be owned\nand provided by the Contractor). All initial development and testing work for the\nSystem shall also be provided and carried out at the Contractor\u2019s premises.\n\nSubsequently, the System shall be progressively migrated to the test and\nproduction environments to be setup at SP for System Performance Testing and\nUser Acceptance Testing (UAT). The Contractor shall ensure the system\nperformance criteria are met. After the successful completion of UAT, the System\nshall be hosted in the production environment at SP.\n\nThe Contractor shall be responsible for assessing the impact and applying the\n\nImplementation of ECM Using SharePoint 2013 and Migration Page 11\nPart 2 Requirement Specifications\nSection B \u2014 Scope of Tender & Work\n\nupdated OS  patching/upgrade, database patching/upgrade and _ software\npatching/upgrade without or with minimum disruption to the service.\n\n10.15. The support and maintenance for the System, if such option is elected by SP, shall\nbe for up to 3 years, to be reviewed and renewed by SP on a yearly basis. The\nContractor shall also grant SP an option to extend the support and maintenance of\nthe System for a further period of up to 5 years after the expiry of the initial 3\nyears, to be reviewed on a yearly basis. Such support and maintenance services\nshall commence only after the expiry of the System Warranty Period.\n\n10.16. The existing DARE system based on Documentum will have its maintenance\ncontract expiring by 20th May 2015. Hence the contractor must ensure all\ncontent is migrated and users shall be able to fully use new ECM system by 15th\nMay 2015. If the ECM system is not rolled out to users by the above cut-off date\nfor any reason, the contractor shall provide support for DARE system at their own\ncost until it is completely migrated.\n\n10.17. The major milestones for the implementation of the System are listed as follows:\n\n\u00a2 Implementation of ECM System and migration for THREE departments by 30th\nSeptember 2014\n* Implementation of complete ECM system and migration for all remaining\ndepartments by 15th May 2015\n10.18. The other planned major milestones are listed as follows:\n\nPhase Planned Milestone\n\nCommissioning Date As soon as the System has successfully\npassed all the Acceptance Tests, SP will\nforthwith issue a certificate or letter of\ncommissioning the System and the date\nof the certificate or letter shall be the\nCommissioning Date of the System.\n\nPerformance Guarantee Period (PGP) Commence on commissioning Date for a\nperiod of 90 working days.\nThe System shall have successfully\ncompleted the PGP if the System meets\nthe standard of performance or service\navailability level as stipulated in the\ncontract.\n\nSystem Acceptance Date Successful completion of PGP and\nacceptance by SP.\nOnce the System has successfully\ncompleted the PGP, SP shall forthwith\nissue a written notice accepting the\nSystem. The date of the notice shall be\nthe System Acceptance Date.\n\nSystem Warranty Period Commence on System Acceptance Date\nfor a period of 12 calendar months.\n\nImplementation of ECM Using SharePoint 2013 and Migration Page 12\nPart 2 Requirement Specifications\nSection B \u2014 Scope of Tender & Work\n\n4 os . 1 =\n- -year syste\nImplementation PGP lb dal\nWarranty\ne oO o e\nLetter of Commission System Start of\nAcceptance Acceptance Maintenance\n\n11. SCOPE OF WORK\n11.1. The Tenderer\u2019s proposal shall include at least the following scope of work:\n\n11.2. Methodology and Strategy\n* To state the methodology, implementation strategy and tools used during the\nimplementation.\n* To state the approach, tools and detailed execution and verification strategy for\nmigration of data from DARE to the new ECM system.\n* To state the configuration and customization approach to implement the\nfunctionality of DARE in the new ECM system\n\n11.3. Project Management and Execution\n* To put in place a project management framework to ensure well-organised and\nsuccessful execution of the project with timely completion of key deliverables,\nwithin budget and proper mitigation of risks.\n\u00a2 To formulate a concrete plan of action covering comprehensive stage-by-stage\nupgrade activities, project schedule and resources required. Roles and\nresponsibilities of both Contractor\u2019s and SP\u2019s teams shall be clearly defined.\n\n11.4. System Infrastructure to Enhance SP\u2019s existing SharePoint Farm\n\n* To propose the system architecture to meet SP\u2019s requirement in terms of\nfunctionality, integration, performance, availability, disaster recovery and\nsecurity.\n\n* The Contractor will provide a comprehensive additional server recommendation,\nincluding server, storage, server sizing, storage sizing, etc for the implementation\nof the proposed solution on SP\u2019s existing SharePoint farm. SP\u2019s SharePoint farm\nis based on VMWare and additional servers proposed should be similarly\nvirtualized.\n\n\u00a2 Please note that the hardware is not included as part of this procurement. SP will\nprovide the required servers of similar configuration, not necessarily of the same\nmake and model, as proposed by the Contractor to meet the performance\nrequirement set out in this document. The Contractor, however, is still responsible\nfor the integration and performance requirements of the whole system as stated in\nthis tender specification and to ensure the successful commissioning of the\nSystem.\n\n11.5. System Setup\n\nImplementation of ECM Using SharePoint 2013 and Migration Page 13\nPart 2 Requirement Specifications\nSection B \u2014 Scope of Tender & Work\n\n11.6.\n\n11.7.\n\n11.8.\n\n11.9.\n\nTo install, test, configure all components of the System to meet SP requirements.\nThe setup shall include the Test and Production environments.\n\nTo configure and ensure all existing integration and interfaces with other related\nor supporting systems are functioning properly.\n\nTo propose the additional software licenses required for the system. SP's existing\nfarm is based on SharePoint 2013 and MS SQL server 2012. SP shall procure the\nadditional licenses as proposed by the contractor.\n\nTesting Strategy\n\nTo propose an overall testing strategy and put in place the overall test plan to\nensure that the proposed system satisfies all requirements defined in this\nspecification. To put in place a rigorous testing process and QA team to test and\nverify all the deliverables before submitting them with corresponding evidence to\nSP.\n\nTo provide the tools and propose verification strategy to validate that migration of\ndocuments has been completed. Reports shall be provided to tally each of the\nindividual documents have been successfully migrated.\n\nTraining\n\nTo provide suitable and customized training for identified staff to ensure\nproficient management and operation of the System. Please refer to Section I \u2014\nTraining and Awareness Programme for details of training requirements\n\nSystem Rollout /Performance Guarantee Period/System Warranty\nTo provide a comprehensive transition and rollout plan to ensure a smooth and\nstraightforward cut-over. To provide Performance Guarantee Period and System\nWarranty as specified.\n\nDocumentation\n\nTo provide a comprehensive set of documentation to ensure smooth operation and\nadministration of the System, and effective use of the System by the users. Please\nrefer to Section L \u2014 Documentation for details of documentation requirements\n\n11.10. Post Warranty Application Software Maintenance Support\n\nTo submit a proposal for the provision of maintenance and application software\nsupport after warranty period, as specified in Section Q \u2014 Support & System\nMaintenance.\n\n12. PLANNED IMPLEMENTATION SCHEDULE\n\n12.1.\n\n12.2.\n\n12.3.\n\nThe Tenderer shall provide a detailed project schedule that can meet the\nmilestones of this project. The project schedule shall show details up to the task\nlevel, how each milestone could be achieved within the timeframe specified\nabove. The project schedule shall reflect possible overlaps between key activities\nand their interdependencies.\n\nThe Tenderer may propose a schedule where the milestones can be achieved\nearlier.\n\nThe Tenderer shall draw up the Schedule using Microsoft Project format.\n\nImplementation of ECM Using SharePoint 2013 and Migration Page 14\nPart 2 Requirement Specifications\nSection B \u2014 Scope of Tender & Work\n\n13. OTHERS\n\n13.1. The shortlisted Tenderers shall be invited by SP to conduct a formal presentation\nto SP on the proposed solutions. Shortlisted Tenderers shall be required to cover\nthe following areas in their presentations:\n\n\u00a2 Project scope and outcomes\n\n\u00a2 Key areas of concern (including change management issues and critical success\nfactors) which SP should take note of\n\n\u00a2 Tenderer\u2019s proposed solution aided with screenshots, diagram, graphics, work\nflow, mock-up etc, that can best demonstrate the Tenderer\u2019s proposed solutions\n\n\u00a2 Tenderer\u2019s proposed team\u2019s structure, credentials and experience\n\n\u00a2 Tenderer\u2019s track record in undertaking projects of the similar nature and scale\n\n\u00a2 Future product development plans\n\n\u00a2 Migration and Change Management strategy that has the least impact to users\n\n13.2. The shortlisted Tenderers may be required to demonstrate how their proposed\nsolutions work under specific business case scenarios to be prepared by SP. The\ntimeframe for making the presentation and completing the demonstration will be\ndecided by SP after a preliminary review of all Proposals after the closing date of\nthis invitation to tender.\n\n13.3. Tenderer should present the proposed team\u2019s experiences and commitment that\nthe team will not be changed throughout the execution of the project. SP reserves\nthe right to request the vendor to change any member of the project team if they\nare found not to be competent.\n\n13.4. Tenderer shall bear all costs incurred in conjunction with the submission of the\nProposal, including the aforesaid presentation and prototype development where\nnecessary. SP shall not be required to reimburse the Contractor for all such costs.\n\n13.5. SP prefers to award the entire Contract to one Contractor where possible.\nHowever SP reserves the right to award parts of the Contract to one or more\nContractors in its sole and absolute discretion.\n\nImplementation of ECM Using SharePoint 2013 and Migration Page 15\nPart 2 Requirement Specifications\nSection C \u2014 Functional Requirements\n\nSECTION C\n\nFUNCTIONAL REQUIREMENTS\n\nImplementation of ECM Using SharePoint 2013 and Migration Page 16\nPart 2 Requirement Specifications\nSection C \u2014 Functional Requirements\n\n14. GENERAL REQUIREMENTS\n\n14.1.\n\n14.2.\n14.3.\n\n14.4.\n\n14.5.\n\n14.6.\n\n14.7.\n\nThe Contractor shall conceptualise, design, build and integrate the System with\nexisting infrastructure. SP may choose to have the architecture validated by a 3rd\n\nParty.\nThe System will be used by staff and collectively known as users.\n\nThe system is rated as confidential for the data stored in the repository. Upon\naward the contractor shall comply with requirements specified in the Government\nprocedures for handling and accessing of data.\n\nThe Contractor shall be responsible for the creation and setup configuration on\nSharePoint that are essential for the operation of the System.\n\nSP is using SharePoint 2013 with MS SQL 2012 to host the existing farm. There\nare several applications already deployed to the farm. The servers (VMWare,\nWindows 2012) currently support access from the Internet and Intranet as shown\nbelow: The servers highlighted in GREEN are in the process of being setup. The\ncontractor is expected to enhance the farm with additional server resources to\nmeet the requirements of this tender without affecting the existing applications.\n\nMain Site\n(SPICE Centre 1)\n\nSAN Switches\n\nNVS\noau91s NNS\n\nDR Site\n\nThe database shall be configured to make use of WMware\u2019s HA/DR\nfunctionalities such as vMotion and SRM.\n\nThe servers used for the SharePoint farm are virtualized using VMWare. SP\nprefers to keep the configuration of any newly proposed virtual server to be of\n\nImplementation of ECM Using SharePoint 2013 and Migration Page 17\nPart 2 Requirement Specifications\nSection C \u2014 Functional Requirements\n\nsimilar configuration to the existing ones shown below:\n\nServer Function: Web-FrontEnd Server and App Server\nCPU: 8\n\nMemory: 16 GB\nDisk Controllers: VMware SCSI Controller\n\nSystem Disks: 100 GB\n\nData Disks: 200 GB\n\nNICs: 1 x Intel PRO/1000MT Network\nSoftware Configuration:\n\nOS: Windows 2012 Datacenter server\nSymantec Endpoint Protection 12.x\n\nServer Function: MS SQL Database Server\n\nCPU: 4\n\nMemory: 32 GB\n\nDisk Controllers: VMware SCSI Controller\nSystem Disks: 100 GB\n\nData Disks: 200 GB\n\nLog Disks: 50 GB\n\nNAS and SAN: 5 TB for other projects\nNICs: 2 x Intel PRO/1000MT Network\n\nSoftware Configuration:\n\nOS: Windows 2012 Datacenter server\nMS SQL Server 2012\n\nVeritas Netbackup Client 7.5\nSymantec Endpoint Protection 12.x\n\n14.8. The expected Recovery Time Objective (RTO) period for the system shall be 7\nworking days.\n\n14.9. The system shall be designed to scale for future growth of data. The Tenderer\nshall submit their proposal with a suitable SharePoint design with web-\napplications, Site-collections, libraries, etc.\n\n14.10. The design shall ensure optimal paths for data transfer via Internet and Intranet.\n14.11. Friendly URLs must be setup for all sites and displayed from the landing page.\n\n14.12. The design shall make use of SAN, NAS and RBS (Blob store) for storage. The\ntenderer shall propose the details of"}, {"FileName": "NTU_PACE_CETCRM Fees Calculation User Manual_V0.1.pdf", "GUID": "9e0b6ac7-f301-44b8-9436-5c4d5d5b9573              ", "FileName Path": "http://msfdemo.isearch.com:18605/Demo MSF/NTU_PACE_CETCRM Fees Calculation User Manual_V0.1.pdf", "FileName Version": 1, "Created DateTime": "2023-01-25 06:40:56.000", "Updated DateTime": "2023-01-25 06:40:56.000", "Created By": "Arun                                                                                                ", "Updated By": "Kumar                                                                                               ", "RawOCR": "NANYANG\nTECHNOLOGICAL TeBS\nUNIVERSITY\n\nCETCRM FEES, FUNDING &\nCREDITS\n\nReference Manual\n\nFEBRUARY 28, 2019\nTOTAL E-BIZ SOLUTIONS PTE LTD\ningapore\n\neg NANYANG\nOe!) TECHNOLOGICAL, TeBS\n\\\u00a539/ UNIVERSITY\nDOCUMENT VERSION\nVersion No. Prepared By Reviewed By Approved By Details\nV0.1 AKHILESH DUBEY | SENTHIL A. Initial Draft\n\nPage 1 of 17\n\neg NANYANG\nee) TECHNOLOGICAL TeBS\nFay UNIVERSITY\n\nContents\nFEES, FUNDING & CREDITS IN CETCRM..u....ssscssssessssesssessssessseesssessseessseessesssreesseessseenseeees 3\n1. INTRODUCTION ..0...esseesssessssesssssssesssvesssecsseesssecsseessseessessareessessseesseessseesseesaseessetaseeeseeses 3\n2. SUBSIDY TYPE o..ceccccecscessscsssesssessssesssesssseesseesssecssesssseessessssessseessseesseessreesseesaneesnesseneenseeees 3\n3. SUBSIDY SETUP .oi..ccecscsccssssssesssessssesssessssessseesssecsseesssecssesssseessesssseesseessseessessaneessessaneensesees 5\n4. CREDIT SETUP ..oe.scecssesssesssessssecssessssecsseesssecsssessnecsseesssecsseesssesssesssneesseessseesseesaseeasessaneesses 9\n5. AFFILIATIONS w0.....cssessssssssessssesssessssecsseesssecsseesssessseesssecssecsssessseesssesasessseessseesseessseesseesases 11\n6. COURSE EVENT FUNDING o...0..cccsssessssessssesssessssecesecsssecssessssesssecsssecssessseeseseesseessseesseess 12\n7. COURSE EVENT DISCOUNT ..0...scsssssssessssesssessssecssessssecsseesssesssesssesssessseeseseesseessseesseess 13\n8. COURSE EVENT CREDITS...0...ccsssessssessssesssessssesssecssvecssecsssessseesssesaseesseessseesseessseesseeesses 14\n9. COURSE EVENT FEE STRUCTURES. ..0....ssssesssesssessssessseesssesssessssessseesseessseesseeesseesseess 15\n10. PARTICIPANT FEE STRUCTURES ...0....cssscsssessssessssessseessseesseesssesssessssessseesseeeaseesseess 15\n\nPage 2 of 17\n\nNANYANG\n| | TECHNOLOGICAL TeBS\nFy UNIVERSITY\n\nFEES, FUNDING & CREDITS IN CETCRM\n\n1. INTRODUCTION\nThe purpose of this document is to explain the fees and funding module built in the NTU\nCETCRM 2016 application. The Fee & Funding module is instrumental for the application users\nto define the different factors that affect the fees calculation for the course events, provide\nsubsidised fee details and also let the users capture and apply the various discounts\napplicable. Finally, it helps the users ascertain the fees payable by the participants taking up\nthe course, based on their personal particulars and other factors.\nThe details of the module consist of various components like \u2014\n\ne Subsidy Type\n\ne Subsidy Setup\n\ne Credit Setup\n\ne Affiliations\n\ne Course Event Funding\n\ne Course Event Discount\n\ne Course Event Credit\n\ne Course Event Fee Structure\n\ne Participant Fee Structure\n\n2. SUBSIDY TYPE\nThe Subsidy Type screen is provided for the users to define the different funding types or\ndifferent funding organisation that are available for the courses being conducted by the PACE\ncentre. For example \u2014 Skills Future Series Singapore (SSG), Employment & Employability\nInstitute (e2i), etc.\nThe Subsidy Types will be a one-time setup (mostly) and do not change very frequently. To\n\nadd/ view or edit the subsidy types, following menu needs to be clicked on \u2014\n\nPage 3 of 17\n\nNANYANG.\nTECHNOLOGICAL TeBS\nUNIVERSITY\n\nMy Work Course Setup Course Management Configuration\nrss he i a-\u2014- OB\n\nOn clicking the Subsidy Type menu, following view will be loaded, which will list the subsidy\n\ntypes available in the system \u2014\n\n+ NEW [DELETE =~ = EMAILALINK | + [DF RUN REPORT \u00a5 BB excer TEMPLATES \u00a5 &, EXPORTTOEXCEL + (Mp IMPORTDATA + gif CH\n\n<\n\n~ Active Subsidy Types\n\nv Name\n\n10/17/2018 7:12 PM\n\n12/05/2018 11:30 AM\n\nIf the users want to add any new subsidy type or modify an existing one, they can do so either\nby clicking the +NEW button, or by double clicking one of the records and going inside it. The\n\nsubsidy type page will be opened similar to the below \u2014\n\nEASAVE =pg/SAVE& CLOSE \u201cNEW [\u00a7 DEACTIVATE [J] DELETE > EMAILALINK RUN WORKFLOW  [B] START DIALOG\n\nSUBSIDY TYPE : INFORMATION\n\nEmployment and Employability Institute (e2i) =\n\n\u00abGeneral\nName * Employment and Employability Institute (e2i)\nPublish in Web Page Yes\n\nPage 4 of 17\n\n45) 0 Rano IC. g TeBS )\n\nThe Subsidy Setup screen is provided for the users to define the different kinds of subsidy or\n\n3. SUBSIDY SETUP\n\nfunding that is being offered by the funding organisation. For e.g. the below list speaks about\nsome examples of the prevailing funding options offered by the funding organisation \u2014\ne Skills Future Series (SSG)\no Basic Subsidy \u2014 For Singapore Citizens & PR between aged 21 to 39 years old\no Mid-Career Enhanced Subsidy (MCES) \u2014 For Singapore Citizens aged 40 years\nold and above\no Enhanced Training Support for SMEs (ETSS) \u2014 For Singapore Citizens and\nSingapore Permanent Residents who are sponsored by their SME employers\nfor the course\no Workfare Training Support (WTS) \u2014 For Singapore Citizens aged 30 years old &\nabove (13 years & above for persons with disabilities) and earn an average\ngross monthly income of not more than $2,000 for the months worked\ne Employment & Employability Institute (e2i)\no Subsidy based on Course Fee \u2014 For Singapore Citizens & PRs, based on a\npercentage of Course Fees (e.g. 50% of Course Fee)\no Based onno. of training hours \u2014 For Singapore Citizens & PRs, based on the no.\nof training hours X $15 (let\u2019s say) per hour\no Capped Amount - For e.g. a capped amount of $50\nTo do a setup of the above subsidies/ funding in the system, user may need to open the\n\nsubsidy setup screen from the menu displayed below \u2014\n\nOn clicking the Subsidy Setup menu, following view will be loaded, which will list the subsidy\n\nsetups available in the system \u2014\n\nPage 5 of 17\n\nBRAA NA NG\n45) U NAN ICAL TeBS\nSay UNIVERSITY\n\n~ Active Subsidy Setup = p\n\nIf the users want to add any new subsidy setup or modify an existing one, they can do so\neither by clicking the +NEW button, or by double clicking one of the records and going inside\n\nit. The subsidy setup page will be opened similar to the below \u2014\n\nETUP MATION\n\nSkillsEuture Series - Basic Subsidy =\n+General\n\nSkillsFuture Series - Basic Subsidy No limit\nSSG\n\nSkillsFuture Series (SSG)\n70.00\n\nProvide basic subsidy for course fee and tax\n\nS'pore Citizens (21 to 39 yrs old)\nor S'pore PRs (> 21 yrs old)\n\nIn the above screen, following is the details of the fields \u2014\n\ne Name - This is a text field that the users can use to provide the name of the subsidy\nsetup. For e.g. one setup can be named as \u2018Skills Future Series \u2014 Basic Subsidy\u201d or\n\u201cSkills Future Series - Enhanced Subsidy\u201d or \u201cSkills Future Series - ETSS\u201d, and so on.\n\ne Subsidy Code -\u2014 This is a text field that the users can use to provide the short\nabbreviation or code of the funding organisation or subsidy type that is providing this\nsubsidy/ funding option. For e.g. \u201cSSG\u201d, \u201ce2i\u201d, etc.\n\ne Subsidy Type \u2014 This is a lookup field in which the users can select the subsidy type (or\n\nthe funding organisation), the parent that would be providing this subsidy. This helps\n\nPage 6 of 17\n\nbred Nanos, TeBS\n\u2018F55/ UNIVERSITY\n\nto establish the relationship between the subsidy type and the subsidy setup. Users\ncan choose from the existing list of subsidy types configured in the system (Subsidy\nType is detailed in the point 2 above).\n\nBasic Funding% - This is a text field of percentage type where users can enter the\nsubsidy percentage to be applied for this subsidy setup.\n\nEnhanced Funding Description \u2014 The field to be used for describing the criteria due to\nwhich the enhanced funding percentage may be applicable. For e.g. additional 20% of\nMCS or additional 25% for WTS and so on.\n\nEnhanced Funding% - This is a text field of percentage type where users can enter the\nadditional subsidy percentage to be applied for this subsidy setup. For e.g. additional\n20% of MCS or additional 25% for WTS and so on.\n\nSubsidy Option \u2014 This is a drop-down field with the following allowable values \u2014\n\no Provide basic subsidy for course fee \u2014 This option is selected by the users\nwhen the basic funding percentage has to be applied on the course fee alone\n(i.e. Nett Course Fee OR Not the Course Fee + GST)\n\no Provide basic subsidy for course fee and tax \u2014 This option is selected by the\nusers when the basic funding percentage has to be applied on the course fee\nand tax (i.e. Full Course Fee OR Course Fee + GST)\n\no Provide basic and enhanced subsidy for course fee and tax \u2014 This option is\nselected by the users when the basic and enhanced both funding percentages\nput together have to be applied on the course fee and tax (i.e. Full Course Fee\nOR Course Fee + GST)\n\nSubsidy Basis \u2014 This is a drop-down field with the following allowable values \u2014\n\no No limit \u2014 This option is selected by the users when the funding application\n(basic and/or enhanced) has to be applied and there is no capped amount for\nthe funding.\n\no Based on absolute amount \u2014 This option is selected by the users when the\nfunding has to be applied as a fixed amount in SGD\n\no Based on no. of class hours \u2014 This option is selected by the users when the\n\nfunding amount is based on the no. of class hours specified in the course event\n\nPage 7 of 17\n\nbred Nanos, TeBS\n\\335/ UNIVERSITY\n\nlevel. The no. of class hours is then multiplied by the another field value on the\nsubsidy setup page \u2014 \u201cSubsidy rate per hour\u201d\n\no Lower of capped amount and hourly rate \u2014 This option is selected by the users\nwhen the funding decision is based on the \u2018no. of class hours X the subsidy rate\nper hour\u2019 but not to be exceeded the capped amount of \u2018A\u2019 dollars.\n\nSubsidy Rate per hour \u2014 This is the text field to enter the per hour subsidy rate, like\n$15 per hour or $20 per hour, etc. This rate is then multiplied by the no. of course\nhours mentioned in the course event level, as explained above as well.\n\nCapped Amount - If there is a highest capped amount up to which only the subsidy\nwill be provided by the funding organisation, users can use this field to enter the dollar\namount.\n\nApplies to Singapore Citizen \u2014 This is a \u201cYes/No\u201d field for the users to specify whether\nthis subsidy setup will be applicable to Singapore Citizens or not. So, at the time of\nascertaining whether a person is entitled for the funding based on this subsidy setup,\nsystem will read the \u201cCitizenship\u201d field in the Participant personal particulars and will\napply this funding if the value selected there is \u201cSingapore Citizen\u201d.\n\nApplies to Singapore PR \u2014 This is a \u201cYes/No\u201d field for the users to specify whether this\nsubsidy setup will be applicable to Singapore permanent residents or not. So, at the\ntime of ascertaining whether a person is entitled for the funding based on this subsidy\nsetup, system will read the \u201cCitizenship\u201d field in the Participant personal particulars\nand will apply this funding if the value selected there is \u201cSingapore PR\u201d.\n\nStart Age to Avail \u2014 This is a number text field to determine the starting age based on\nwhich this subsidy or funding can be availed by the participants. So, at the time of\nascertaining whether a person is entitled for the funding based on this subsidy setup,\nsystem will read the \u201cBirthday\u201d field in the Participant personal particulars and will\nsubtract the year part from the current year and if the value is greater than or equal\nto the value specified here, then system will apply this funding.\n\nTraining Support for SMEs - This is a \u201cYes/No\u201d field for the users to specify whether\nthis subsidy setup will be applicable to participant nominated by an SME company or\n\nnot. So, at the time of ascertaining whether a person is entitled for the funding based\n\nPage 8 of 17\n\nERXA NANYANG\noF TECHNOLOGICAL\n\nPS) UNIVERSITY reas)\non this subsidy setup, system will read the \u201cSME\u201d field in the Participant company\ndetails and will apply this funding if the value selected there is \u201cYes\u201d.\n\ne Low Salary Amount - This is a number text field to determine the salary amount below\nwhich this subsidy or funding can be availed by the participants. So, at the time of\nascertaining whether a person is entitled for the funding based on this subsidy setup,\nsystem will read the \u201cSalary Range\u201d field in the Participant personal particulars and\nwill ascertain if the value selected there has the lower value in the range smaller than\nthe value specified in the subsidy setup, then system will apply this funding.\n\ne Terms & Conditions \u2014 This is a multi-line text field for the users to enter the details of\nthis subsidy setup. This same text appears in the website also while displaying the\n\navailable funding available for a particular course event.\n\n4. CREDIT SETUP\nThe Credit Setup screen is provided for the users to define the different kinds of credits or\nthat are available to be used for paying course event fees. For e.g. the below list speaks about\nsome examples of the prevailing credit options available \u2014\n\ne Alumni Course Credits (ACC)\n\ne Skills Future Credits (SFC)\n\ne Union Training Assistance Programme (UTAP)\nTo do a setup of the above credits in the system, user may need to open the credit setup\n\nscreen from the menu displayed below \u2014\n\n\u20ac > CA Notsecure\n\nuceterm.ntu.edusg,\n\nMy Work Course Setup Course Management Configuration\nFlee Ew Oo. > Bess\n\nOn clicking the Credit Setup menu, following view will be loaded, which will list the subsidy\n\nsetups available in the system \u2014\n\nPage 9 of 17\n\neg NANYANG\n| | TECHNOLOGICAL TeBS\noF UNIVERSITY\n\n* Active Credit Setups\n\nIf the users want to add any new credit setup or modify an existing one, they can do so either\nby clicking the +NEW button, or by double clicking one of the records and going inside it. The\n\ncredit setup page will be opened similar to the below \u2014\n\nbdsave GF\u2019sal\n\nOSE \u201cNEW |g DEACTIVATE [ff DELETE $8 ASSIGN \u20ac) SHARE @EMAILALINK RUN WORKFLOW\n\nCREDIT SETUP : INFORMATION\n\nAlumni Course Credit (ACC) =\n\u00abGeneral\n\nACC\n$1,600.00\n\nIn the above screen, following is the details of the fields \u2014\n\ne Credit Name \u2014 This is a text field that the users can use to provide the name of the\ncredit setup. For e.g. one setup can be named as \u2018Alumni Course Credit (ACC)\u201d or \u201cSkills\nFuture Credit (SFC)\u201d or \u201cUnion Training Assistance Programme (UTAP)\u201d, and so on.\n\ne Credit Code \u2014 This is a text field that the users can use to provide the short\nabbreviation or code of the credit type. For e.g. \u201cACC\u201d, \u201cSFC\u201d, \u201cUTAP\u201d etc.\n\ne Capped Amount - If there is a highest capped amount up to which only the credit will\nbe provided, users can use this field to enter the dollar amount.\n\ne Credit Admin Fees - This is a text field of amount here users can enter the admin fees\nthat will be charged by the center for letting the participant utilize this type of credit.\ne Publish in Web Page \u2014 The is a \u201cYes/No\u201d field to be used for specifying if this credit\n\nsetup has to be made available in the website for the users to utilize. This field was\n\nalso present in the legacy CRM3.0 system.\n\nPage 10 of 17\n\nNANYANG.\nOe TECHNOLOGICAL TeBS\nJ UNIVERSITY\n\nThe Affiliation screen is provided for the users to define the different kinds of affiliation that\n\n5. AFFILIATIONS\n\nthe participant may have. For e.g. the below list speaks about some examples of the prevailing\naffiliations available \u2014\n\ne Group Registration\n\ne NTU/NIE Alumni, Staff & Students\n\ne NTUC Member\n\ne University Full Time Student\n\ne University Staff\n\ne Early Bird Registration\nTo do a setup of the above affiliations in the system, user may need to open the affiliations\n\nscreen from the menu displayed below \u2014\n\nEY CETCRMUAT\n\nCourse Management Configuration\n\nTraining Materials Master\n\nTrainer\n\nB\nfl\n= \u2122\nOi\n\nOn clicking the Affiliations menu, following view will be loaded, which will list the Affiliations\n\navailable in the system \u2014\n\n> Active Affiliations \u00bb\n\n6PM\n\n10/17/2018 7:17 PM\n\nIf the users want to add any new Affiliation or modify an existing one, they can do so either\nby clicking the +NEW button, or by double clicking one of the records and going inside it. The\n\nAffiliation page will be opened similar to the below \u2014\n\nPage 11 of 17\n\neg NANYANG\n| | TECHNOLOGICAL TeBS\noF UNIVERSITY\n\nFASAVE Gq/SAVE& CLOSE \u201cFNEW [6 DEACTIVATE ji] DELETE 9 EMAILALINK @@RUNWORKFLOW [BI STARTDIALOG [ff] WORD TEMPLATES >\n\nAFFILIATION : INFORMATION\n\nNTUC Member -\n\n\u00abGeneral\n\nName * NTUC Member\n\nIn the above screen, following is the details of the fields \u2014\ne Name - This is a text field that the users can use to provide the name of the affiliation.\nFor e.g. one affiliation can be named as \u201cNTUC Member\u201d or \u201cNTU/NIE Alumni, Staff &\n\nStudents\u201d, and so on.\n\n6. COURSE EVENT FUNDING\n\nThe Course Event Funding functionality is provided for the users to associate a particular\ncourse events with the funding options available to be utilized. The Course Event Funding can\nbe entered from within the Course Event at the time of defining or proposing the course\nevent. The Course Event Funding grid/ table is available in the Course Event Screen as\n\ndepicted below \u2014\n\nwi ld u + \u2122 a o FEESTRUCTURES 9\n\nW | Together we create a better an... = Propet\n: Yes\n\nNo\n\nSCHEDULE\n\n02/14/2019\n02/15/2019\n\nIn the above example the Course event is deemed to be funded by the Skills Future Series\n(SSG) funding. The 4 related \u2018FUNDING\u2019 records suggest that these 4 subsidy setups \u2014 Basic,\nMCES, ETSS & WTS are being applicable or available to be utilized by the participants of the\ncourse event.\n\nTo add or modify a funding/ subsidy setup with the Course Event, users can click on the \u2018+\u2019\n\nbutton above the grid or table and the following screen will pop-up for the users, with the\n\nPage 12 of 17\n\nbeg TetnoLouen, reas)\nas UNIVERSITY\n\nCourse Event already filled-in and the funding can be selected to associate with the Course\n\nEvent \u2014\n\nHE Course Event Subsidy: New Course Event Subsidy - Google Chrome - Oo x\n\n@ Notsecure | ucetcrm.ntu.edu.sg MUA = 2 =%3F_ ft 203B-D304 0F B.\n\nMicrosoft Dynamics CRM = __ EduSenz ~ Course Event Subsidy |\u00bb New Course Event S...\n\nEdsave pisave& close \u201cNEW ES FORMEDITOR\n\nCOURSE EVENT SUBSIDY : INFORMATION\n\nNew Course Event Subsidy =\n\u00abGeneral\n\nCourse Event * W | Together we create a better and smarter city (Int\n\n4 Administration\n\nCreated By a-\n\nCreated On a-\n\n7. COURSE EVENT DISCOUNT\n\nThe Course Event Discount functionality is provided for the users to associate a particular\ncourse events with the fee discounting options available to be utilized. The Course Event\nDiscount can be entered from within the Course Event at the time of defining or proposing\nthe course event. The \u201cDISCOUNTS ALLOWED\u201d grid/ table is available in the Course Event\n\nScreen as depicted below \u2014\n\nswe GPswves + Bo iS OEACTIVATE Mf DELE NERA RUCTURES SBASSIGN C)SHARE oe\n\nase Rie\n\nW | Together we create a better an... = Papas\n\nFORMATION\n\n$834.60 DISCOUNTS ALLOWED\n\name *\n\n14 February 2019 to 15 February 2019\n\nYes\n\nPage 13 of 17\n\nsea NANYANG\nOE TECHNOLOGICAL TeBS\nFay UNIVERSITY\n\nWhichever discounts/affiliation will be associated with a course event in this screen, will be\nmade available to be selected at the time of participant web registration as checkbox to\nmention the affiliation.\n\nEvery time a user sets up a new course event, they will have to add the affiliation/ discount,\notherwise it won\u2019t be available to be selected by the participants at the time of web\n\nregistration.\n\n8. COURSE EVENT CREDITS\n\nThe Course Event Credit functionality is provided for the users to associate a particular course\nevent with the credit options available to be utilized. The Course Event Credit can be entered\nfrom within the Course Event at the time of defining or proposing the course event. The\n\u201cCREDITS\u201d grid/ table is available in the Course Event Screen as depicted below \u2014\n\ntd u + . ] RATE FE mes $B\n\nW | Together we create a better an... =\n\nProposed\n\nse34.60 ure $58422\n\n$834.60 Sk 2 Ses $586.0\n\nCOURSE DETAILS\n\nito one of the ptaces on\nan ambitious Smart Nation program. Singapore has become a test he application of Big Data and Internet of Things\n\nInternet to every home and otfice. It\nof the Smart Nation program is to\nsettings. In one Singapore neighborhood. thousands of sensors installed on individual apartments to measure energy draw,\nwaste production, and water usage in real time\n\nWhichever credits will be associated with a course event in this screen, will be made available\nto be opted by the participant as the method to offset the course fee and/or tax over the fee\ncomponents.\n\nEvery time a user sets up a new course event, they will have to add the credits, otherwise it\nwon't be available to be selected by the participants as the method to offset the course fee\n\nand/ or the tax over the fee components.\n\nPage 14 of 17\n\neg NANYANG\nee) TECHNOLOGICAL TeBS\nFay UNIVERSITY\n\n9. COURSE EVENT FEE STRUCTURES\n\nThe Course Event Fee Structure functionality is provided for the users to generate and\nassociate various fee structures to a particular course event. The multiple fee structures that\nwill be generated and associated will be based on the various funding and credits already\nassociated with the course events. The \u201cFEE STRUCTURES\u201d grid/ table is available in the\n\nCourse Event Screen as depicted below \u2014\n\na G + s E @ cee t F J s\n\nWw | logeth\n\nFUNDING CATEGORY\n\ncREDITS\n\nCOURSE DETAILS\n\nWhichever Fee Structures will be associated with a course event in this screen, will be made\navailable to be considered when applying which fee structure will be applicable on the\n\nparticipant.\n\nEvery time a user modifies the factors affecting the Course Fee Structures (Fee Amount, GST,\nNo. of training hours, Funding, Credit & Affiliation), they will have to run the function \u2014\n\u201cGENERATE FEE STRUCTURES\u201d \u2014 to generate and associate the new set of fee structure\n\napplicable on the course event.\n\n10. PARTICIPANT FEE STRUCTURES\n\nThe Participant Fee Structure functionality is provided for the users to generate and associate\nthe applicable course fee structure to a particular participant based on the various participant\ndetails. The participant fee structures will be generated and associated when the Status\nReason of the Participant record is changed to \u201cPending Fee Payment\u201d. The Fee Tab in the\nParticipant screen shows the detailed breakup of the fees applicable to the participant and\n\nthe applicable participant fee structure. Same is depicted below \u2014\n\nPage 15 of 17\n\neg NANYANG\nee) TECHNOLOGICAL TeBS\nFay UNIVERSITY\n\nPending Fee\n\nFees Details Payment Details\n\n@ $780.00 -\n\n2 Fee @ $834.60\n\nIn the Fees & Payment tab, the left hand of the screen \u2014 \u201cFee Details\u201d \u2014 consists of the\n\nfollowing details \u2014\n\nCourse Fees (w/o GST) \u2014 This is a locked field that stores the Nett Course Fee (w/o\nGST) for the Course Event for which the participant has applied for. This is driven from\nthe Course Screen.\n\nCourse Fees (with GST) \u2014 This is a locked field that stores the Full Course Fee (with\nGST) for the Course Event for which the participant has applied for. This is driven from\nthe Course Screen.\n\nParticipant Affiliation Applied \u2014 If the participant is having any affiliation (one or\nmany), one of it will be tagged in this field based on which affiliation provides the\nmaximum discount in the fee payable. For e.g. if a participant declares both being an\nNTU/NIE Alumni, getting a 10% discount privilege and NTUC Member, getting a 15%\ndiscount privilege,\n\nCourse Fees Discount \u2014 This field is a descriptive text field that shows the calculation\nand application of discount on the Course Fees; and this will remain blank if no\ndiscount has been provided to the participant\n\nDiscount Amount \u2014 This is an amount field that shows the discounted fee amount;\nand this will remain blank if no discount has been provided to the participant.\nParticipant Fee Structure \u2014 This field references the Course Fee Structure that is\n\napplicable to this participant based on the values of different participant fields that\n\nPage 16 of 17\n\nbred Nanos, TeBS\n\u2018F55/ UNIVERSITY\n\nare factors of determining the fee payable, like, Citizenship, Age, Salary Range, Is SME,\netc.\n\nFee Structure Applied \u2014 The Course Fee Structure that has been picked to prepare the\napplicable Participant Fee Structure Applied. This gives the users the ability to traverse\nthrough the details of the Fee Structure that got applied and understand the reason\nwhy it got applied.\n\nFunding Amount \u2014 The amount of funding or subsidy that got applied\n\nDiscount/ Funding Applicable \u2014 This is a drop-down field that gets automatically set\nto either \u201cFunding\u201d or \u201cDiscount\u201d based on the participant fee structure selected.\nDiscount/ Funding Amount Applied \u2014 This is an amount field that gets automatically\nfilled by the discount/ funding amount based on the participant fee structure selected.\nCredit Availed \u2014 This is a lookup field to Course Event Credit entity to select the type\nof credit (for e.g. ACC or SFC or UTAP, etc.) based on the participant\u2019s decision of credit\nusage and subject to credit amount availability.\n\nAlumni Credit Amount \u2014 The amount the participant wishes to spend from the course\ncredit available.\n\nCredit Admin Fees \u2014 The amount of admin fees for the sake of credit being utilized.\nFee Others \u2014 This field is provided as an additional mechanism to add any other fees\ncomponent which is ad-hoc in nature or perhaps is a result of some kind of fee\nadjustment like courier charges, postal charges, etc.\n\nNett Fees (Payable) \u2014 This is an automatic field that shows the final amount to be paid\nby the participant.\n\nRefund \u2014 In the event of a refund situation, this amount field is used to adjust the\nrefunded amount.\n\nPayment Status \u2014 This is a drop-down field that is driven by the payment gateway\nresponse regarding the online payment made by the participant.\n\nMode of Payment \u2014 The drop down field that captures the mode of payment like\n\u201cCheque\u201d, \u201cBank Draft\u201d, \u201cTelegraphic Transfer\u201d, \u201cOnline (Credit/ Debit Card)\u201d, \u201cOne\nStop\u201d.\n\nApproved PSEA Amount \u2014 The amount field for the user to capture the PSEA amount\n\napproved for the participant\u2019s fee payment.\n\nPage 17 of 17\n\n"}, {"FileName": "NintexWorkflow2013Helpfile.pdf", "GUID": "fc7c522c-36e5-4099-b807-2b722db47512              ", "FileName Path": "http://msfdemo.isearch.com:18605/Demo MSF/NintexWorkflow2013Helpfile.pdf", "FileName Version": 1, "Created DateTime": "2023-01-25 06:40:56.000", "Updated DateTime": "2023-01-25 06:40:56.000", "Created By": "Govind                                                                                              ", "Updated By": "Arun                                                                                                ", "RawOCR": "oe .. ;\n\u00a9 Nintex\u2019 Workflow\nx\n\nNintex Workflow 2013 Help\n\nLast updated: Friday, May 08, 2015\n\n1 Workflow Actions\n.1 Action Set\n.2 Add User To AD Group\n3 Assign Flexi Task\nA Assign To-Do Task\n5 Build String\n.6 Calculate Date\n.7 Call web service\n.8 Capture document set version\n.9 Change State\n.10 Check in item\n.11 Check Out Item\n.12 Collection Operation\n.13 Commit pending changes\n.14 Compile Audience\n.15 Complete Workflow Task\n.16 Convert Document\n.17 Convert Value\n.18 Copy item\n.19 Copy to file share\n.20 Copy to SharePoint\n.21 Create AD Group\n.22 Create AD User\n.23 Create appointment\n.24 Create Audience\n.25 Create CRM Record\n.26 Create item\n.27 Create item in another site\n.28 Create list\n.29 Create Site\n.30 Create Site Collection\n.31 Create task\n.32 Declare as record\n.33 Decommission AD User\n.34 Decommission Site Collection\n.35 Delegate Workflow Task\n.36 Delete / Disable CRM Record\n\n\u00a9 2015 Nintex Global Ltd. All rights reserved. Nintex Confidential\n.37 Delete AD Group\n38 Delete Audience\n39 Delete drafts\n.40 Delete Item\nAl Delete multiple items\n42 Delete previous versions\n.43 Delete site\n.44 Discard check out\n.45 Enable Lync / OCS\n.46 End workflow\n47 Execute SQL\n.48 Filter\n.49 Find users by status\n.50 For Each\n.51 Get meeting suggestions\n.52 Get user status\n.53 Log in the History List\n.54 Loop\n\n.55 Math operation\n.56 Pause for\n\n.57 Pause Until\n.58 Provision User In Exchange\n.59 Publish Workflow\n.60 Query BCS\n.61 Query CRM\n.62 Query Excel Services\n.63 Query LDAP\n.64 Query List\n.65 Query User Profile\n.66 Query XML\n.67 Read Document\n.68 Regular Expression\n.69 Remove User From AD Group\n.70 Request Approval\n.71 Request Data\n.72 Request Review\n.73 Retrieve data\n.74 Run If\n.75 Run parallel actions\n.76 Search Query\n.77 Send / Receive Biztalk\n.78 Send document set to repository\n.79 Send document to repository\n.80 Send notification\n.81 Set a condition\n.82 Set a variable\n\n\u00a9 2015 Nintex Global Ltd. All rights reserved. Nintex Confidential\n.83 Set approval status\n.84 Set document set approval status\n.85 Set field value\n.86 Set item permissions\n.87 Set workflow status\n.88 Start workflow\n.89 State Machine\n.90 Store data\n.91 Submit Record\n.92 Switch\n.93 Task reminder\n.94 Terminate workflow\n.95 Undeclare as record\n.96 Update AD User\n.97 Update CRM record\n.98 Update document\n.99 Update item\n.100 Update multiple items\n.101 Update User Profile\n.102 Update XML\n.103 Wait for an item update\n.104 Wait for check out status change\n.105 Web Request\n2 Using Nintex Live Connector for Nintex Workflow 2013\n2.1 Access Management\n2.2 Adding and removing services\n2.3 Catalog Settings\n2.4 Nintex Live Workflow Settings\n2.5 Using the Nintex Live Catalog\n3 Workflow Interaction with SharePoint\n3.1 About LazyApproval\n3.2 Approving, Rejecting and Reviewing Items\n3.3 Configuring the Chart Viewer Webpart\n3.4 Configuring the Report Viewer Webpart\n3.5 Delegating Approval Tasks\n3.6 InfoPath Forms\n3.7 Managing Workflow Change Approval\n3.8 Managing workflow history lists\n3.9 My Workflow Tasks web part\n3.10 Reusable Workflows\n3.11 Scheduling a workflow\n3.12 Set Title and Description for Reusable Workflow Template\n3.13 Site Workflows\n3.14 Starting a workflow\n3.15 Updating User Defined Action in Published Workflows\n3.16 User Defined Action Parameters\n\n\u00a9 2015 Nintex Global Ltd. All rights reserved. Nintex Confidential\n3.17 User Defined Action Settings\n3.18 User Defined Actions\n3.19 Viewing workflow history\n3.20 Viewing workflow status\n3.21 Workflow Change Approval\n3.22 Workflows I have started web part\n4 Administration and Configuration\n4.1 SharePoint IDs for Nintex Features\n4.2 Support packages\n4.3 Monitoring workflow errors\n4.4 Preventing excessive looping iterations\n4.5 Creating support packages\n4.6 Licensing settings\n4.7 Database settings\n4.8 Manage content databases\n4.9 Web Application activation settings\n4.10 Managing workflow actions\n.11 Global Settings\n2 Managing LazyApproval settings\n3 Defining message templates\n4 Activating Nintex Workflow\n5 Configuring user preferences\n.16 Security Settings\n7 Manage Context Data\n8 Purge workflow data\n9 Managing workflow error notification settings\n\naN\n\nAUR IAIALR\n\nAAS\n\n5 Using the Workflow Designer\n\n5.1 Getting started with the Nintex Workflow designer\n\n5.2 About connections\n5.3 Association columns\n5.4 Connection Manager dialog box\n5.5 Create Connection dialog box\n5.6 Error Handling\n5.7 Importing and exporting workflows\n5.8 Inline functions\n5.9 Inserting reference fields\n5.10 LDAP Picker\n1 Managing connections to external providers\n2 Managing Start Variable Order\n3 Managing Workflows\n4 Opening and saving workflows\n.15 Printing\n6 Publishing a workflow\n.17 Run Now\n.18 Set action labels\n\n.19 Using lookups\n\nWr Jor Jr for fon\n\nNn\n\n\u00a9 2015 Nintex Global Ltd. All rights reserved. Nintex Confidential\n5.20 Verbose logging\n5.21 Workflow Action Common Settings\n\n5.22 Workflow Constants\n5.23 Workflow gallery\n5.24 Workflow Settings\n5.25 Workflow Snippets\n5.26 Workflow start data\n5.27 Workflow templates\n5.28 Workflow variables\n5.29 XPath Query Builder\n\n\u00a9 2015 Nintex Global Ltd. All rights reserved. Nintex Confidential\n1 Workflow Actions\n\n1.1 Action Set\n\nThis workflow action bundles a collection of actions in a container that can be collapsed and\nexpanded to make workflow designing more convenient.\n\nTo use the workflow action:\n\ne Locate the action in Workflow Actions Toolbox (located on the left hand-side);\no Click on the Category listings to reveal the actions; OR\no Search for the action using a keyword.\n\ne Select the action, drag it onto the design canvas and drop it onto a design pearl.\n\nAlternatively\n\ne Left-clicking the pearl, mouse-over Insert Action and then the Categories to reveal the\nactions, click the required action from the list.\n\nOptions for this action\n\nThis action does not require any configuration. It has a border that contains a pearl, when actions\nare added to the pearl inside the border, they become part of the Action set.\n\nAction set hd\n\n& Configure\n\n[A Save as Snippet\n\nBa Copy Save as Snippet\n\n\u00a9 Disable\n\nX_ Delete\n\n\u00a9) Minimize\nThe action set can be minimized by activating the title bar's drop down menu and clicking\nMinimize.\n\n\u00a9 2015 Nintex Global Ltd. All rights reserved. Nintex Confidential\nAction set bd\n\n| Configure\n\n[i Save as Snippet\nGa Copy\n\n\u00a9 Disable\n\nX _ Delete\n\nEH) Minimize h\nSaving as a snippet\n\nTo save an action set as a snippet, activate the drop down menu on the action title bar and click\nSave as Snippet. For more information, please refer to the Workflow Snippets.\n\n1.2 Add User To AD Group\n\n* This topic applies to Nintex Workflow Enterprise Edition only\nThis workflow action will add a user to an Active Directory security group.\nTo use the workflow action:\ne Locate the action in Workflow Actions Toolbox (located on the left hand-side);\no Click on the Category listings to reveal the actions; OR\n\no Search for the action using a keyword.\ne Select the action, drag it onto the design canvas and drop it onto a design pearl.\n\nAlternatively\n\ne Left-clicking the pearl, mouse-over Insert Action and then the Categories to reveal the\nactions, click the required action from the list.\n\nTo change the settings used by the action:\ne On the action\u2019s title click the down arrow to activate a drop-down\ne Select Configure; OR\n\ne Double-click the action's icon.\n\nFor more information on the other options in the drop-down, please refer to the Getting started\nwith the Nintex Workflow designer, \u201c\u201c\n\n\u00a9 2015 Nintex Global Ltd. All rights reserved. Nintex Confidential\nConfigure Action - Add user to AD group\n\nHeaai2z\u00a2\u00e9 & @\n\nSave Cancel Action Labels Common Variables Help\n\nCommit Settings Variables\n\nActive Directory details\n\nLDAP path * E &\n\nUsername * a\n\nPassword\n\nAdd user to AD group\n\nUser * EB\nGroup * EB\n\u00a9 Error the workflow if the user already exists in the group\n\n+] Error handling @\n\nOptions within this action\n\nActive Directory Details\n\nLDAP Path\n\nTo configure the LDAP Path, refer to the LDAP Picker for more information.\nAdd User to AD Group\n\nUser\n\nThe username (sAMAccountName) of the Active Directory entry.\n\nGroup\n\nThe name of an existing Group to which the user will be added. E.g. \"Backup Operators\".\nMultiple groups can be separated with semi-colons (;).\n\nError the workflow if the user already exists in the group\n\nSelecting this option will cause the workflow to error if the user already exists in the group. By\ndefault this option is checked.\n\n1.3 Assign Flexi Task\n\n\u00a9 2015 Nintex Global Ltd. All rights reserved. Nintex Confidential\nThis workflow action will allow the assignment of a task to one or more users and request a\nspecific outcome. The list of possible outcomes is determined by the person designing the\nworkflow.\n\nTo use the workflow action:\ne Locate the action in Workflow Actions Toolbox (located on the left hand-side);\no Click on the Category listings to reveal the actions; OR\no Search for the action using a keyword.\ne Select the action, drag it onto the design canvas and drop it onto a design pearl.\n\nAlternatively\n\ne Left-clicking the pearl, mouse-over Insert Action and then the Categories to reveal the\nactions, click the required action from the list.\n\nTo change the settings used by the action:\ne On the action\u2019s title click the down arrow to activate a drop-down\ne Select Configure; OR\n\ne Double-click the action's icon.\n\nFor more information on the other options in the drop-down, please refer to the Getting started\nwith the Nintex Workflow designer, \u201c\u201c\n\n\u00a9 2015 Nintex Global Ltd. All rights reserved. Nintex Confidential\nReject +\n\nAssign Flexitask +\n\n)\n\nConfigure Action - Assign Flexi task\n\nGENERAL\n\nHaim Hw ek BOF & O\n\nNot Required Reminders Escalation Edit Task Labels Common Variables Help\n\nSave Cancel Action Task\n\nNotification Notification Form +\nCommit Settings\nTask description\nOutcomes DD approve X\nG reject X\nAdd outcome\nBehaviour\n\nStore outcome in\n\nStore outcome achieved in\nTask name\n\nTask content type\n\nPriority\n\nDue Date\n\nForm type\n\nStore task IDs in\n\n@ First response applies\nO Majority must choose a specific outcome\nOAll must agree on a specific outcome\n\nWorkflow task\n\nNintex Workflow Multi Outcome Task\n\n(2) Normal\n\nValue v\n\nDefault\n\nOptions within this action\n\nRibbon Option: Action\n\nAssignees\n\nThe assignees list contains all users or groups that will be assigned the task when the\n\nworkflow is run.\n\nVariables Help\n\ninsert Reference 7\n\nO majority decides\n\nOAall must agree\n\nKk) kK]\n\n[x]\n\nB\n\nfl\n\n[x] [Kk]\n\npocecece\n\n\u00a9 2015 Nintex Global Ltd. All rights reserved. Nintex Confidential\nUsers can be:\n\n= Entered directly using their username, email address or full name\nand will be resolved where possible against the SharePoint user list\nor Active Directory.\n\n= Searched for: click on the address book icon on the right.\n\nPlease note that users that are external to the SharePoint environment can be added\nas Assignees by specifying their email address. However, the only way that they\ncan respond to the Task is through LazyApproval, as they will have no access to the\nSharePoint site.\n\nSelect People and Groups\n\nTo search for users, click on the address book icon on the right.\n\n3) Search for people and groups from the directory, add external email addresses or select addresses from the lookup list.\n\n= Internal Search\n\nFind & List View bd\nA Organizations Display Name E-mail Address Title Department Presence Worl\nA All Users Type into the search box above then press \u201cEnter\u201d to start your search,\n\nSi Active Directory\n\nGg, SharePoint Groups\n\n+ Lookup\n\nSelections\n\n{ OK JI Cancel }\n\nThe configuration dialog allows the workflow designer to search for and/or add users to\nthe Assignees list by one or more of the following methods:\n\ne Internal Search: Entering a partial display name, email address or user account\nname and clicking on the magnifying glass will provide a list of matching users\nand groups from SharePoint as well as Active Directory.\n\ne External email address: Enter an external email address manually. Where\npossible Nintex Workflow will resolve this to an actual user account.\n\n\u00a9 2015 Nintex Global Ltd. All rights reserved. Nintex Confidential\ne Lookup: Provides the option of adding a dynamic reference as an approver. e.g.\nWorkflow variable, list field.\n\nClick the title bar to expand or collapse each option.\n\nCreate individual tasks for all group members\n\nIn the case where a group is assigned the task and Create individual tasks for all group\nmembers checkbox is:\n\ne Not selected - all users in that group will receive the task notification. However,\nthe first respondent will represent the entire group.\ne Selected - an individual task will be assigned to every member of the group.\n\nGroups will only be expanded to one level. Groups within groups will not be expanded.\n\nAllow delegation\n\nWhen this option is selected, the assignee at runtime can delegate the task to another user.\nFor more information, please refer to Delegating Approval Tasks. Changing the 'Allow\ndelegation' option on the 'Action' screen is the same as changing the 'Allow delegation'\noption for all assignees on the 'Task Notification' ribbon option. See the 'Task\nNotification' ribbon option section below for more information.\n\nAllow LazyApproval\n\nIf LazyApproval has been enabled, the workflow can permit the assignees to use\nLazyApproval. Lazy Approval means that a task response can be registered when the\nassignee replies to a notification email or an automated OCS / Lync conversation with a\nrecognized word or phrase. An administrator can edit or add to the list of acceptable\nterms. For more information, please refer to the Managing LazyApproval\n\nsettings. Changing the allow LazyApproval option on the 'Action' ribbon option is the\nsame as changing the 'Allow LazyApproval' option for all assignees on the 'Task\nNotification' ribbon option. See the 'Task Notification' ribbon option section below for\nmore information.\n\nTask description\n\nAllows entry of dynamic text that will display on the task response form. This can be\nused to communicate additional information about the task to the responding\nuser. References can also be inserted using the Inserting reference fields feature.\n\nOutcomes\n\n\u00a9 2015 Nintex Global Ltd. All rights reserved. Nintex Confidential\nThe Outcomes define all the possible responses to the task. When completing the task,\nassignees must choose from one of the listed outcomes.\n\nNew Outcomes can be added by clicking Add outcome or removing/editing existing\noutcomes using the icons.\n\nEach outcome is configured with a name and an optional description, which is displayed\non the task response form and can be used to provide instructions and more detail.\nWhether or not the assignee must provide comments for the outcome can be configured\nas optional, required or none.\n\nBehaviour\n\nThere are five behavioural alternatives to instruct Nintex Workflow how to handle\ntasks with multiple assignees. These are:\n\ne First response applies: The first response received will be used for the\noverall outcome. All other pending tasks will be set to 'not required\".\n\ne Majority must choose a specific outcome: The majority of assignees\nmust agree on the same outcome. If a majority is not reached, the 'outcome\nachieved' variable will be set to 'no' and the overall task outcome will be\nblank. As soon as Nintex Workflow determines that a majority cannot be\nreached, the action will complete and all pending tasks will be set to 'not\nrequired\u2019.\n\ne All must agree on a specific outcome: All assignees must select the\noutcome specified in the 'Outcome' drop down list. If any assignee\nchooses an alternative outcome, all pending tasks will be set to 'not\nrequired\u2019, the 'outcome achieved! variable will be set to 'no' and the overall\ntask outcome will be blank.\n\ne Majority decides: The outcome variable will be set to the most popular\noutcome. If Nintex Workflow can determine the most popular outcome\nbefore all assignees have completed the task, all pending tasks will be set\nto 'not required\u2019. If two or more outcomes have the same number of\nresponses after all tasks are completed, the 'outcome achieved' variable\nwill be set to 'no' and the overall outcome will be blank.\n\ne All must agree: All assignees must agree on the same outcome. If an\nassignee responds with an outcome which differs to a previous respondent,\nall pending tasks will be set to 'not required\u2019, the outcome achieved\nvariable will be set to 'no' and the overall task outcome will be blank.\n\nStore outcome in\nAfter an outcome is reached, this workflow variable will be populated with the chosen\n\noutcome. See the 'Behaviour' section above for more detail on how outcomes are\ndetermined.\n\n\u00a9 2015 Nintex Global Ltd. All rights reserved. Nintex Confidential\nStore outcome achieved in\nIn some circumstances, it is possible that an outcome is not reached. After this action is\ncompleted, this workflow variable will be populated to indicate whether or not an\n\noutcome has been reached. See the Behaviour section for more detail on how outcomes\nare determined.\n\nTask name\n\nAllows the title of the task to be defined. This is the title that appears in a SharePoint task\nlist. If left blank, the action's title will be used by default.\n\nReferences can also be inserted using the Inserting reference fields feature.\n\nTask content type\nAllows a task content type other than the default to be used. This option will only display\n\nif an alternative content type is available on the site. Alternative content types are\nprimarily used to enable custom task response forms.\n\nPriority\n\nSpecifies the value that should be assigned to the priority flag for the\ntask. References can also be inserted using the Inserting reference fields feature.\n\nDue Date\n\nSet a date for the task to be completed by. Note: When tasks appear in Nintex Mobile\nApps, the tasks list will be sorted by this due date.\n\nForm type\nChoose which form type is presented to Assignees.\nStore task IDs in\n\nWhen the workflow runs, the ID given to each task that is created will be stored into\nan Integer, List Item ID or Collection workflow variable.\n\nItem Permissions\nSet user permissions to: Sets the user permission on the item.\n\nWhen task is complete, set user permissions to: Sets the user permission on the item\nafter the task has been completed.\n\n\u00a9 2015 Nintex Global Ltd. All rights reserved. Nintex Confidential\nNote: Setting the item permissions could be useful when the task is delegated, this will\ngive the delegated user the necessary permissions to view the item.\n\nRibbon Option: Task Notification\n\nSent when the task is assigned to a user, also used when the task is delegated by one user\n\nto another.\n\nConfigure Action - Assign Flexi task\n\na @ A722 BE & 9\nco & Oe oof\n\nTask Not Required Reminders Escalation Edit Task Labels Common Variables\nNotification Notification Form +\n\nSave Cancel\n\nAction\n\nEdit settings for All Assignees|\u00a5]\nAllow delegation Oo\n\nDelivery type @ Email \u00a9 User preference \u00a9 None\n\ncc EB\n\nFrom EB\n\nNormal] \u00a5]\n\nResponse required &\n\nImportance\nSubject\n\nAttachments (Include list item attachments\n\n*& Add attachment\nRich Text |\n\\A task has been assigned to you regarding this item:\n\nContext Item Display Name\n\nClick here to respond to the task.\nClick here to view the workflow status.\n\nEdit settings for\n\ninsert Reference *\n\nA\n\nChanging this setting from the default All Assignees allows the configuration of unique\nnotification options for a particular Assignee in the list.\n\nUnless specifically configured, assignees will use the All Assignees settings. To override\nsettings for a specific Assignee, select their name from the drop down list.\n\nChanges to All Assignees will not affect users who are given custom settings.\n\n\u00a9 2015 Nintex Global Ltd. All rights reserved. Nintex Confidential\nEdit settings for All Assignees Oa\n\nAllow delegation j.smith@mycompany.com\nk.brown@mycompany.com\n\nAllow LazyApproval (applicable with e-mail and IM delivery)\n\nAllow delegation\n\nWhen this option is selected, the assignee at runtime can delegate the task to another user.\nFor more information, please refer to Delegating Approval Tasks.\n\nAllow LazyApproval\n\nIf LazyApproval has been enabled on the server, the workflow can permit the assignees\nto use About LazyApproval. Lazy Approval means that an approval or rejection task\nresponse can be registered when the assignee replies to a notification email or an\nautomated OCS / Lync conversation with a recognized word or phrase. An administrator\ncan edit or add to the list of acceptable terms. For more information, please refer to\nManaging LazyApproval settings.\n\nDelivery type\n\nCC\n\nDelivery type is the method of delivering the notification to the recipients.\n\nAvailable delivery options; None, Email, User preference or Instant Message (if enabled\non the server). For information on User preference, please refer to Configuring user\npreferences.\n\nPlease note: Nintex does not provide support for troubleshooting email, SMS or OCS /\nLync systems.\n\nIf Allow LazyApproval is checked and Delivery type selected is IM. The option Send a\nconversation request to confirm if the user is available to respond will be available.\nChecking this option will ask the assignee if they are available to respond, if the assignee\nresponds with \"No\", the Delivery type will be switched to Email and the assignee will\nreceive a notification email instead.\n\nIf at anytime the assignee does not respond within 5 minutes to the automated OCS /\nLync conversation, the conversation will end and a notification email to complete the\ntasks will be sent instead.\n\nThe CC field sets read-only users who will receive the notification. CC recipients are not\nable to respond to the tasks.\n\n\u00a9 2015 Nintex Global Ltd. All rights reserved. Nintex Confidential\nTo set the CC field click on |= to open the Select People and Groups configuration\ndialog.\n\nBCC\n\nThe BCC field sets read only users who will receive the email. BCC recipitants are not\nable to respond to the tasks. Other users addressed in the email via the To, CC and BCC\nfields will not be able to see any addresses in the BCC field. To set the BCC field, enter\nthe account name, or alternatively, select the address book icon for additional options.\n\nFrom\nThe From field sets the user or domain group that will appear as the sender of the\nmessage. This setting applies to emails only. If no From user or domain group is\nspecified, the From address configured in Global Settings will be used.\n\nImportance\nThe priority of the notification. This is only applicable when using email notifications.\n\nSubject\n\nThe Subject is the title of the notification being sent. If an Instant Message is being sent\nit will be pre-pended to the body of the notification.\n\nIt can be added manually or by clicking on E | to use Insert reference fields from within\nthe runtime instance of the workflow.\n\nAttachments\nAllows file attachments to be added to the notification. You can specify multiple URLs\nby separating each URL with a semicolon. You can also specify multiple URLs by\nreferencing a collection variable.\nFiles will not be received by a user when SMS or IM is selected as the delivery\nmethod. For information on User preference, please refer to Configuring user\npreferences.\n\nFormat\n\n\u00a9 2015 Nintex Global Ltd. All rights reserved. Nintex Confidential\nThis sets the format of the email.\nSelecting:\ne Rich Text enables italicize, bold, underline and indent information within the\nemail using simple HTML styles provided by the SharePoint rich text tool bar.\ne Plain Text is simply the text without any stylized formatting.\nNotification body\nThe body of the notification will adapt depending on whether the Rich Text or Plain\n\nText format is selected. Within the space provided, enter the content for the notification\nas straight text. Also available are Insert reference fields from within the workflow.\n\nRibbon Option: Not Required Notification\nSent when the user no longer needs to respond to the task. This can occur when:\ne A task is assigned to multiple users but only one is required to respond.\n\ne The workflow is terminated prior to the task being processed.\ne Anerror occurs in the workflow at runtime.\n\n\u00a9 2015 Nintex Global Ltd. All rights reserved. Nintex Confidential\nConfigure Action - Assign Flexi task o x\n\nGENERAL\n\nem & 2. 0 Al EE \u20ac 2 (?)\nlal od Gl @ we GE safe\nSave Cancel Action Task Not Required Reminders Escalation Edit Task Labels Common Variables Help\nNotification Notification Form +\n\nCommit Settings Variables Help\nEdit settings for All Assignees| V|\nDelivery type @eEmail O User preference \u00a9 None\ncc EB\nBcc EB\nFrom EB\nImportance Normal|\u00a5]\nSubject Response no longer required &\nAttachments (1 Attach file from workflow\n\n& Add attachment\n\nRich Text [\u00a5] Insert Reference *\nA task regarding this item no longer requires your response: a\n\nContext Item Display Name\n\nClick here to view the workflow status\n\nSee Ribbon Option: Task Notification above for field descriptions.\n\nRibbon Option: Reminders\n\nOptional notification Reminders can be configured to be sent to each assignee who has\nnot yet completed the task.\n\n\u00a9 2015 Nintex Global Ltd. All rights reserved. Nintex Confidential\nConfigure Action - Assign Flexi task\n\nGENERAL\nre & @ O Ye Wa FS & 2 [?)\nio a eo 6& 2082 exe\nSave Cancel Action Task Not Required Reminders Escalation Edit Task Labels Common Variables Help\nNotification Notification\nCommit Settings Variables Help\nNumber of reminders 0 & A\nTime between reminders pays. 9 &\n=e\nHours: 0 B\n>.\nMins: 0 B\nTime calculation C1 During business days only\n(During business hours only\ncc EB\nBcc EB\nFrom EB\nImportance Normal|\u00a5]\nSubject &\nAttach file im\nRich Text iv Insert Reference *\nv\n\nNumber of reminders\n\nThe number of reminders to be sent.\n\nTime between reminders\n\nThe delay before sending each reminder in days, hours and minutes.\n\nThe total time is calculated by summing all fields, regardless of the Time calculation\noption selected. For example, 4 days and 4 minutes will be calculated as 96 (24x4) hours\n\nand 4 minutes.\n\nTime calculation\n\nSpecifies whether or not hours outside the work week should be included when counting\n\ndown to send a reminder.\n\nDuring business days only\n\n\u00a9 2015 Nintex Global Ltd. All rights reserved. Nintex Confidential\nThe During business days only option will specify that weekends or holidays are not\nincluded in the countdown, but after hours on a business day are.\n\nExample:\n\ne The task is assigned Friday morning and is configured to wait 1 day before\nsending a reminder (the work week is defined as Monday to Friday).\no A reminder will be sent Monday morning: weekends are not included in\nthe countdown.\n\nDuring business hours only\n\nThe During business hours only option specifies that only business hours are used in the\ncount down.\n\nExample:\n\ne The task is assigned Wednesday at 4pm and is configured to wait 4 hours before\nsending a reminder (the work day is defined as Monday to Friday, 8am to Spm).\no A reminder will be sent at 11am on Thursday: after-business hours are not\nincluded in the countdown.\n\nNeither option\n\nIf neither option is selected, all hours will be included in the count down.\n\nExamples:\n\ne The task is assigned Friday morning and is configured to wait 1 day before\nsending a reminder.\no Areminder will be sent Saturday morning: weekends are included in the\ncountdown.\ne The task is assigned Wednesday at 4pm and is configured to wait 4 hours before\nsending a reminder.\no A reminder will be sent at 8pm on Wednesday: after-business hours are\nincluded in the countdown.\n\nPublic holidays and any other special occasions are set using the \"Site Settings > Nintex\nWorkflow > Manage Holidays\" page.\n\nSee Ribbon Option: Task Notification above for additional field descriptions.\n\nRibbon Option: Escalation\n\nEscalation is optional, there are two possible escalation paths:\n\n\u00a9 2015 Nintex Global Ltd. All rights reserved. Nintex Confidential\ne Delegate task will re-assign all pending tasks to the nominated user after the\nspecified time.\n\ne\u00a2 Complete task will auto-respond to all pending tasks and set the overall outcome\nof the action to the indicated outcome after the specified time.\n\ne The specified outcome does not have to be one of the configured possible\nOutcomes set in the Action.\n\nEscalation occurs after all reminders have been sent and the specified \"Time to\nescalation\" has elapsed.\n\nConfigure Action - Assign Flexi task o\n\na \u00ab :. < Yn F \u20ac |2 (7)\n\nll B bw & 2 ss : opt\n\nSave Cancel Action Task Not Required Reminders Escalation sk Labels Common Variables Help\nNotification Notification\n\nCommit Settings Variables Help\n\nEscalation type Delegate task |\n\nTime to escalation Days: [0 &\nHours: [0 &\nMins: [0 &\nTime calculation [During business days only\n\nC1 During business hours only\nDelegate to * EB\n\nComments insert Reference *\n\nSee Ribbon Option: Reminders above for additional field descriptions.\n\n1.4 Assign To-Do Task\n\nThis workflow action will assign a SharePoint task to one or more users.\nTo use the workflow action:\ne Locate the action in Workflow Actions Toolbox (located on the left hand-side);\no Click on the Category listings to reveal the actions; OR\n\no Search for the action using a keyword.\ne Select the action, drag it onto the design canvas and drop it onto a design pearl.\n\n\u00a9 2015 Nintex Global Ltd. All rights reserved. Nintex Confidential\nAlternatively\n\ne Left-clicking the pearl, mouse-over Insert Action and then the Categories to reveal the\nactions, click the required action from the list.\n\nTo change the settings used by the action:\ne On the action\u2019s title click the down arrow to activate a drop-down\ne Select Configure; OR\n\ne Double-click the action's icon.\n\nFor more information on the other options in the drop-down, please refer to the Getting started\nwith the Nintex Workflow designer. \u201c\u201c\u2018\n\nConfigure Action - Assign to-do task ao x\n\npaws waezGe BO\n\nlal ma eo & me \\ege\n\nSave Cancel Action Task Not Required Reminders Escalation Labels Common Variables Help\nNotification Notification\n\nCommit\n\nAssignees * EB\n\n(Ol Create individual tasks for all group members\n\nAllow delegation\n\nTask description insert Reference *\n\nKS}\n\nTask options \u00a9 All must respond\nFirst response applies\nContent type * Use existing \u00ae Create new\nDue Date Value 4} &\n\nStore task IDs in\n\n[x]\n\nOptions within this action\n\nRibbon Option: Action\n\n\u00a9 2015 Nintex Global Ltd. All rights reserved. Nintex Confidential\nAssignees\n\nThe Assignees list contains all users or groups that will be assigned the task when\nthe workflow is runs.\n\nUsers can be:\n\nEntered directly using their username, email address or full name and will\n\nbe resolved where possible against the SharePoint user list or Active\nDirectory.\n\ne Search for users, click on the address book icon on the right.\n\nSelect People and Groups\n\nTo search for users, click on the address book icon on the right.\n\n3) Search for people and groups from the directory, add external email addresses or select addresses from the lookup list.\n\nInternal Search\n\nFind & List View bd\n\na Organizations Display Name E-mail Address Title Department Presence Worl\nif All Users Type into the search box above then press \u201cEnter\u201d to start your search.\n[i Active Directory\n\nGg, SharePoint Groups\n\nLookup\n\nSelections\n\nThe configuration dialog allows the workflow designer to search for and/or add users to\nthe Assignees list by one or more of the following methods:\n\ne Internal Search: Entering a partial display name, email or user account name and\n\nclicking on the magnifying glass will provide a list of matching users and groups\nfrom SharePoint as well as Active Directory.\n\n\u00a9 2015 Nintex Global Ltd. All rights reserved. Nintex Confidential\ne External email address: Enter an external email address manually. Where\npossible Nintex Workflow will resolve this to an actual user account.\n\ne Lookup: Provides the option of adding a dynamic reference as an approver. e.g.\nWorkflow variable, list field.\n\nClick the title bar to expand or collapse each option.\n\nCreate individual tasks for all group members\n\nIn the case when a group is assigned the task and Create individual tasks for all group\nmembers checkbox is:\n\ne not selected, all users in that group will receive the task notification. The first\nrespondent will represent the entire group.\ne selected, an individual task will be assigned to every member of the group.\n\nGroups will only be expanded to one level. Groups within groups will not be expanded.\n\nUsers can be entered directly using their username, email address or full name and will be\nresolved where possible against the SharePoint user list or Active Directory.\n\nAllow delegation\n\nWhen this option is selected, if the assignee field of the task is changed, Nintex\nWorkflow will record the change as a task delegation and the new assignee will receive\nthe Response Required Notification. If this option is not selected, Nintex Workflow will\nnot track the change to the assignee and Nintex Workflo"}, {"FileName": "Harvard_3.pdf", "GUID": "7f55998e-7a61-4f66-b012-9599db3d6480              ", "FileName Path": "http://msfdemo.isearch.com:18605/Demo MSF/Harvard_3.pdf", "FileName Version": 1, "Created DateTime": "2023-01-25 06:40:57.000", "Updated DateTime": "2023-01-25 06:40:57.000", "Created By": "Rajesh                                                                                              ", "Updated By": "Guru                                                                                                ", "RawOCR": "Established originally by the Massachusetts legislature and soon thereafter named for John\n\nHarvard (its first benefactor), Harvard is the United States' oldest institution of higher learning, and\n\nthe Harvard Corporation (formally, the President and Fellows of Harvard College) is its first\n\nchartered corporation. Although never formally affiliated with any denomination, the early College\nprimarily trained Congregationalist and Unitarian clergy. Its curriculum and student body were\ngradually secularized during the 18th century, and by the 19th century Harvard had emerged as the\ncentral cultural establishment among Boston elites. Following the American Civil War, President\nCharles W. Eliot's long tenure (1869-1909) transformed the college and affiliated professional\nschools into a modern research university; Harvard was a founding member of the Association of\nAmerican Universities in 1900. James Bryant Conant led the university through the Great\nDepression and World War II and began to reform the curriculum and liberalize admissions after the\n\nwar. The undergraduate college became coeducational after its 1977 merger with Radcliffe College.\n\n"}, {"FileName": "Granular_Backup_and_Restore_User_Guide.pdf", "GUID": "cda77c24-ed41-400d-85aa-385ba97d58a5              ", "FileName Path": "http://msfdemo.isearch.com:18605/Demo MSF/Granular_Backup_and_Restore_User_Guide.pdf", "FileName Version": 1, "Created DateTime": "2023-01-25 06:40:57.000", "Updated DateTime": "2023-01-25 06:40:57.000", "Created By": "Govind                                                                                              ", "Updated By": "Govind                                                                                              ", "RawOCR": "AavePoint*\nGy DOCAVE'6 User Guide\n\nDocAve\u2019 6 Granular Backup\nand Restore\n\nUser Guide\n\nService Pack 4, Cumulative Update 3\n\nRevision P\nIssued September 2014\n\nThe Enterprise-Class Management Platform for SharePoint Governance\nTable of Contents\n\nAbout DocAve Granular Backup and R@StOre .........ccescssscsscsssesecesceseceeessesseseeseaseeesesecseseeecaeceesesseaeeuecseserseaess 5\nComplementary Products ........:ccscsssssscsscssscssccseesecsscssecsesesecsecesessecsesesesseseescsseesecsecsesesesseseeecaeceesenseaesenseaees 5\nSubmitting Documentation Feedback to AVEPOINE ........eeeceeeeseeseeeeseeseeecseeeeeecsecseeaeseeaeeaceeseesaesersetaeeasieeaeeess 6\n\nBefore You Begin.\n\nCONFIQUIATION oe ee eeeeeeeeeeeeeeeeseeseeeeseeseseeseeaeseesecaesacsecseeaesessecaesecsesesaeseeseeaseeseesaesassessesaeseeaseasieseesaeeesseeaeees 7\nAROCNHS occ ccc ccsseceeecceseeessescseaseesesseeseseeseseesssesesessseesseseeseessceeseeesseseseseesceeaseseeseessessesseesesseeseeescseaseseseeaeee 7\nRequired Permissions ........cccccsccscssceseesscssessecssccsecescesecsecsesesscsescsscseesecseceesesecseseasessessecseseseeesaeseeseaseseeneees 7\nGranular Backup and Restore for SharePoint On-Premises PerMisSiONns .........:cccccseseeseesesesesseseeeseeeaee 7\nGranular Backup and Restore for SharePoint Online Permissions ...........cccccccssceseessesseeseeteeeseetesseeseeenee 8\nLocal System PermisSiONns ......c..ccccsccescsssesscessesecsecssecsecesesseeeeeesecsecesecseseescseceesessesecesecaeseeseseseseesesseneseneees 9\nHealth AnalyZer.....c.ccccsccsccsscssscsscsscssecsecssssseceseesecsecesecseceessseceesesscsesaecseseesesecaeseesesecasscseceeseeesaeseeseateneeeges 10\nGetting Started... ee ceescsceseeeeeceeeseeeceecseesesecsecsecesesaeeecsesaeeacsecseeaeseesesecsecaesaesaeseeaseaseeseesesesaetaseeeseeaeeeeee 11\nLaunching Granular Backup and ReStOre.......ccseccsssscescseeseeseecesseeeeecseeeeeeesesaeaeseeaeeecsesaeseseetseeaeeasseeaeeees 11\nUser Interface OVErVieW oo... ccc rene cs ce renecseeseeneneeesenecsceseseeseseseenesieseesesieseesesenseesesaeeeeetenags 12\n\nSelecting Farms and Nodes....\n\nConfiguring Devices and Setting Up Storage Policies ..........cceesseeseeeeseeseeeceeeeeecsetseeeeseeaeeeceesaeteseetseeaeeees 13\nPerforming a BaCkup........ccceecsscesesccseesseeceseseeecsecseesesecseacseesesaeecsesseaeseesseacsesaesesecsesaeeesseeaseessesaeeesetaeeaeeees 14\nOverview Of Backup TYP@S.......:cccccssssscsecsscsscssecsecsecssscsesesseseceecesecsesesesseseesesseessesecseseeesseseeseaecaesenseneseneegs 14\n\nSelecting Content to Back Up ....\n\nSelecting Content by Search .......ceeecseseecsseeseseeseeseeeeseeseeecsecseeacsecseeaeseeseseeeessesaeasseeseeasesaeseesateetseeaeeees 15\nSelecting Content by BrowSe ........ccececesesscesseeeseeseeeeseeseeecsesseeeesecseeeeseeseseeeessesaeaseeseeaseseesaeeaseerseeaeeees 16\nAbout Ad HOC Backup .......cccccscssscsscessesecescesecsecssecseseeseseceescsecsesesessecesesseessesecseseeseseseesessenssesseseseeseeesaesenses 17\nConfiguring Default Settings .........cceceessceeseeseeseeeeeesceecsesseeecsecseeeeseeseseesessesseeaeseeseeaseseeseesaseetseeaeeees 17\nUsing Ad Hoc Backup .......ceeesesesesseeseseessesceeseeecsecseescsecsecacsaeseeaesessecsesaeseeaseasaessecassassesaeassesateesiesaeeatees 18\nUsing the Plan Builder... ccc eceeeseeeeesseeseeecsecseeecseeseeecsecseeecseesseaeeesaeseesecsesaesaeseeaeeessesaeeesesaesaseasseeaseeee 18\n\nUsing Wizard Mode...\n\nUsing FOr MOde.......cecseccssssseseseeseeseecseeseseeseeeesecsesacsecsecaesacsesaeeeesessesaeseeaceasaesaesasessesaesaeseeaseesaesaeeetees 21\nElements Unsupported to Be Backed Up in SharePoint 2013 .........cccscccscssecssceeesseeseesecsecseeseeseesesseneeaes 24\nPerforming a REStOre ........ccceessessceccseeseesceeseeecsecsceecsecseaeseesesaesecsesaesaeseeseacsecaesessesaeaeaeseeasasiesaeeeseesseeaeeees 25\n\nDocAve 6: Granular Backup and Restore\nDefining General Settings ...\n\nUser Mapping... cc ceescssessesseessecssesseesecsesesessesseessseseseaseseeeaeeseseeseeesaeseseseeseecaeseeseeesaesaeseaseaeeaeeaeseaeees 25\nDomain Mapping..........cccceccscssessesseesseeseeeeecsecseeesecsesseeeseesesesseseeeaeeseseeeseecaeseeseseeasesesaeseeeseeseeseaseneenaes 25\nLanguage Mapping......... cc ceesessessessesssseseeseecsecsecesessesseessseeessseseeesecseseesseecseseeseaseseeesesseseeeseeseeseateneenaes 26\nConfiguring and RUNNMINg a REStOFe ...... eee eeeeeseeeeceteeseeecseceeeecseeseaeseeseeeesecaeseesecsesaesasseeaeeesaesaeteetetsetaeeees 26\nSelecting Backed-up Data to REStOre........seseessseseesesseseeeceetseeseseeseeaeecseseeeessecseeaeseeseeaseeseetaeeesetaeeaeeees 26\nREStOrE TYPO oo... eeeeeeeseesceseeecssesseseesseeseeseecsecesesecsesseessesesesseseeseeseceesesecaeseeseaeesaeesesaeseeeseeseeseaseneeeaes 33\n\nRestoring Data Backed Up by DocAve 5....\n\nChecking a Job Status... cccsesseccsseseesceecseeseeecsecseeccsesaeeecsecaeaeseeseeaesecseseesecsesaeseeseeaseaseeseesessesaesaseeeseeaeeees 42\nEnd-User Granular R@StOre ........cccccseessesesseseeeeeeseescsecseeseseeseeacsecsessesaescessacsesaeseesessesaeesaeeaeeesiesaesaseatseeaeeees 43\nSupported and Unsupported Web BrowsSe\u2019s.........csccscsssssscsscsscesessscesecseceecesscsecsecsesesesaeseeseascneseneeseseneses 43\n\nInstalling the End-User Granular Restore Solution...\n\nActivating the End-User Granular Restore Feature .........ccscecesssseeecseeeeseeeeseeecseceeeeeecsesaeaeseeaeeesesaeeatees 44\nConfiguring the End-User Granular Restore Settings .........:cccscssceseseeseeseeeceeeeeecseeaeeeeseeaeeecseseeeeseetseeaeeees 45\nUsing the End-User Granular Restore Feature .......ccceccsesseesceeeseeseeeceeeeeeecseeseeeeseeaeeecseseesasessetaeeesseeneeeeee 46\nAdditional Optional Configurations ..........ccceseeesseseeceeseseeceeeseeecsecseeseseeseeecsecsesaeseeseeaseasseseesesesaetaeeeseeaseeeee 49\nPredefined SCHEMES o.....c cece cece ceeeeenecseeseesececeseeseceeessenseecessesseesesseseesesseseecesisseesesieseenesseseetenaes 49\nAdvanced Predefined Scheme Settings ..........:.scsssessssseeseeeseeseeeeeeeceecseseeeessecseeaeseeseeasesaeseeeesesseeaseees 50\nOutgoing E-mail Server Settings .........ceceseeeseeeeccseeseeeeseeeeeecsessceacsecseaeseceesesessesaeeeseeaeeasaesaeeestersetaeeees 50\nDocAve Granular Backup and Restore USe Case ........ccccscssceseesscsseeseeeecesseseesesseceeseeeseeseeseascesseseseeeeaeseseeees 51\nConfiguring a Successful BaCkUp Plan........ecesecesceccseeeeeeeeeseeeceeseeseseeseeecseceeseeeessesaeeeseeaeeesaesaeeesetseeaeeees 51\nAppendix A \u2014 Advanced Search .........ccccscsscssscsscescssecsecssecsecesecsecesesecsecaseseceseseeseecsecseseessaeceeseassaeseseeseseneng 53\n\nAppendix B \u2014 Supported and Unsupported Web Parts....\n\nAppendix C \u2014 Supported and Unsupported Features for SharePoint Online .........cceceeeeeeseeeeeeeteeeeteeeeeeee 57\nBACKUP .....ccccsccsscescesccssesecsscesecsecsseeseceseseesesaecsecsesesecsecssessceesesscsecsseseseesesecaesessessessscseseeseeeseeseesenseneeenes 57\nRESCOLC ...ecccccccccssceescsessecsssecsecscsecsececsecseseceessessesecsecesecssseussssesseessecsscessesseseasesseseesesseseseesseseaseseessaseseess 58\nPlan Manager .......eeessesseseesceseseeseeseeeeseeececseeseecseeaeecesecseseesecaeeaeseeseeaseessesaesecsesaeaeseeaseaseesaeteseesseeateees 60\n\nAppendix D \u2014 Accessing Hot Key Mode .........:.cccsessecssssseeseeeeseeseseeseeaesecsesaesecsesaesecseeasasseseesessesaetasaeseeaeeeeee 62\n\nBackUp Page .......cesscscsscescescseessesceeesesecsecseesesecsecaesacsesaeacsecseacseeseaeseesesacsessesaesaesecaseaseesaeeessesaeeaeeesieeneeeees 62\nReStOre Page ou... eeeeceesssessceeeeseceeeesecseseeesseeeecaeesecesecseseeecsecseseasesessaecseseeeesecseseeseateseseseseseeesaeseeeeaseneeeaes 63\nRestore WIZard oo... cece reece eee renee sens cece cee neneeesecneeeceseeneeeseseeseeesesieseesessesseeseseeseetesaesseetesaeene 63\nEnd-User Granular R@Store oo... cece cece cece eenececeseeneceeeseeneceeesecsseetesenseesesseseeneseeseeseneseeeeseneaene 64\n\nDocAve 6: Granular Backup and Restore\nPlan Manager Page...\n\nAppendix E \u2014 Customization Support Table.....c.cccccsccsscsscssscsecssecsecsecssesesseseseseecsecseseessaeseseaseaesesessesenses 65\nWorkflow Restore Notes... cece ener nee erence reser nine seneeetesenenenesieneeeneseseetesiseeeseseenneenenesenea 69\nRestoring Workflow Definitions...........ccceesesseesessessesceecseeeeeeseeseseeseeacsecsesaesecsesaeeeeseeaseeseesaeseseetseeaeeees 69\nRestoring Workflow INStances ........:scesssseeseseeseeecteeseeceseeseeeesecaceacsecseeaeseesesaeecsecaeaeseeaseaseesaeteseetseeaeeees 69\nSupported and Unsupported Workflows.........ccsscessseesceesseeseeeeseeseeecsecseeessecseeaeseesecaeeessesaesaseetseeaeeees 70\nAppendix F \u2014 Advanced Settings in Configuration Files... ceseseseseeeeeseeseeseeeesseececeeeeeeessetaceesseeaeeeee 71\n\nAgentCommonWrapperConfig.config ....\n\nRestoring Entered Web Properties .........:.cccecsseecessesseceeecseeeeeeeseeaeseeseeacsecseseceecsesaesaeseeaseessesaeeeseesseeaeeees 71\nSP2010GranularBackupRestore.cfg and SP2013GranularBackupRestore.cfg .........:sesseceseseeeeeetteeeees 71\nBacking Up and Restoring Stubs and Related Data... cesseescsecseeseeeceeseeeeeseeseeeeseeaeeessesaeeeseetseeaeeees 71\n\nConfiguring Resolution for Content with the Same Modified Time ...\n\nNotices and Copyright Information ........:ccececsecsseeseeeeseeseeeeseeeceecsesseeecseeseeaeseeaeseeecsesaeaeseeaseessesaeeeseerseeaeeees 74\n\nao DocAve 6: Granular Backup and Restore\nAbout DocAve Granular Backup and Restore\n\nDocAve Granular Backup and Restore for SharePoint 2010 and SharePoint 2013 ensures resiliency of\nservice in the event of a disaster and quickly recovers lost or corrupted content with database or\ngranular restores.\n\nGranular Backup and Restore offers full, incremental, and differential backup capabilities for SharePoint\ncontent, enabling the user to build backup plans and schedules that focus on frequent backup of high\npriority data, thereby improving backup operations and storage efficiency.\n\nComplementary Products\n\nMany products and product suites on the DocAve 6 platform work in conjunction with one another. The\nfollowing products are recommended for use with Granular Backup and Restore:\n\ne DocAve Platform Backup and Restore to back up the entire SharePoint environment,\nincluding farm-level components\n\ne DocAve Replicator for SharePoint for copying SharePoint content within the same\nSharePoint farm or from one SharePoint farm to another\n\ne DocAve Content Manager for SharePoint for restructuring or moving SharePoint content\n\ne DocAve Report Center for SharePoint to examine pain points in the SharePoint\ninfrastructure and report on SharePoint user behavior and changes\n\ne DocAve Data Protection for setting backup and recovery points prior to adjusting\nSharePoint governance policies in this product\n\nDocAve 6: Granular Backup and Restore\nSubmitting Documentation Feedback to AvePoint\n\nAvePoint encourages customers to provide feedback regarding our product documentation. You can\nSubmit Your Feedback on our website.\n\nre DocAve 6: Granular Backup and Restore\nBefore You Begin\n\nRefer to the sections for system and farm requirements that must be in place prior to installing and\nusing Granular Backup and Restore.\n\nConfiguration\n\nIn order to use Granular Backup and Restore, the DocAve 6 platform must be installed and configured\nproperly on your farm. Granular Backup and Restore will not function without DocAve 6 present on the\nfarm.\n\nAgents\n\nDocAve Agents are responsible for running DocAve jobs and interacting with the SharePoint object\nmodel. DocAve Agents enable DocAve Manager to communicate with the respective servers, allowing\nfor Granular Backup and Restore commands to function properly.\n\n*Note: The use of system resources on a server increases when the installed agent is performing\nactions. This may affect server performance. However, if the agent installed on a server is not being\nused, the use of system resources is very low; therefore, the effect on server performance is negligible.\n\nFor instructions on installing the DocAve Platform, DocAve Manager, and DocAve Agents, see the\nDocAve 6 Installation Guide.\n\nRequired Permissions\n\nRefer to the section below for the required permissions to use Granular Backup and Restore.\n\nGranular Backup and Restore for SharePoint On-Premises Permissions\n\nTo install and use Granular Backup and Restore on the SharePoint on-premises environment properly,\nensure that the agent account has the required permissions.\n\n1. Local System Permissions: These permissions are automatically configured by DocAve during\ninstallation. Refer to Local System Permissions for a list of the permissions automatically\nconfigured upon installation. If there are no strict limitations within your organization on the\npermissions that can be applied, you can simply add the DocAve Agent Account to the local\nAdministrators group to apply all of the required permissions.\n\n2. SharePoint Permissions: These permissions must be manually configured prior to using\nDocAve 6 Granular Backup and Restore; they are not automatically configured.\n\ne User is a member of the Farm Administrators group. Since Administrator works across\nfarms and on all SharePoint settings and configurations, this account is needed in order\nto provide the best and most complete quality of service.\n\ne Full Control to all zones of all Web applications via User Policy for Web Applications.\n\nDocAve 6: Granular Backup and Restore\n\nUser Profile Service Application:\no For SharePoint 2010\n= Use Personal Features\n= Create Personal Site\n= Use Social Features\no For SharePoint 2013\n= Create Personal Site\n\n= Follow People and Edit Profile (required for personal storage, newsfeed,\nand followed content)\n\n= Use Tags and Notes\n\nManaged Metadata Service:\n\no Term Store Administrator\n\no Administrator with Full Control permission\nBusiness Data Connectivity Service: Full Control\nSearch Service: Full Control\nUser Profile Connection Permission:\n\no Administrator\n\no Full Control\n\nSQL Permissions: These permissions must be manually configured prior to using DocAve 6\nGranular Backup and Restore; they are not automatically configured.\n\nMember has a Database Role of db_owner for all of the databases related to\nSharePoint, including Content Databases, Config Database, and Central Admin Database.\n\no Creator and Security Admin permission to SQL Server\n\nDatabase Role of db_owner for FBA database if forms based authentication (FBA) is\nenabled in SharePoint Web applications.\n\nDatabase Role of db_owner for User Profile Service database, Nintex workflow\ndatabase.\n\nGranular Backup and Restore for SharePoint Online Permissions\n\nTo install and use Granular Backup and Restore on SharePoint Online environment properly, ensure that\nthe Office 365 account and Agent account have enough permission.\n\n1. Agent account permissions:\n\nLocal System permissions: These permissions are automatically configured by DocAve\nduring installation. Refer to Local System Permissions for a list of the permissions\n\nBB DocAve 6: Granular Backup and Restore\nautomatically configured upon installation. If there are no strict limitations within your\norganization on the permissions that can be applied, you can simply add the DocAve\nAgent Account to the local Administrators group to apply all of the required\npermissions.\n\n*Note: If the registered site collections are SharePoint Online site collections, the Agent account\nis on the Agent machine that has network connection or has configured Agent Proxy Settings\nbefore registering SharePoint Online site collections.\n\nIf the registered site collections are on-premises site collections, the Agent account is on the\nAgent machine that will run the Granular Backup and Restore job.\n2. Site Collection user permissions:\ne User is a member of the Site Collection Administrators group.\ne User Profile Service Application permissions:\no Follow People and Edit Profile\no Use Tags and Notes\n\no Full Control (only when the registered site collections are on-premises site\ncollections)\n\ne Managed Metadata Service: Term Store Administrator\n\ne Read permission to the Apps for SharePoint library in catalog site.\n*Note: To register site collections using the Scan Mode, make sure the specified site collection\nuser has the following permissions:\n\ne When the registered site collections are on-premises site collections\n\nPolicy for Web Application: Full Control\n\ne When the registered site collections are SharePoint Online site collections:\n\nUser has the Global administrator role\n*Note: If you want to properly restore user profile properties to SharePoint Online, the user\nprofile property settings in the source must be configured before using Granular Backup and\nRestore. (In the Office 365 SharePoint admin center, navigate to user profiles > Manage User\nProperties. Select the property you want to restore, and then select Edit from the drop-down\nmenu. Select the Allow users to edit values for this property option in the Edit Settings field,\nand then click OK to save settings.)\n\nLocal System Permissions\n\nThe following Local System Permissions are automatically configured during DocAve 6 installation:\n\ne User is a member of the following local groups:\n\nDocAve 6: Granular Backup and Restore PS\n\no IIS WPG (for IIS 6.0) or IIS IUSRS (for IIS 7.0)\no Performance Monitor Users\n\no DocAve Users (the group is created by DocAve automatically; it has the\nfollowing permissions):\n\n= Full Control to the Registry of\nHKEY_LOCAL_MACHINE\\SOFTWARE \\AvePoint\\DocAve6\n\n= Full Control to the Registry of\nHKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Services\\EventLog6\n\n= Full Control to the Communication Certificate\n\n= Permission of Log on as a batch job (navigate to: Control Panel >\nAdministrative Tools > Local Security Policy > Security Settings > Local\nPolicies > User Rights Assignment)\n\n= Full Control to the DocAve Agent installation directory\n\nHealth Analyzer\n\nAvePoint recommends using Health Analyzer to check the prerequisites required to correctly use\nDocAve Granular Backup and Restore.\n\n*Note: Only the users in the DocAve Administrators group can use Health Analyzer.\n\n*Note: You can ignore the Agent Account Cannot be SharePoint System Account rule, if you are not\ngoing to back up and restore SharePoint apps.\n\nFor more information about Health Analyzer, refer to the DocAve 6 Control Panel Reference Guide.\n\nDocAve 6: Granular Backup and Restore\nGetting Started\n\nSharePoint and the DocAve platform modules have common functionality. While some of this shared\nfunctionality is covered in this guide, the primary focus of this document is the functionality that is\nspecific to the DocAve module.\n\nFor information on the shared functionality not covered in this document, refer to SharePoint Help.\n\nRefer to the sections below for important information on getting started with Granular Backup and\nRestore.\n\nLaunching Granular Backup and Restore\n\nTo launch Granular Backup and Restore and access its functionality, complete the following steps:\n\n1.\n\nLog in to DocAve. If you are already in the software, click the DocAve tab. The DocAve tab\n\ndisplays all modules on the left side of the window.\n\nFrom the DocAve tab, click Data Protection to view the backup modules.\n\nClick Granular Backup & Restore to launch this module.\n\n%\n\na\nfa\n\nMigration\n\nAdministration\nCompliance\nReport Center\n\nStorage Optimization\n\ncontrol Pane!\nJob Monitor\nPlan Group\n[B Health analyzer\n\nLog Out\n\nWelcome\n\n(9) Data Protection Backup & restore SharePoint objects.\n\nProtect & recover your SharePoint platform.\nAnalyze & restore SQL Server data.\n\nMinimize the downtime of SharePoint in case of a\n\nof its farm-level components, while mai\nmetadata, securities, and version histori\n\n4% Platform Backup & Restore\n\nPlatform Backup and Restore is a farm-level recovery\nsolution which enables SharePoint administrators to back\nup and restore all ofthe contents, customizations,\nsolutions, and features, as well as back-end SQL\ndatabases, configurations, search index files, BLOBs, Web\nFront-End IIS settings, file system resources, and custom\napplication databases. It allows for restore of an entire\nplatform, individual SharePoint environment components,\nor the granular contents of the content database.\n\nB SQL Server Data Manager\n\nUE) sai server Data Manager is @ recovery solution that\nProvides full fidelity recovery of SharePoint content from,\nSQL backup files, VHD files, and content databases.\n\nHigh Availability\nHigh Availability is a one-switch disaster recovery solution\nfor Microsoft SharePoint. It enables SQL database\nreplication to a standby environment in order to minimize\ndowntime, or allows you to leverage SQL alias to replicate\ndatabases within the same farm to separate SQL instances.\n\nGi\n\nFigure 1: DocAve module launch window.\n\nvser:admin~ Be\n\nGranular Backup & Restore\nPlatform Backup & Restore\nSQL Server Data Manager\n\nHigh Availability\n\nGranular Backup & Restore\n\nGranular Backup\n\n\u2018You can set up backup plans on three levels:\nItem, Site, and Site Collection.\n\nGranular Restore 5\n\nAfter running a granular backup, you can\noranularly restore the backup data.\n\nPlan Manager\n\nView, edit or delete your backup plans in Plan\nManager.\n\nDocAve 6: Granular Backup and Restore\nUser Interface Overview\n\nThe Granular Backup and Restore user interface launches with the Backup tab active. This tab displays\nyour farm environment and allows for quick access to a list of Granular Backup and Restore features.\n\nGranular Backup and Restore > Backup QUser:admin- | B~-\n\nBackup | Restore Plan Manager\n\n\u00a5 What is Backup? What do you want to do next?\n\n[input Keyword 9) Actions = |) ag Hoc Backup\n\n[i Farm(2210VM01-SHAREPOINT_CONFIG) \u2018Ad Hoc Backup backs up the selected content immediately\n\n(Re Farm(2810VM262:SHAREPOINT_CONFIG) || without scheduling, using Default Settings configured just before To start an Ad Hoc backup, you must configure the\n\nRG My Registered Sites running the backup. Default Settings and then select the desired objects from\nthe tree in the left pane.\n\nCreate a Backup Plan\n\nUse Plan Builder to define the type of backup (Full, Incremental,\n\nor Differential), schedule a backup, or use 3 Predefined Scheme.\nTo create a Granular Backup plan, start by selecting the desired\nobjects from the tree in the left pane.\n\n> What can these settings do for you?\n> Dashboard\n\nNavigate to Granular Restore to perform the restore acti\n\nFigure 2: Granular Backup and Restore user interface.\n\n1. The SharePoint tree (in the Source panel) displays all content within your farms. Use this panel\nto select the content that you want to perform actions on. Selecting content often reveals new\ntabs and functionality on the ribbon.\n\n2. The ribbon shows the available actions and wizards for the selected nodes. This content is\ndynamic; it will often change depending on what is selected in the SharePoint tree.\n\n3. The workspace shows all form-based content that is used during the configuration of actions\nperformed in DocAve products.\n\nDocAve 6: Granular Backup and Restore\nSelecting Farms and Nodes\nTo select farms and nodes, complete the following steps:\n\n1. From the Source panel on the left, select the farm that contains the relevant SharePoint\ncontent.\n\n2. Click the checkboxes to the left of the nodes to select the relevant content you want to work\nwith.\n\n3. After selecting content, you will be able to perform the procedures described throughout this\nguide.\n\nConfiguring Devices and Setting Up Storage Policies\n\nIn order to perform a backup job using Granular Backup and Restore, it is necessary to first configure\none or more physical devices and then set up a storage policy.\n\nWhen performing a backup job, Granular Backup and Restore can write to Net Share, FTP, Amazon S3,\nAT&T Synaptic, Caringo Storage, Dell DX Storage, Dropbox, EMC Centera, HDS Hitachi Content Platform,\nIBM Storwize Family, Rackspace Cloud File, OneDrive, TSM, or Windows Azure Storage.\n\nIn addition, DocAve has the ability to treat multiple storage devices as a single logical unit when saving\nbackup data. This feature is especially useful for very large backup plans, as many small drives can be\ncombined. A logical drive must be defined before creating a backup plan.\n\nFor instructions on defining devices and setting up storage policies, refer to the DocAve 6 Control Panel\nReference Guide.\n\nDocAve 6: Granular Backup and Restore\nPerforming a Backup\n\nThere are several ways to configure and perform a granular backup. Once you select the content you\nwant, you can run backups using the following methods:\n\ne Using Ad Hoc Backup\ne Using the Plan Builder (Using Wizard Mode or Using Form Mode)\n\nFor more information regarding backup and recovery, refer to the Microsoft TechNet article Backup and\nrecovery best practices (SharePoint Server 2010) and Backup and Restore (SharePoint 2013). For the\nelements in SharePoint 2013 that are supported to be backed up, refer to Elements Unsupported to Be\nBacked Up in SharePoint 2013.\n\nOverview of Backup Types\n\nWhen configuring a backup plan using the Using the Plan Builder or Predefined Schemes, there are three\nbackup types you can select from to perform a backup job: Full, Incremental, or Differential.\n\nThe Full option backs up all of the selected data each time a backup is performed. This option requires\nthe most storage space because, depending upon the size of your SharePoint environment, each backup\nfile can be substantial in size. Unlike incremental and differential backups, all full backup files are\nindependent of one another and do not have any dependencies on other back up data files. However,\nbecause each of the backups is comprehensive, full backup jobs take the longest to complete of the\nthree available options.\n\nThe Incremental option backs up only the content that has been updated since the last backup,\ndrastically reducing the size of the backup file created. The most common option, this backup requires\nless storage than a full or differential backup. Incremental backups reduce execution time, thereby\nallowing for shorter backup windows. It is important to note, however, that in order to recover all of the\nmost recent SharePoint data from an incremental backup, all of the backup files must be available.\nConsider each incremental backup file as a piece of the whole SharePoint environment. If one of these\nfiles is not available, the full SharePoint environment cannot be restored.\n\nFor example, the following four cylinders represent four backups and they are performed in this order\u2014\nFull Backup, Incremental Backup, Incremental Backup, Incremental Backup:\n\nFigure 3: One Full backup followed by three Incremental backups.\n\nDocAve 6: Granular Backup and Restore\n1. The first Incremental Backup backs up the newly-added data in the blue period.\n2. The second Incremental Backup backs up the newly-added data in the green period.\n3. The third Incremental Backup backs up the newly-added data in the orange period.\n\nEach time it runs, the Differential option backs up all content that has been updated since the last full\nbackup. These backup files are larger in size than incremental files, but smaller than full backup files. In\norder to recover all of the most recent SharePoint content, the first full backup file and latest differential\nbackup file are required.\n\nFor example, the following four cylinders represent four backups and they are performed in this order \u2014\nFull Backup, Differential Backup, Differential Backup, Differential Backup:\n\nFigure 4: One Full backup followed by three Differential backups.\n1. The first Differential Backup backs up the newly-added data in the blue period.\n2. The second Differential Backup backs up the newly-added data in the green period.\n3. The third Differential Backup backs up the newly-added data in the orange period.\n\n*Note: Due to SharePoint API limitations, when you run an incremental or a differential backup at the\nsite collection level using the same plan, the Apps and AppData in the site collection that was backed up\nin the previous full backup job will also be fully backed up.\n\nSelecting Content to Back Up\n\nThere are two options to select the content to back up: Browse and Search. To select the content to\nback up, refer to the sections below.\n\n*Note: If the content is stub content, DocAve only backs up real files of those stubs generated by EBS\nand RBS. In addition, Granular Backup jobs will not capture linked content.\nSelecting Content by Search\n\nFor a large environment, use the search function to quickly locate the target content. To use the search\nfunction, complete the following steps:\n\n1. Locate the Source panel on the left-hand side of the screen.\n\n2. Inthe search field at the top of the Source tab, enter the characters from the SharePoint object\nURL or name you want to search for.\n\nDocAve 6: Granular Backup and Restore\n\n5.\n\nClick the magnifying glass (2!) to start the search or wait a moment for it to start automatically.\nWhen the search is running, you can click the stop button |\u201c! to stop the search, if needed.\n\nSelect the relevant objects that you want to back up by clicking the checkboxes to the left of the\nobjects. You can select objects in one farm.\n\n*Note: When you use the Select All node to select all of the child nodes under your selected\nnode, the Include New function takes effect automatically for this plan/job. Even a SharePoint\nobject is created in the selected scope after the plan is saved, the content under the node can\nbe backed up automatically by the backup job.\n\ne If you directly select the Select All option, the current nodes and the new nodes created\nafter the backup plan is saved will be backed up in the backup job.\n\ne If you manually selected all of the nodes one by one, the Select All option will be\nautomatically selected, but the new nodes created after the backup plan is saved will\nnot be backed up in the backup job.\n\nAfter selecting content, choose to perform either a backup using the Using Ad Hoc Backup or a\nbackup using the Using the Plan Builder.\n\nSelecting Content by Browse\n\nTo browse through the SharePoint farm objects, complete the following steps:\n\n1.\n\n3.\n\nFrom the Source panel on the left, double-click the farm that contains the relevant SharePoint\ncontent. A list of objects appears beneath the farm entry.\n\nSelect the relevant objects that you want to back up by clicking the checkboxes to the left of the\nobject. You can select objects in one farm.\n\n*Note: When you use the Select All node to select all of the child nodes under your selected\nnode, the Include New function takes effect automatically for this plan/job. Even a SharePoint\nobject is created in the selected scope after the plan is saved, the content under the node can\nbe backed up automatically by the backup job.\n\ne If you directly select the Select All option, the current nodes and the new nodes created\nafter the backup plan is saved will be backed up in the backup job.\n\ne If you manually selected all of the nodes one by one, the Select All option will be\nautomatically selected, but the new nodes created after the backup plan is saved will\nnot be backed up in the backup job.\n\nAfter selecting content, choose to perform either a backup using the Using Ad Hoc Backup or a\nbackup using the Using the Plan Builder. See the appropriate section below.\n\nDocAve 6: Granular Backup and Restore\nAbout Ad Hoc Backup\n\nAn Ad Hoc Backup backs up the selected content immediately (without setting up a schedule) using the\n\ndefault settings, which need to be configured prior to running the backup.\n\n*Note: An Ad Hoc backup is a back-end process, meaning that the job runs in the background. The user\ncan continue to navigate through the user interface without having to first terminate the running job.\n\nTo use Ad Hoc Backup, you must first define the default settings, as described below.\n\nConfiguring Default Settings\n\nTo use Ad Hoc Backup, it is necessary to first configure the default settings. To configure default backup\n\nsettings, complete the following steps:\n\n1.\n2.\n\nAfter Selecting Content to Back Up, click Ad Hoc Backup on the ribbon of the Backup tab.\nSelect Default Settings from the drop-down list. The Default Settings page appears.\n\nStorage Policy \u2014 Select the storage policy for the backup data, or create a new storage policy in\nthe Specify a storage policy drop-down list. A storage policy is used to configure a set of rules\nfor storing backed up data. It also supports the following functions:\n\ne Pruning the data backed up by Granular Backup and Restore and delete or move the\npruned backup data.\n\ne When you add more than one Media services in a storage policy, it supports the\nautomatic failover that causes another Media service in the storage policy to take over\nthe role of the Media service that is down during the backup job.\n\nFor more information on working with storage policies, refer to t"}, {"FileName": "Documentum Exporter Guide.pdf", "GUID": "caed5de4-cf95-4bdf-b714-d104d6869d0f              ", "FileName Path": "http://msfdemo.isearch.com:18605/Demo MSF/Documentum Exporter Guide.pdf", "FileName Version": 1, "Created DateTime": "2023-01-25 06:40:57.000", "Updated DateTime": "2023-01-25 06:40:57.000", "Created By": "Guru                                                                                                ", "Updated By": "Govind                                                                                              ", "RawOCR": "Tzuna\n\nMigration Masters\n\nTzunami Deployer\nDocumentum Exporter Guide\n\nSupports migration of EMC Documentum content\nrepositories into Microsoft SharePoint using\nTzunami Deployer\n\nVersion 2.8\nTable of Content\n\nCOMMENTS AND SUGGESTIONS\n\n1 INSTALLING TZUNAMI DOCUMENTUM EXPORTER.......s.ssssssssssesssssssecensscessceessssesessesessceesensesessesaseaeenensees 1-1\nSYSTEM REQUIREMENTS .....cesssseseessssesesesseeecseseesecseseaecsasacecseseasesseseasessaseasesseseasesseseasesseseaessaseaessaseaeessaseseeseasaaee 1-2\nINSTALLING TZUNAMI DOCUMENTUM EXPORTER.....essssescessssesesesseceesessecessesausesseseasessesaaesseseasessesaacesseseaseseesaaeessesages 1-3\n\n2 \u2014TZUNAMI DOCUMENTUM EXPORTER .......scssssssssssscssssscssscssssceecsseecssscsessesessssecsssceeseceeseseacessesesaceeseseesesees 2-6\nOVERVIEW\n\nSupported Types .\n\nSOCUTIEY eee eeeeeeseeseeeseeeeeseeseeseeeaecseeeaeeaeeaesaeeseesaeeseeaesaessaeeaesseeeaesseseaesseseaesaesaseaeeeseadeaeseaeseeeeaseeeseaeeaee\nEXPORTING FROM DOCUMENTUM\n\nCOMMAND-LINE EXPoRrT..\nBesT PRACTICE\n\n3 LICENSING INFORMATION ..\nCOPYRIGHT AND TRADEMARK..........ssscsssssssssssssessessssnssssessssssnsssesssenessssaesaesaesaesaesaesaesaesaesassaesaesaesassaseaseaseaseases |\n\nwna SSCS\n\nMigration Masters\nPREFACE\n\nThis guide provides installation procedures for Tzunami Documentum Exporter and detail\nsteps to extract contents from Documentum using Tzunami Documentum Exporter. The\nguide also describes how to extract contents non-interactive way using command-line\ninstructions and best practice.\n\nThis preface contains the following topics.\n\u00a2 Intended Audience\n\u00a2 Conventions\n\u00a2 = Technical Support\n\u00a2 Comments and Suggestions\n\nINTENDED AUDIENCE\n\nTzunami Documentum Exporter Guide is intended for:\n\ne System Administrators who are responsible for exporting Documentum contents\nand setting migration environment using Tzunami Deployer.\n\n\u00a2 Project Managers and IT Managers who create and regulate usage of Tzunami\nDeployer and Tzunami Documentum Exporter.\n\nCONVENTIONS\n\nThe following text conventions are used in this document:\n\n\u00a2 Commands and keywords are given in boldface\n\ne Terminal sessions, console screens, or system file names are displayed in fixed\nwidth fonts\n\nCaution indicates that the described action might result in program malfunction or data loss.\n\nmanual.\n\nSP Notes contain helpful suggestions about or references to materials not contained in this\nP Tips provide information that might help you solve a problem.\n\nwna SSCS\n\nMigration Masters\nTECHNICAL SUPPORT\n\nBefore contacting Tzunami Support Team, ensure that you are referencing the latest copy of\nthis user guide from:\n\nhttp://download.tzunami.com/go.aspx?DocumentumGuide=Download\n\nFor additional information, please contact Tzunami Support Team at support@tzunami.com.\n\nCOMMENTS AND SUGGESTIONS\n\nYour feedback is important to us and will help us to provide the most accurate and high\nquality information possible in our documentation. Send us comments or suggestions by\nemail to support@tzunami.com. Be sure to include as much of the following as possible:\n\n\u00a2 The document title.\n\ne The location that the document was accessed from (either downloaded from\nTzunami web site or the Tzunami Deployer User Guide and Tzunami Documentum\nExporter Guide available in Tzunami Deployer).\n\n\u00a2 The section or chapter number and the original text found in the document.\n\nWhen you send information to Tzunami Deployer, you grant Tzunami a non-exclusive right to\nuse or distribute the information in any way it believes appropriate without incurring any\nobligation to you.\n\nwna SSS\n\nMigration Masters\n1 INSTALLING TZUNAMI DOCUMENTUM\nEXPORTER\n\nThis chapter contains information about installing Tzunami Documentum Exporter. It\n\ncontains the following topics:\n\ne System Requirements\n\n\u00a2 Installing Tzunami Documentum Exporter\n\nShe\n\nnay\n\nMigration Masters\nSYSTEM REQUIREMENTS\n\nThe following requirements must be met in order to use Tzunami Documentum Exporter:\n\nComponents\n\nComputer and processor\nMemory\n\nHard disk\n\nSupported Operating System\nSupported Architectures\nNetwork\n\nDisplay\n\nMicrosoft .NET Framework\n\nTzunam\n\nMigration Masters\n\nTable 1: Hardware Requirements\n\nMinimum Requirements\n2GHz Pentium processor or equivalent\n2 GB (Minimum); 4GB (Recommended)\n\n50Mb (additional space will be required for the Tzunami Deployer\nprojects, which may vary from 10 Mb to 4 GB).\n\nWindows Server 2003/2008 & Windows XP\nx86 and x64\nIntranet/Internet access depending on connectivity requirements\n\n800 x 600, 256 colors (minimum); 1024 x 768 high color, 32-bit\n(recommended)\n\nMicrosoft .Net Framework 3.5\n\nPage | 1-2\nINSTALLING TZUNAM!I DOCUMENTUM EXPORTER\n\nTzunami Documentum Exporter requires that the Documentum Foundation Classes (DFC) to\nbe installed and configured on the machine where the exporter is running.\n\nTo install Tzunami Documentum Exporter:\n\n1. Unzip the zip file, and run Tzunami Documentum Exporter Tool Setup.msi.\nThe Tzunami Documentum Exporter setup wizard (Welcome window) will launch. To\nadvance through the install wizard, click Next on the bottom of the window.\n\ni Tzunami Documentum Exporter Setup = (5) xj\n\nWelcome to the Tzunami Documentum\nExporter Setup Wizard\n\nThe Setup Wizard will install Tzunami Documentum Exporter\n\u2018on your computer. Click Next to continue or Cancel to exit\nthe Setup Wizard.\n\nFigure 1: Welcome Window\n\n2. In the End-User Licensing Agreement panel, click \u201cI accept the terms in the License\nAgreement\u201d and click Next to continue installation.\n\nao\nEnd-User License Agreement \u00bb\nPlease read the following license agreement carefully @\n\nEND-USER LICENSE AGREEMENT\n\nIMPORTANT! THE LICENSOR. TZUNAMI, INC.,\n(HEREINAFTER REFERRED TO AS \u201cTZUNAMI\u2019) AGREES TO.\nILICENSE THE SOFTWARE TO (HEREINAFTER\nIREFERRED TO AS \u201cLICENSEE\u201d) ONLY ON THE CONDITION\n\n|AGREEMENT. READ THIS LICENSE AGREEMENT\n|CAREFULLY BEFORE DOWNLOADING THE SOFTWARE. BY |\n\nFigure 2: End-User License Agreement Window\n\nwna SSCS\n\nMigration Masters\nYou are advised to read the terms of the license carefully before proceeding with the\ninstallation. If you decline the license terms, the installation cannot proceed.\n\n3. Inthe Custom Setup panel, do one of the following:\n\n\u00a2 To accept the default Destination Folder, click Next.\n\n\u00a2 Click Browse, locate and select a destination folder, click OK, and then click\nNext.\n\ni= Tzunami Documentum Exporter Setup\n\nCustom Setup\nSelect the way you want features to be installed.\n\nFigure 3: Custom Setup Window\n\n4. Inthe Ready to install Tzunami Documentum Exporter panel, click Install.\n\ni= Tzunami Documentum Exporter Setup\n\nFigure 4: Installing Tzunami Documentum Exporter Window\n\ntanaiy\n\nMigration Masters\n5. Inthe Completed Tzunami Documentum Exporter Setup Wizard, to exit the wizard,\nclick Finish.\n\ni= Tzunami Documentum Exporter Setup\n\nCompleted the Tzunami Documentum\nExporter Setup Wizard\n\nClick the Finish button to exit the Setup Wizard.\n\nFigure 5: Installation Complete Window\n\nWhen Tzunami Documentum Exporter is installed, it comes with a default license that can be\nused for evaluation purpose only. This license is limited in time and number of operations.\n\nwna SSS\n\nMigration Masters\n2 TZUNAMI DOCUMENTUM EXPORTER\n\nThis chapter contains information about Tzunami Documentum Exporter. It contains the\nfollowing topics:\n\ne Overview\n\ne Exporting from Documentum\n\n\u00a2 Command-line Export\n\n\u00b0 Best Practice\n\nShe\n\nwna SSS\n\nMigration Masters\nOVERVIEW\n\nTzunami Documentum Exporter enables migrating Documentum content into SharePoint\nServer 2013/SharePoint Foundation 2013 (SPS2013/SPF2013), SharePoint Microsoft Office\n365, SharePoint Server 2010/SharePoint Foundation 2010 (SPS2010/SPF2010), Microsoft\nOffice SharePoint Server 2007/Windows SharePoint Services 3.0 (MOSS/WSS3.0), or\nMicrosoft SharePoint Portal Server 2003/Windows SharePoint Services 2.0\n(SPS2003/WSS2.0) using Tzunami Deployer.\n\nTo load Documentum content into Tzunami Deployer, you must first extract the content,\nusing Tzunami Documentum Exporter, into TDX (Tzunami Deployer Export) and STDX\n(Separate Tzunami Deployer Export) files. You can then load this TDX file into a Deployer\nproject.\n\nKe) When working with Tzunami Deployer on several machines, you can run an export on one\nmachine and load the exported data on another.\n\nTzunami Documentum Exporter is distributed as an external tool from Tzunami Deployer.\n\nSupported Types\n\nThe following items are exported from Documentum:\n\u00a2 Cabinets (General and Personal)\ne Folders\n\u00a2 Documents (including custom types)\n\n\u00a2 Virtual Documents\n\n\\ , Virtual Documents are converted to Folders.\n\nSecurity\n\nIn addition to the structure and items, Tzunami Documentum Exporter extracts\nsecurity information. The following permissions are used in the exporter:\n\ne Browse\ne Read\n\ne Relate\ne Note\n\ne Version\ne = =Write\n\n\u00a2 Delete\n\nShe\n\nTzunam\n\nMigration Masters\n\n| Page | 2-7\ne Change State\n\ne Change Permission\ne Change Ownership\ne\u00a2 Change Location\n\n\u00a2 Execute Procedure\n\ne None\n\nEach item is assigned an ACL defining the permissions of the various members\naccording to the roles they were assigned.\n\nThe exporter automatically creates four default roles that are used during the\ndeployment process. The roles include Reader (Browse and Read permissions),\nContributor (Browse, Read, Relate and Note permissions), Web Designer (Browse,\nRead, Relate, Note, Version, Write and Delete permissions), and Administrator (user\nhas full permissions).\n\nEXPORTING FROM DOCUMENTUM\n\nThe Tzunami Documentum Exporter enables you to export Documentum content to a TDX\nfile.\n\n4 When exporting, keep the following in mind:\n\nExport in small chunks: When exporting from your source system, perform the export in small chunks\nof about 40K-50K files each that have a common business logic or some other logic.\n\nEnsure consistency: Make sure that the content of the different exports does not overlap and that,\nwhile exporting, no changes are made to the source data.\nTo export to a TDX file:\n\n1. In Tzunami Deployer, Right-Click in the Documentum tab source store area and\nselect Export Documentum to TDX.\n\nOr\nClick Start > All Programs > Tzunami > Tzunami Documentum Exporter\nThe Welcome screen of the Export Wizard appears.\n\n2. Click Next. The Documentum Configurations screen appears with three tabs:\nCredentials, General, and Advanced.\n\n3. Click the Credentials tab and enter the information required for the exporter to\nconnect to Documentum.\n\nwna\n\nMigration Masters\n|(UTC-01:00) Azores\n\nFigure 6: Documentum Configurations Screen \u2014 Credentials Tab\n\nTable 2: Documentum Configurations Screen \u2014 Description of Fields\n\nField Description\n\nUsername Enter the username to use when connecting to the Documentum DocBase.\n\nPassword Enter the password to use when connecting to the Documentum DocBase.\n\nRemember password Check this option if you wish to save your password for next login\n\nDocBase Select the DocBase to connect to in order to perform the export. Click\nRefresh to view the list of available DocBases.\n\nServer Time Zone: Select the Documentum Server time zone to extract the data time value\ncorrectly.\n\n4. Click the General tab and enter general export information.\n\nDocumentum Exporter Wizard\n\nDocumentum Configurations\nConfigure Documentum Settings...\n\nFigure 7: Documentum Configurations Screen \u2014 General Tab\n\ntanaiy SS\n\nMigration Masters\nTable 3: Documentum Configurations Screen, General Tab \u2014 Description of Fields\n\nField\n\nDescription\n\nExport security | Check this option if you wish to export the security permissions of items.\n\nExport versions Check this option if you wish to export all versions of documents.\n\n& If you do not check this option, only the latest version of each document\n\nis exported.\nExport Virtual Check this option if you wish to export virtual documents. Exported virtual\nDocuments documents are converted to folders during the export process.\n\nLinks - Folders | A Documentum folder can be located in more than one folder, but SharePoint does\n\nnot support this behavior. Specify whether to export such a folder only once (in the\nfirst parent it appears in), or to duplicate it in each location in which it appears.\n\nLinks\n\nA Documentum item can be located in more than one folder, but SharePoint does\nnot support this behavior. Specify whether to export such an item only once (in the\nfirst parent it appears in), or to duplicate it in each location in which it appears.\n\n5. Click the Advanced tab to enter advanced export information.\n\nDocumentum Configurations\nConfigure Documentum Settings.\n\n\"Credentials | General Advanced |\nSeutymot:[-  O\u2014~\u2014CSsSSCSCSst\u2018\u201cC<\u2018\u201c(\u2018#(NNNNSNSNNN\nDrectRots: ff |\n\nFigure 8: Documentum Configurations Screen \u2014 Advanced Tab\n\nTable 4: Documentum Configurations Screen, Advanced Tab \u2014 Description of Fields\n\nField\n\nItem\nProcessor\n\nDescription\n\nThe default behavior of Documentum Exporter is not to create files for items that do not\nhave content. The item processor allows you to add different behaviors. By entering the\nfull path for Tzunami.Common.EcmDocumentumExporter.dl1l1, an empty file is\ncreated during the export. For specific requirements please contact the Tzunami Support\n\nTeam at support@tzunami.com.\n\nSecurity\nImport\n\nTzunam\n\nMigration Masters\n\nIf you are performing multiple exports, it is more efficient to export security entities from\nanother TDX file rather than from the Documentum server. Enter the full path of a TDX\nfile from which to import security entities. Note that even if the TDX file you specify is\nmissing some users or groups, they are exported as part of the regular export.\n\nPage | 2-10\nField Description\n\nDirect Enter the r_object_id of the required folder to be used as a root folder. Multiple entries\nRoots are allowed, separated with semicolon () such as\n'0b000003800221ac;0b000003800221a6;0900000380004d2b'.\n\n6. Click Next. The Folders screen appears.\n\n7. Navigate the Documentum folders and select the folders to export.\n\n& You can select all subfolders of a selected folder by checking Automatically select subfolders.\n\n8. Click Next. The Filter screen appears.\n\nDocumentum Exporter Wizard a\n\nFilter\nPlease set a filter...\n\n\u2018Condition:\nObject Type\nI Equals to pe ]\n\nCreated smaller than \u201811/1/2010 3:50:09 PM\"\nObject Type equals to 'dm_server_config\u2019 and \u2018dm_job\u2019\n\nhal Clear All |\n< Back | Next > Cancel |\n\nFigure 9: Filter Screen\n\n9. Set up filtering as follows:\na. Inthe Properties field, select a property.\n\nb. Inthe Condition field, select a condition from the dropdown list and enter or\nselect values in the corresponding field.\n\nc. Click Add Condition. The condition is added to the Filter area, displaying the\nfull filter expression.\n\n& You can only add one condition per property.\n\nYou can edit a condition for a property by selecting the property and modifying the condition\ntype or values that are currently assigned to it.\n\nYou can remove a condition from a property or all the conditions from all the properties by\nclicking Clear Condition or Clear All, respectively.\n\nIf multiple conditions are applied, only items that match all conditions are exported.\n\nTan\n\nMigration Masters\n10. Click Next. The Destination Folder screen appears.\n\n| Documentum Exporter Wizard a\n\nDestination Folder\nPlease enter the destination folder...\n\n; Destination:\n\nLocation: |D:\\Friends and Co\n\nData will be exported to: D:\\Friends and Co\\Documentum Data\n\nThe destination folder holds TDX information and extracted files.\nPlease use a folder close to the drive root to allow deep hierarchies and long file names.\n\nNote: all currently existing content in the destination folder will be deleted.\n\n| Export specification file\n\nSaving exporter specification and details as file allows you to run the exporter from Save...\nthe command-line.\n\n< Back Next> Cancel\n\nFigure 10: Destination Folder Screen\n\n11. Specify where to export the files and generated TDX information. Make sure you are\nsaving to a folder with a descriptive name and under a well-organized file system\nhierarchy. It is recommended to export to a folder that is as close to the root as\npossible.\n\nClick Save for saving export specification details as an XML file which can be used to\nrun the exporter in command-line mode. See the section \u2018Command-Line Export\u2019\nbelow for more details.\n\n12. Click Next.\n\n& If the export folder already exists, a warning appears, informing you that the destination\nfolder already exists and if you continue all existing information will be deleted.\n\nClicking OK confirms overwrite and clicking Cancel returns you to the Destination Folder\nscreen to change the destination folder.\n\nAn Exporting screen appears with a progress bar and execution report, and the\nexport process begins.\n\nTan\n\nMigration Masters\nDocumentum Exporter Wizard\n\nExporting\nPlease wait while the export is in progress...\n\nRunning export wizard...\n\nLevel Description\n\ni) Information Completed extracting folder folder3\ni) Information Extracting folder test.tt\n\ni) Information Extracting items of test.txt\n\ni) Information Reading sub-folders of folder test. txt\n\ni) Information Completed extracting folder test.txt\n\u00a5\n4 >\n\nI Enors only I Auto-scroll View Save As...\n\nFigure 11: Exporter Progress Screen\n\n& You can save the export report by clicking Save As... after the export is complete.\nYou can display only export errors and warnings by checking Errors only.\n\nYou can check Auto-scroll to display the latest progress messages, as they appear.\n\n13. Click Next. The Export Complete screen appears.\n14. Click Done. The Tzunami Documentum Export wizard is closed.\n\nIf the exporter was run from Tzunami Deployer, after the extraction process\ncompletes successfully, you are prompted to load the exported data into the current\nTzunami Deployer project. Clicking \u2018Yes\u2019 begins the process of loading the content\nfrom the previously exported TDxX file into the project. For more information about\nloading sources, refer to the Tzunami Deployer User Guide.\n\nCOMMAND-LINE EXPORT\n\nTzunami Exporter for Documentum provides ability to run export sessions non-interactively\nusing command line instructions. This allows administrators to plan and schedule long\nrunning migration jobs through scripts, batch files and schedulers according to needs and\norganizational timetables. To run the exporter in batch mode you will need exporter\nspecification file explained in the \u2018Choose Destination Folder\u2019 step of the export wizard. The\nfile contains all the export option details including:\n\n\u00a2 Source ECM connectivity information (Server Address, User Name, Password etc.)\ne Items to export\n\n\u00a2 Destination and Log Folder\n\ne Filter\n\nTandy\n\nMigration Masters\ne Exporter specific options\n\nThis file can be edited to suit your needs however the XML schema of the file should not be\naltered. It is recommended that you generate a sample specifications file in the Destination\nFolder Screen selection step of the export wizard and use it as a template to create your own\nspecification file.\n\nOnce the specification file is ready, you can run the exporter from command line using\ncommand:\n\nTzunamiExporter.exe [-r <ResultFile>] -s <ExportSpecificationsFile>\n\nUsage\nField Description\n-r Outputs export results into an XML file [Optional]\n-S XML file containing export specifications\n\nFor example:\n\nC:\\User\\Administrator> \u201cC:\\Program Files (x86)\\Tzunami\\Deployer\n2.8\\Exporters\\Documentum\\TzunamiExporter.exe\u201d -s \u201cD:\\Spec Files\\specs1.xml\u201d\n\nC:\\Program Files (x86)\\Tzunami\\Deployer 2.8\\Exporters\\Documentum>\nTzunamiExporter.exe -s \u201cD:\\Spec Files\\specs1.xml\u201d\n\nBased on your needs you can create number of specification files and use them to run\nmultiple export sessions as batch commands.\n\nYou will need to provide absolute path for TzunamiExporter.exe and ExportSpecificationsFile\nin the command if you are not running from the exporter installation directory.\n\nIn Microsoft Windows Server 2003 and Windows Server 2008 environment, if USG (Universal\nSecurity Group) is enabled, Users with low privileges sometimes cannot export ECM\ncontents. To export contents using command line, User must run with elevated or\nadministrative privileges.\n\nTo export contents with elevated or administrative privileges, you can run the exporter from\ncommand line using command:\n\nRUNAS /trustlevel: \u201cUnrestricted\u201d \u201c<ExporterInstallationDirectory>\\TzunamiExporter.exe\u201d\n-s \u201c<Spec file path>\\Specfilename.xml\u201d \u201d\n\nFor example:\n\nC:\\> RUNAS /trustlevel:\u201cUnrestricted\u201d \u201cC:\\Program Files (x86)\\Tzunami\\Deployer\n2.8\\Exporters\\Documentum\\TzunamiExporter.exe \u201c -s \u201cD:\\Spec Files\\specs1.xml\u201d\n\nTandy\n\nMigration Masters\nBEST PRACTICE\n\nDue to the technological differences between Documentum and SharePoint, the following\nbest practices should be taken into consideration:\n\ne Follow the guidelines below when choosing the target structure.\n\nTable 5: Target Structure Guidelines\n\nDocumentum Item Type Relevant SharePoint Types\nCabinet e \u2014 Site/Site Collection\n\n\u00a2 Document Library\n\nFolder Folder/Document Library\nDocument Document\nVirtual Document \u00a9 Folder\n\n\u00a2 Document Library\n\nTan\n\nMigration Masters\n3 LICENSING INFORMATION\n\nTzunami Documentum Exporter uses a default license that can be used for evaluation\npurposes. This license is limited in the number of items that are exported. If the license does\nnot match your evaluating needs, contact support@tzunami.com for an extended license.\nFor this purpose you will need to provide the Product Serial Code, and then enter the\nLicense Key you receive back from the Tzunami.\n\nTo retrieve the Tzunami Product Serial Code:\n\n1. Select Start > Programs > Tzunami > Tzunami License Update for Documentum.\nTzunami License Update window opens.\n\ni 2\n\n|License generation date: 10/13/2008 12:00:24 PM\ni Issuer:\n\nFigure 12: License Update window\n\n2. Click Copy. This copies the Product Serial Code to the clipboard.\n\n3. Paste the contents of the clipboard into an email and send it to the Tzunami Support\n\nTeam at support@tzunami.com.\n\nTo extend the Tzunami license:\n\n1. Select Start > Programs > Tzunami > Tzunami License Update for Documentum.\nTzunami License Update window opens (Figure 12).\n\n2. Click Browse and select the new License Key file received from the Tzunami Support\nTeam.\n\nve\n<< . If an error message appears, contact Tzunami Support Team at support@tzunami.com.\n\nTandy\n\nMigration Masters\nCOPYRIGHT AND TRADEMARK\n\n\u00a9 Copyright 2014. Tzunami Inc. All rights reserved.\n\nAll intellectual property rights in this publication are owned by Tzunami, Inc. and protected\nby United States copyright laws, other applicable copyright laws and international treaty\nprovisions. Tzunami, Inc. retains all rights not expressly granted. No part of this publication\nmay be reproduced in any form whatsoever or used to make any derivative work without\nprior written approval by Tzunami, Inc.\n\nNo representation of warranties for fitness for any purpose other than what is specifically\nstated in this guide is made either by Tzunami, Inc. or by its agents.\n\nTzunami, Inc. reserves the right to revise this publication, and/or make improvements or\nchanges in the product(s) and/or the program(s) described in this documentation at any\ntime without prior notice.\n\nAny software on removable media described in this publication is furnished under a license\nagreement included with the product as a separate document. If you are unable to locate a\ncopy, please contact Tzunami, Inc. and a copy will be forwarded to you.\n\nTzunami is either a registered trademark or a trademark of Tzunami, Inc. in the United States\nand/or other countries.\n\nAll other brand or product names are trademarks or registered trademarks of their\nrespective companies.\n\nFor further information, you can contact Tzunami Inc. at:\nTzunami Inc.\n\n601 108th Avenue, NE\n\nSuite 1900\n\nBellevue, WA 98004, USA\n\nEmail: sales@tzunami.com, support@tzunami.com\n\nWeb: = http://www.tzunami.com\n\nwna SSCS\n\nMigration Masters\n"}]